{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb81bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these paths based on your local setup\n",
    "train_folder = 'E:/capstone/dataset_kitti/3D_object_detection/training'\n",
    "test_folder = 'E:/capstone/dataset_kitti/3D_object_detection/testing'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f8023",
   "metadata": {},
   "source": [
    "## kitti configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e2d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Car and Van ==> Car class\n",
    "# Pedestrian and Person_Sitting ==> Pedestrian Class\n",
    "CLASS_NAME_TO_ID = {\n",
    "    'Pedestrian': 0,\n",
    "    'Car': 1,\n",
    "    'Cyclist': 2,\n",
    "    'Van': 1,\n",
    "    'Truck': -3,\n",
    "    'Person_sitting': 0,\n",
    "    'Tram': -99,\n",
    "    'Misc': -99,\n",
    "    'DontCare': -1\n",
    "}\n",
    "\n",
    "colors = [[0, 255, 255], [0, 0, 255], [255, 0, 0], [255, 120, 0],\n",
    "          [255, 120, 120], [0, 120, 0], [120, 255, 255], [120, 0, 255]]\n",
    "\n",
    "#####################################################################################\n",
    "boundary = {\n",
    "    \"minX\": 0,\n",
    "    \"maxX\": 50,\n",
    "    \"minY\": -25,\n",
    "    \"maxY\": 25,\n",
    "    \"minZ\": -2.73,\n",
    "    \"maxZ\": 1.27\n",
    "}\n",
    "\n",
    "bound_size_x = boundary['maxX'] - boundary['minX']\n",
    "bound_size_y = boundary['maxY'] - boundary['minY']\n",
    "bound_size_z = boundary['maxZ'] - boundary['minZ']\n",
    "\n",
    "boundary_back = {\n",
    "    \"minX\": -50,\n",
    "    \"maxX\": 0,\n",
    "    \"minY\": -25,\n",
    "    \"maxY\": 25,\n",
    "    \"minZ\": -2.73,\n",
    "    \"maxZ\": 1.27\n",
    "}\n",
    "\n",
    "BEV_WIDTH = 608  # across y axis -25m ~ 25m\n",
    "BEV_HEIGHT = 608  # across x axis 0m ~ 50m\n",
    "DISCRETIZATION = (boundary[\"maxX\"] - boundary[\"minX\"]) / BEV_HEIGHT\n",
    "\n",
    "# maximum number of points per voxel\n",
    "T = 35\n",
    "\n",
    "# voxel size\n",
    "vd = 0.1  # z\n",
    "vh = 0.05  # y\n",
    "vw = 0.05  # x\n",
    "\n",
    "# voxel grid\n",
    "W = math.ceil(bound_size_x / vw)\n",
    "H = math.ceil(bound_size_y / vh)\n",
    "D = math.ceil(bound_size_z / vd)\n",
    "\n",
    "# Following parameters are calculated as an average from KITTI dataset for simplicity\n",
    "#####################################################################################\n",
    "Tr_velo_to_cam = np.array([\n",
    "    [7.49916597e-03, -9.99971248e-01, -8.65110297e-04, -6.71807577e-03],\n",
    "    [1.18652889e-02, 9.54520517e-04, -9.99910318e-01, -7.33152811e-02],\n",
    "    [9.99882833e-01, 7.49141178e-03, 1.18719929e-02, -2.78557062e-01],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "# cal mean from train set\n",
    "R0 = np.array([\n",
    "    [0.99992475, 0.00975976, -0.00734152, 0],\n",
    "    [-0.0097913, 0.99994262, -0.00430371, 0],\n",
    "    [0.00729911, 0.0043753, 0.99996319, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "P2 = np.array([[719.787081, 0., 608.463003, 44.9538775],\n",
    "               [0., 719.787081, 174.545111, 0.1066855],\n",
    "               [0., 0., 1., 3.0106472e-03],\n",
    "               [0., 0., 0., 0]\n",
    "               ])\n",
    "\n",
    "R0_inv = np.linalg.inv(R0)\n",
    "Tr_velo_to_cam_inv = np.linalg.inv(Tr_velo_to_cam)\n",
    "P2_inv = np.linalg.pinv(P2)\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8caf7a",
   "metadata": {},
   "source": [
    "## Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce5d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "def parse_configs():\n",
    "    config_dict = {}\n",
    "    config_dict['seed'] = 2020\n",
    "    config_dict['saved_fn'] = 'fpn_resnet_18'\n",
    "    config_dict['root_dir'] = './'\n",
    "    \n",
    "    ####################################################################\n",
    "    ##############     Model configs            ########################\n",
    "    ####################################################################\n",
    "    config_dict['arch'] = 'fpn_resnet_18'\n",
    "    config_dict['pretrained_path'] = None\n",
    "    ####################################################################\n",
    "    ##############     Dataloader and Running configs            #######\n",
    "    ####################################################################\n",
    "    config_dict['hflip_prob'] = 0.5\n",
    "    config_dict['no_val'] = False\n",
    "    config_dict['num_samples'] = None\n",
    "    config_dict['num_workers'] = 4\n",
    "    config_dict['batch_size'] = 16\n",
    "    config_dict['print_freq'] = 50\n",
    "    config_dict['tensorboard_freq'] = 50\n",
    "    config_dict['checkpoint_freq'] = 2\n",
    "    ####################################################################\n",
    "    ##############     Training strategy            ####################\n",
    "    ####################################################################\n",
    "    config_dict['start_epoch'] = 1\n",
    "    config_dict['num_epochs'] = 300\n",
    "    config_dict['lr_type'] = 'cosin'\n",
    "    config_dict['lr'] = 0.001\n",
    "    config_dict['minimum_lr'] = 1e-7\n",
    "    config_dict['momentum'] = 0.949\n",
    "    config_dict['weight_decay'] = 0\n",
    "    config_dict['optimizer_type'] = 'adam'\n",
    "    config_dict['steps'] = [150, 180]\n",
    "\n",
    "    ####################################################################\n",
    "    ##############     Loss weight            ##########################\n",
    "    ####################################################################\n",
    "\n",
    "    ####################################################################\n",
    "    ##############     Distributed Data Parallel            ############\n",
    "    ####################################################################\n",
    "    config_dict['world_size'] = -1\n",
    "    config_dict['rank'] = -1\n",
    "    config_dict['dist_url'] = 'tcp://127.0.0.1:29500'\n",
    "    config_dict['gpu_idx'] = 0\n",
    "    config_dict['no_cuda'] = False\n",
    "    config_dict['multiprocessing_distributed'] = False\n",
    "    ####################################################################\n",
    "    ##############     Evaluation configurations     ###################\n",
    "    ####################################################################\n",
    "    config_dict['evaluate'] = False\n",
    "    config_dict['resume_path'] = None\n",
    "    config_dict['K'] = 50\n",
    "\n",
    "    configs = edict(config_dict)\n",
    "\n",
    "    ####################################################################\n",
    "    ############## Hardware configurations #############################\n",
    "    ####################################################################\n",
    "    configs.device = torch.device('cpu' if configs.no_cuda else 'cuda')\n",
    "    configs.ngpus_per_node = torch.cuda.device_count()\n",
    "\n",
    "    configs.pin_memory = True\n",
    "    configs.input_size = (608, 608)\n",
    "    configs.hm_size = (152, 152)\n",
    "    configs.down_ratio = 4\n",
    "    configs.max_objects = 50\n",
    "\n",
    "    configs.imagenet_pretrained = True\n",
    "    configs.head_conv = 64\n",
    "    configs.num_classes = 3\n",
    "    configs.num_center_offset = 2\n",
    "    configs.num_z = 1\n",
    "    configs.num_dim = 3\n",
    "    configs.num_direction = 2  # sin, cos\n",
    "\n",
    "    configs.heads = {\n",
    "        'hm_cen': configs.num_classes,\n",
    "        'cen_offset': configs.num_center_offset,\n",
    "        'direction': configs.num_direction,\n",
    "        'z_coor': configs.num_z,\n",
    "        'dim': configs.num_dim\n",
    "    }\n",
    "\n",
    "    configs.num_input_features = 4\n",
    "\n",
    "    ####################################################################\n",
    "    ############## Dataset, logs, Checkpoints dir ######################\n",
    "    ####################################################################\n",
    "    # Update these paths based on your local setup\n",
    "    configs.dataset_dir = 'E:/capstone/dataset_kitti/3D_object_detection/'\n",
    "    configs.checkpoints_dir = os.path.join(configs.root_dir, 'checkpoints', configs.saved_fn)\n",
    "    configs.logs_dir = os.path.join(configs.root_dir, 'logs', configs.saved_fn)\n",
    "\n",
    "    if not os.path.isdir(configs.checkpoints_dir):\n",
    "        os.makedirs(configs.checkpoints_dir)\n",
    "    if not os.path.isdir(configs.logs_dir):\n",
    "        os.makedirs(configs.logs_dir)\n",
    "\n",
    "    return configs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a681a61e",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7bbf6",
   "metadata": {},
   "source": [
    "## Transformation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3932c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def angle_in_limit(angle):\n",
    "    # To limit the angle in -pi/2 - pi/2\n",
    "    limit_degree = 5\n",
    "    while angle >= np.pi / 2:\n",
    "        angle -= np.pi\n",
    "    while angle < -np.pi / 2:\n",
    "        angle += np.pi\n",
    "    if abs(angle + np.pi / 2) < limit_degree / 180 * np.pi:\n",
    "        angle = np.pi / 2\n",
    "    return angle\n",
    "\n",
    "\n",
    "def camera_to_lidar(x, y, z, V2C=None, R0=None, P2=None):\n",
    "    p = np.array([x, y, z, 1])\n",
    "    if V2C is None or R0 is None:\n",
    "        p = np.matmul(R0_inv, p)\n",
    "        p = np.matmul(Tr_velo_to_cam_inv, p)\n",
    "    else:\n",
    "        R0_i = np.zeros((4, 4))\n",
    "        R0_i[:3, :3] = R0\n",
    "        R0_i[3, 3] = 1\n",
    "        p = np.matmul(np.linalg.inv(R0_i), p)\n",
    "        p = np.matmul(inverse_rigid_trans(V2C), p)\n",
    "    p = p[0:3]\n",
    "    return tuple(p)\n",
    "\n",
    "\n",
    "def lidar_to_camera(x, y, z, V2C=None, R0=None, P2=None):\n",
    "    p = np.array([x, y, z, 1])\n",
    "    if V2C is None or R0 is None:\n",
    "        p = np.matmul(Tr_velo_to_cam, p)\n",
    "        p = np.matmul(R0, p)\n",
    "    else:\n",
    "        p = np.matmul(V2C, p)\n",
    "        p = np.matmul(R0, p)\n",
    "    p = p[0:3]\n",
    "    return tuple(p)\n",
    "\n",
    "\n",
    "def camera_to_lidar_point(points):\n",
    "    # (N, 3) -> (N, 3)\n",
    "    N = points.shape[0]\n",
    "    points = np.hstack([points, np.ones((N, 1))]).T  # (N,4) -> (4,N)\n",
    "\n",
    "    points = np.matmul(R0_inv, points)\n",
    "    points = np.matmul(Tr_velo_to_cam_inv, points).T  # (4, N) -> (N, 4)\n",
    "    points = points[:, 0:3]\n",
    "    return points.reshape(-1, 3)\n",
    "\n",
    "\n",
    "def lidar_to_camera_point(points, V2C = None):\n",
    "    # (N, 3) -> (N, 3)\n",
    "    N = points.shape[0]\n",
    "    points = np.hstack([points, np.ones((N, 1))]).T\n",
    "\n",
    "    if V2C is None or R0 is None:\n",
    "        points = np.matmul(Tr_velo_to_cam, points)\n",
    "        points = np.matmul(R0, points).T\n",
    "    else:\n",
    "        points = np.matmul(V2C, points)\n",
    "        points = np.matmul(R0, points).T\n",
    "    points = points[:, 0:3]\n",
    "    return points.reshape(-1, 3)\n",
    "\n",
    "\n",
    "def camera_to_lidar_box(boxes, V2C=None, R0=None, P2=None):\n",
    "    # (N, 7) -> (N, 7) x,y,z,h,w,l,r\n",
    "    ret = []\n",
    "    for box in boxes:\n",
    "        x, y, z, h, w, l, ry = box\n",
    "        (x, y, z), h, w, l, rz = camera_to_lidar(x, y, z, V2C=V2C, R0=R0, P2=P2), h, w, l, -ry - np.pi / 2\n",
    "        # rz = angle_in_limit(rz)\n",
    "        ret.append([x, y, z, h, w, l, rz])\n",
    "    return np.array(ret).reshape(-1, 7)\n",
    "\n",
    "\n",
    "def lidar_to_camera_box(boxes, V2C=None, R0=None, P2=None):\n",
    "    # (N, 7) -> (N, 7) x,y,z,h,w,l,r\n",
    "    ret = []\n",
    "    for box in boxes:\n",
    "        x, y, z, h, w, l, rz = box\n",
    "        (x, y, z), h, w, l, ry = lidar_to_camera(x, y, z, V2C=V2C, R0=R0, P2=P2), h, w, l, -rz - np.pi / 2\n",
    "        # ry = angle_in_limit(ry)\n",
    "        ret.append([x, y, z, h, w, l, ry])\n",
    "    return np.array(ret).reshape(-1, 7)\n",
    "\n",
    "\n",
    "def center_to_corner_box2d(boxes_center, coordinate='lidar'):\n",
    "    # (N, 5) -> (N, 4, 2)\n",
    "    N = boxes_center.shape[0]\n",
    "    boxes3d_center = np.zeros((N, 7))\n",
    "    boxes3d_center[:, [0, 1, 4, 5, 6]] = boxes_center\n",
    "    boxes3d_corner = center_to_corner_box3d(boxes3d_center, coordinate=coordinate)\n",
    "\n",
    "    return boxes3d_corner[:, 0:4, 0:2]\n",
    "\n",
    "\n",
    "def center_to_corner_box3d(boxes_center, coordinate='lidar'):\n",
    "    # (N, 7) -> (N, 8, 3)\n",
    "    N = boxes_center.shape[0]\n",
    "    ret = np.zeros((N, 8, 3), dtype=np.float32)\n",
    "\n",
    "    if coordinate == 'camera':\n",
    "        boxes_center = camera_to_lidar_box(boxes_center)\n",
    "\n",
    "    for i in range(N):\n",
    "        box = boxes_center[i]\n",
    "        translation = box[0:3]\n",
    "        size = box[3:6]\n",
    "        rotation = [0, 0, box[-1]]\n",
    "\n",
    "        h, w, l = size[0], size[1], size[2]\n",
    "        trackletBox = np.array([  # in velodyne coordinates around zero point and without orientation yet\n",
    "            [-l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2], \\\n",
    "            [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2], \\\n",
    "            [0, 0, 0, 0, h, h, h, h]])\n",
    "\n",
    "        # re-create 3D bounding box in velodyne coordinate system\n",
    "        yaw = rotation[2]\n",
    "        rotMat = np.array([\n",
    "            [np.cos(yaw), -np.sin(yaw), 0.0],\n",
    "            [np.sin(yaw), np.cos(yaw), 0.0],\n",
    "            [0.0, 0.0, 1.0]])\n",
    "        cornerPosInVelo = np.dot(rotMat, trackletBox) + np.tile(translation, (8, 1)).T\n",
    "        box3d = cornerPosInVelo.transpose()\n",
    "        ret[i] = box3d\n",
    "\n",
    "    if coordinate == 'camera':\n",
    "        for idx in range(len(ret)):\n",
    "            ret[idx] = lidar_to_camera_point(ret[idx])\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "CORNER2CENTER_AVG = True\n",
    "\n",
    "\n",
    "def corner_to_center_box3d(boxes_corner, coordinate='camera'):\n",
    "    # (N, 8, 3) -> (N, 7) x,y,z,h,w,l,ry/z\n",
    "    if coordinate == 'lidar':\n",
    "        for idx in range(len(boxes_corner)):\n",
    "            boxes_corner[idx] = lidar_to_camera_point(boxes_corner[idx])\n",
    "\n",
    "    ret = []\n",
    "    for roi in boxes_corner:\n",
    "        if CORNER2CENTER_AVG:  # average version\n",
    "            roi = np.array(roi)\n",
    "            h = abs(np.sum(roi[:4, 1] - roi[4:, 1]) / 4)\n",
    "            w = np.sum(\n",
    "                np.sqrt(np.sum((roi[0, [0, 2]] - roi[3, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[1, [0, 2]] - roi[2, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[4, [0, 2]] - roi[7, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[5, [0, 2]] - roi[6, [0, 2]]) ** 2))\n",
    "            ) / 4\n",
    "            l = np.sum(\n",
    "                np.sqrt(np.sum((roi[0, [0, 2]] - roi[1, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[2, [0, 2]] - roi[3, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[4, [0, 2]] - roi[5, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[6, [0, 2]] - roi[7, [0, 2]]) ** 2))\n",
    "            ) / 4\n",
    "            x = np.sum(roi[:, 0], axis=0) / 8\n",
    "            y = np.sum(roi[0:4, 1], axis=0) / 4\n",
    "            z = np.sum(roi[:, 2], axis=0) / 8\n",
    "            ry = np.sum(\n",
    "                math.atan2(roi[2, 0] - roi[1, 0], roi[2, 2] - roi[1, 2]) +\n",
    "                math.atan2(roi[6, 0] - roi[5, 0], roi[6, 2] - roi[5, 2]) +\n",
    "                math.atan2(roi[3, 0] - roi[0, 0], roi[3, 2] - roi[0, 2]) +\n",
    "                math.atan2(roi[7, 0] - roi[4, 0], roi[7, 2] - roi[4, 2]) +\n",
    "                math.atan2(roi[0, 2] - roi[1, 2], roi[1, 0] - roi[0, 0]) +\n",
    "                math.atan2(roi[4, 2] - roi[5, 2], roi[5, 0] - roi[4, 0]) +\n",
    "                math.atan2(roi[3, 2] - roi[2, 2], roi[2, 0] - roi[3, 0]) +\n",
    "                math.atan2(roi[7, 2] - roi[6, 2], roi[6, 0] - roi[7, 0])\n",
    "            ) / 8\n",
    "            if w > l:\n",
    "                w, l = l, w\n",
    "                ry = ry - np.pi / 2\n",
    "            elif l > w:\n",
    "                l, w = w, l\n",
    "                ry = ry - np.pi / 2\n",
    "            ret.append([x, y, z, h, w, l, ry])\n",
    "\n",
    "        else:  # max version\n",
    "            h = max(abs(roi[:4, 1] - roi[4:, 1]))\n",
    "            w = np.max(\n",
    "                np.sqrt(np.sum((roi[0, [0, 2]] - roi[3, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[1, [0, 2]] - roi[2, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[4, [0, 2]] - roi[7, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[5, [0, 2]] - roi[6, [0, 2]]) ** 2))\n",
    "            )\n",
    "            l = np.max(\n",
    "                np.sqrt(np.sum((roi[0, [0, 2]] - roi[1, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[2, [0, 2]] - roi[3, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[4, [0, 2]] - roi[5, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[6, [0, 2]] - roi[7, [0, 2]]) ** 2))\n",
    "            )\n",
    "            x = np.sum(roi[:, 0], axis=0) / 8\n",
    "            y = np.sum(roi[0:4, 1], axis=0) / 4\n",
    "            z = np.sum(roi[:, 2], axis=0) / 8\n",
    "            ry = np.sum(\n",
    "                math.atan2(roi[2, 0] - roi[1, 0], roi[2, 2] - roi[1, 2]) +\n",
    "                math.atan2(roi[6, 0] - roi[5, 0], roi[6, 2] - roi[5, 2]) +\n",
    "                math.atan2(roi[3, 0] - roi[0, 0], roi[3, 2] - roi[0, 2]) +\n",
    "                math.atan2(roi[7, 0] - roi[4, 0], roi[7, 2] - roi[4, 2]) +\n",
    "                math.atan2(roi[0, 2] - roi[1, 2], roi[1, 0] - roi[0, 0]) +\n",
    "                math.atan2(roi[4, 2] - roi[5, 2], roi[5, 0] - roi[4, 0]) +\n",
    "                math.atan2(roi[3, 2] - roi[2, 2], roi[2, 0] - roi[3, 0]) +\n",
    "                math.atan2(roi[7, 2] - roi[6, 2], roi[6, 0] - roi[7, 0])\n",
    "            ) / 8\n",
    "            if w > l:\n",
    "                w, l = l, w\n",
    "                ry = angle_in_limit(ry + np.pi / 2)\n",
    "            ret.append([x, y, z, h, w, l, ry])\n",
    "\n",
    "    if coordinate == 'lidar':\n",
    "        ret = camera_to_lidar_box(np.array(ret))\n",
    "\n",
    "    return np.array(ret)\n",
    "\n",
    "\n",
    "def point_transform(points, tx, ty, tz, rx=0, ry=0, rz=0):\n",
    "    # Input:\n",
    "    #   points: (N, 3)\n",
    "    #   rx/y/z: in radians\n",
    "    # Output:\n",
    "    #   points: (N, 3)\n",
    "    N = points.shape[0]\n",
    "    points = np.hstack([points, np.ones((N, 1))])\n",
    "\n",
    "    mat1 = np.eye(4)\n",
    "    mat1[3, 0:3] = tx, ty, tz\n",
    "    points = np.matmul(points, mat1)\n",
    "\n",
    "    if rx != 0:\n",
    "        mat = np.zeros((4, 4))\n",
    "        mat[0, 0] = 1\n",
    "        mat[3, 3] = 1\n",
    "        mat[1, 1] = np.cos(rx)\n",
    "        mat[1, 2] = -np.sin(rx)\n",
    "        mat[2, 1] = np.sin(rx)\n",
    "        mat[2, 2] = np.cos(rx)\n",
    "        points = np.matmul(points, mat)\n",
    "\n",
    "    if ry != 0:\n",
    "        mat = np.zeros((4, 4))\n",
    "        mat[1, 1] = 1\n",
    "        mat[3, 3] = 1\n",
    "        mat[0, 0] = np.cos(ry)\n",
    "        mat[0, 2] = np.sin(ry)\n",
    "        mat[2, 0] = -np.sin(ry)\n",
    "        mat[2, 2] = np.cos(ry)\n",
    "        points = np.matmul(points, mat)\n",
    "\n",
    "    if rz != 0:\n",
    "        mat = np.zeros((4, 4))\n",
    "        mat[2, 2] = 1\n",
    "        mat[3, 3] = 1\n",
    "        mat[0, 0] = np.cos(rz)\n",
    "        mat[0, 1] = -np.sin(rz)\n",
    "        mat[1, 0] = np.sin(rz)\n",
    "        mat[1, 1] = np.cos(rz)\n",
    "        points = np.matmul(points, mat)\n",
    "\n",
    "    return points[:, 0:3]\n",
    "\n",
    "\n",
    "def box_transform(boxes, tx, ty, tz, r=0, coordinate='lidar'):\n",
    "    # Input:\n",
    "    #   boxes: (N, 7) x y z h w l rz/y\n",
    "    # Output:\n",
    "    #   boxes: (N, 7) x y z h w l rz/y\n",
    "    boxes_corner = center_to_corner_box3d(boxes, coordinate=coordinate)  # (N, 8, 3)\n",
    "    for idx in range(len(boxes_corner)):\n",
    "        if coordinate == 'lidar':\n",
    "            boxes_corner[idx] = point_transform(boxes_corner[idx], tx, ty, tz, rz=r)\n",
    "        else:\n",
    "            boxes_corner[idx] = point_transform(boxes_corner[idx], tx, ty, tz, ry=r)\n",
    "\n",
    "    return corner_to_center_box3d(boxes_corner, coordinate=coordinate)\n",
    "\n",
    "\n",
    "def inverse_rigid_trans(Tr):\n",
    "    ''' Inverse a rigid body transform matrix (3x4 as [R|t])\n",
    "        [R'|-R't; 0|1]\n",
    "    '''\n",
    "    inv_Tr = np.zeros_like(Tr)  # 3x4\n",
    "    inv_Tr[0:3, 0:3] = np.transpose(Tr[0:3, 0:3])\n",
    "    inv_Tr[0:3, 3] = np.dot(-np.transpose(Tr[0:3, 0:3]), Tr[0:3, 3])\n",
    "    return inv_Tr\n",
    "\n",
    "\n",
    "class Compose(object):\n",
    "    def __init__(self, transforms, p=1.0):\n",
    "        self.transforms = transforms\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, lidar, labels):\n",
    "        if np.random.random() <= self.p:\n",
    "            for t in self.transforms:\n",
    "                lidar, labels = t(lidar, labels)\n",
    "        return lidar, labels\n",
    "\n",
    "\n",
    "class OneOf(object):\n",
    "    def __init__(self, transforms, p=1.0):\n",
    "        self.transforms = transforms\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, lidar, labels):\n",
    "        if np.random.random() <= self.p:\n",
    "            choice = np.random.randint(low=0, high=len(self.transforms))\n",
    "            lidar, labels = self.transforms[choice](lidar, labels)\n",
    "\n",
    "        return lidar, labels\n",
    "\n",
    "\n",
    "class Random_Rotation(object):\n",
    "    def __init__(self, limit_angle=np.pi / 4, p=0.5):\n",
    "        self.limit_angle = limit_angle\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, lidar, labels):\n",
    "        \"\"\"\n",
    "        :param labels: # (N', 7) x, y, z, h, w, l, r\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if np.random.random() <= self.p:\n",
    "            angle = np.random.uniform(-self.limit_angle, self.limit_angle)\n",
    "            lidar[:, 0:3] = point_transform(lidar[:, 0:3], 0, 0, 0, rz=angle)\n",
    "            labels = box_transform(labels, 0, 0, 0, r=angle, coordinate='lidar')\n",
    "\n",
    "        return lidar, labels\n",
    "\n",
    "\n",
    "class Random_Scaling(object):\n",
    "    def __init__(self, scaling_range=(0.95, 1.05), p=0.5):\n",
    "        self.scaling_range = scaling_range\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, lidar, labels):\n",
    "        \"\"\"\n",
    "        :param labels: # (N', 7) x, y, z, h, w, l, r\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if np.random.random() <= self.p:\n",
    "            factor = np.random.uniform(self.scaling_range[0], self.scaling_range[0])\n",
    "            lidar[:, 0:3] = lidar[:, 0:3] * factor\n",
    "            labels[:, 0:6] = labels[:, 0:6] * factor\n",
    "\n",
    "        return lidar, labels\n",
    "\n",
    "\n",
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "        Refer from: https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_holes, ratio, fill_value=0., p=1.0):\n",
    "        self.n_holes = n_holes\n",
    "        self.ratio = ratio\n",
    "        assert 0. <= fill_value <= 1., \"the fill value is in a range of 0 to 1\"\n",
    "        self.fill_value = fill_value\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        if np.random.random() <= self.p:\n",
    "            h = img.size(1)\n",
    "            w = img.size(2)\n",
    "\n",
    "            h_cutout = int(self.ratio * h)\n",
    "            w_cutout = int(self.ratio * w)\n",
    "\n",
    "            for n in range(self.n_holes):\n",
    "                y = np.random.randint(h)\n",
    "                x = np.random.randint(w)\n",
    "\n",
    "                y1 = np.clip(y - h_cutout // 2, 0, h)\n",
    "                y2 = np.clip(y + h_cutout // 2, 0, h)\n",
    "                x1 = np.clip(x - w_cutout // 2, 0, w)\n",
    "                x2 = np.clip(x + w_cutout // 2, 0, w)\n",
    "\n",
    "                img[:, y1: y2, x1: x2] = self.fill_value  # Zero out the selected area\n",
    "                # Remove targets that are in the selected area\n",
    "                keep_target = []\n",
    "                for target_idx, target in enumerate(targets):\n",
    "                    _, _, target_x, target_y, target_w, target_l, _, _ = target\n",
    "                    if (x1 <= target_x * w <= x2) and (y1 <= target_y * h <= y2):\n",
    "                        continue\n",
    "                    keep_target.append(target_idx)\n",
    "                targets = targets[keep_target]\n",
    "\n",
    "        return img, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3b6585",
   "metadata": {},
   "source": [
    "## Data Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "789f2ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "class Object3d(object):\n",
    "    ''' 3d object label '''\n",
    "\n",
    "    def __init__(self, label_file_line):\n",
    "        data = label_file_line.split(' ')\n",
    "        data[1:] = [float(x) for x in data[1:]]\n",
    "        # extract label, truncation, occlusion\n",
    "        self.type = data[0]  # 'Car', 'Pedestrian', ...\n",
    "        self.cls_id = self.cls_type_to_id(self.type)\n",
    "        self.truncation = data[1]  # truncated pixel ratio [0..1]\n",
    "        self.occlusion = int(data[2])  # 0=visible, 1=partly occluded, 2=fully occluded, 3=unknown\n",
    "        self.alpha = data[3]  # object observation angle [-pi..pi]\n",
    "\n",
    "        # extract 2d bounding box in 0-based coordinates\n",
    "        self.xmin = data[4]  # left\n",
    "        self.ymin = data[5]  # top\n",
    "        self.xmax = data[6]  # right\n",
    "        self.ymax = data[7]  # bottom\n",
    "        self.box2d = np.array([self.xmin, self.ymin, self.xmax, self.ymax])\n",
    "\n",
    "        # extract 3d bounding box information\n",
    "        self.h = data[8]  # box height\n",
    "        self.w = data[9]  # box width\n",
    "        self.l = data[10]  # box length (in meters)\n",
    "        self.t = (data[11], data[12], data[13])  # location (x,y,z) in camera coord.\n",
    "        self.dis_to_cam = np.linalg.norm(self.t)\n",
    "        self.ry = data[14]  # yaw angle (around Y-axis in camera coordinates) [-pi..pi]\n",
    "        self.score = data[15] if data.__len__() == 16 else -1.0\n",
    "        self.level_str = None\n",
    "        self.level = self.get_obj_level()\n",
    "\n",
    "    def cls_type_to_id(self, cls_type):\n",
    "        if cls_type not in CLASS_NAME_TO_ID.keys():\n",
    "            return -1\n",
    "\n",
    "        return CLASS_NAME_TO_ID[cls_type]\n",
    "\n",
    "    def get_obj_level(self):\n",
    "        height = float(self.box2d[3]) - float(self.box2d[1]) + 1\n",
    "\n",
    "        if height >= 40 and self.truncation <= 0.15 and self.occlusion <= 0:\n",
    "            self.level_str = 'Easy'\n",
    "            return 1  # Easy\n",
    "        elif height >= 25 and self.truncation <= 0.3 and self.occlusion <= 1:\n",
    "            self.level_str = 'Moderate'\n",
    "            return 2  # Moderate\n",
    "        elif height >= 25 and self.truncation <= 0.5 and self.occlusion <= 2:\n",
    "            self.level_str = 'Hard'\n",
    "            return 3  # Hard\n",
    "        else:\n",
    "            self.level_str = 'UnKnown'\n",
    "            return 4\n",
    "\n",
    "    def print_object(self):\n",
    "        print('Type, truncation, occlusion, alpha: %s, %d, %d, %f' % \\\n",
    "              (self.type, self.truncation, self.occlusion, self.alpha))\n",
    "        print('2d bbox (x0,y0,x1,y1): %f, %f, %f, %f' % \\\n",
    "              (self.xmin, self.ymin, self.xmax, self.ymax))\n",
    "        print('3d bbox h,w,l: %f, %f, %f' % \\\n",
    "              (self.h, self.w, self.l))\n",
    "        print('3d bbox location, ry: (%f, %f, %f), %f' % \\\n",
    "              (self.t[0], self.t[1], self.t[2], self.ry))\n",
    "\n",
    "    def to_kitti_format(self):\n",
    "        kitti_str = '%s %.2f %d %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f' \\\n",
    "                    % (self.type, self.truncation, int(self.occlusion), self.alpha, self.box2d[0], self.box2d[1],\n",
    "                       self.box2d[2], self.box2d[3], self.h, self.w, self.l, self.t[0], self.t[1], self.t[2],\n",
    "                       self.ry, self.score)\n",
    "        return kitti_str\n",
    "\n",
    "\n",
    "def read_label(label_filename):\n",
    "    lines = [line.rstrip() for line in open(label_filename)]\n",
    "    objects = [Object3d(line) for line in lines]\n",
    "    return objects\n",
    "\n",
    "\n",
    "class Calibration(object):\n",
    "    ''' Calibration matrices and utils\n",
    "        3d XYZ in <label>.txt are in rect camera coord.\n",
    "        2d box xy are in image2 coord\n",
    "        Points in <lidar>.bin are in Velodyne coord.\n",
    "        y_image2 = P^2_rect * x_rect\n",
    "        y_image2 = P^2_rect * R0_rect * Tr_velo_to_cam * x_velo\n",
    "        x_ref = Tr_velo_to_cam * x_velo\n",
    "        x_rect = R0_rect * x_ref\n",
    "        P^2_rect = [f^2_u,  0,      c^2_u,  -f^2_u b^2_x;\n",
    "                    0,      f^2_v,  c^2_v,  -f^2_v b^2_y;\n",
    "                    0,      0,      1,      0]\n",
    "                 = K * [1|t]\n",
    "        image2 coord:\n",
    "         ----> x-axis (u)\n",
    "        |\n",
    "        |\n",
    "        v y-axis (v)\n",
    "        velodyne coord:\n",
    "        front x, left y, up z\n",
    "        rect/ref camera coord:\n",
    "        right x, down y, front z\n",
    "        Ref (KITTI paper): http://www.cvlibs.net/publications/Geiger2013IJRR.pdf\n",
    "        TODO(rqi): do matrix multiplication only once for each projection.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, calib_filepath):\n",
    "        calibs = self.read_calib_file(calib_filepath)\n",
    "        # Projection matrix from rect camera coord to image2 coord\n",
    "        self.P2 = calibs['P2']\n",
    "        self.P2 = np.reshape(self.P2, [3, 4])\n",
    "        self.P3 = calibs['P3']\n",
    "        self.P3 = np.reshape(self.P3, [3, 4])\n",
    "        # Rigid transform from Velodyne coord to reference camera coord\n",
    "        self.V2C = calibs['Tr_velo2cam']\n",
    "        self.V2C = np.reshape(self.V2C, [3, 4])\n",
    "        # Rotation from reference camera coord to rect camera coord\n",
    "        self.R0 = calibs['R_rect']\n",
    "        self.R0 = np.reshape(self.R0, [3, 3])\n",
    "\n",
    "        # Camera intrinsics and extrinsics\n",
    "        self.c_u = self.P2[0, 2]\n",
    "        self.c_v = self.P2[1, 2]\n",
    "        self.f_u = self.P2[0, 0]\n",
    "        self.f_v = self.P2[1, 1]\n",
    "        self.b_x = self.P2[0, 3] / (-self.f_u)  # relative\n",
    "        self.b_y = self.P2[1, 3] / (-self.f_v)\n",
    "\n",
    "    def read_calib_file(self, filepath):\n",
    "        with open(filepath) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        obj = lines[2].strip().split(' ')[1:]\n",
    "        P2 = np.array(obj, dtype=np.float32)\n",
    "        obj = lines[3].strip().split(' ')[1:]\n",
    "        P3 = np.array(obj, dtype=np.float32)\n",
    "        obj = lines[4].strip().split(' ')[1:]\n",
    "        R0 = np.array(obj, dtype=np.float32)\n",
    "        obj = lines[5].strip().split(' ')[1:]\n",
    "        Tr_velo_to_cam = np.array(obj, dtype=np.float32)\n",
    "\n",
    "        return {'P2': P2.reshape(3, 4),\n",
    "                'P3': P3.reshape(3, 4),\n",
    "                'R_rect': R0.reshape(3, 3),\n",
    "                'Tr_velo2cam': Tr_velo_to_cam.reshape(3, 4)}\n",
    "\n",
    "    def cart2hom(self, pts_3d):\n",
    "        \"\"\"\n",
    "        :param pts: (N, 3 or 2)\n",
    "        :return pts_hom: (N, 4 or 3)\n",
    "        \"\"\"\n",
    "        pts_hom = np.hstack((pts_3d, np.ones((pts_3d.shape[0], 1), dtype=np.float32)))\n",
    "        return pts_hom\n",
    "\n",
    "\n",
    "def compute_radius(det_size, min_overlap=0.7):\n",
    "    height, width = det_size\n",
    "\n",
    "    a1 = 1\n",
    "    b1 = (height + width)\n",
    "    c1 = width * height * (1 - min_overlap) / (1 + min_overlap)\n",
    "    sq1 = np.sqrt(b1 ** 2 - 4 * a1 * c1)\n",
    "    r1 = (b1 + sq1) / 2\n",
    "\n",
    "    a2 = 4\n",
    "    b2 = 2 * (height + width)\n",
    "    c2 = (1 - min_overlap) * width * height\n",
    "    sq2 = np.sqrt(b2 ** 2 - 4 * a2 * c2)\n",
    "    r2 = (b2 + sq2) / 2\n",
    "\n",
    "    a3 = 4 * min_overlap\n",
    "    b3 = -2 * min_overlap * (height + width)\n",
    "    c3 = (min_overlap - 1) * width * height\n",
    "    sq3 = np.sqrt(b3 ** 2 - 4 * a3 * c3)\n",
    "    r3 = (b3 + sq3) / 2\n",
    "\n",
    "    return min(r1, r2, r3)\n",
    "\n",
    "\n",
    "def gaussian2D(shape, sigma=1):\n",
    "    m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "    y, x = np.ogrid[-m:m + 1, -n:n + 1]\n",
    "    h = np.exp(-(x * x + y * y) / (2 * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "\n",
    "    return h\n",
    "\n",
    "\n",
    "def gen_hm_radius(heatmap, center, radius, k=1):\n",
    "    diameter = 2 * radius + 1\n",
    "    gaussian = gaussian2D((diameter, diameter), sigma=diameter / 6)\n",
    "\n",
    "    x, y = int(center[0]), int(center[1])\n",
    "\n",
    "    height, width = heatmap.shape[0:2]\n",
    "\n",
    "    left, right = min(x, radius), min(width - x, radius + 1)\n",
    "    top, bottom = min(y, radius), min(height - y, radius + 1)\n",
    "\n",
    "    masked_heatmap = heatmap[y - top:y + bottom, x - left:x + right]\n",
    "    masked_gaussian = gaussian[radius - top:radius + bottom, radius - left:radius + right]\n",
    "    if min(masked_gaussian.shape) > 0 and min(masked_heatmap.shape) > 0:  # TODO debug\n",
    "        np.maximum(masked_heatmap, masked_gaussian * k, out=masked_heatmap)\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def get_filtered_lidar(lidar, boundary, labels=None):\n",
    "    minX = boundary['minX']\n",
    "    maxX = boundary['maxX']\n",
    "    minY = boundary['minY']\n",
    "    maxY = boundary['maxY']\n",
    "    minZ = boundary['minZ']\n",
    "    maxZ = boundary['maxZ']\n",
    "\n",
    "    # Remove the point out of range x,y,z\n",
    "    mask = np.where((lidar[:, 0] >= minX) & (lidar[:, 0] <= maxX) &\n",
    "                    (lidar[:, 1] >= minY) & (lidar[:, 1] <= maxY) &\n",
    "                    (lidar[:, 2] >= minZ) & (lidar[:, 2] <= maxZ))\n",
    "    lidar = lidar[mask]\n",
    "    lidar[:, 2] = lidar[:, 2] - minZ\n",
    "\n",
    "    if labels is not None:\n",
    "        label_x = (labels[:, 1] >= minX) & (labels[:, 1] < maxX)\n",
    "        label_y = (labels[:, 2] >= minY) & (labels[:, 2] < maxY)\n",
    "        label_z = (labels[:, 3] >= minZ) & (labels[:, 3] < maxZ)\n",
    "        mask_label = label_x & label_y & label_z\n",
    "        labels = labels[mask_label]\n",
    "        return lidar, labels\n",
    "    else:\n",
    "        return lidar\n",
    "\n",
    "\n",
    "def box3d_corners_to_center(box3d_corner):\n",
    "    # (N, 8, 3) -> (N, 7)\n",
    "    assert box3d_corner.ndim == 3\n",
    "\n",
    "    xyz = np.mean(box3d_corner, axis=1)\n",
    "\n",
    "    h = abs(np.mean(box3d_corner[:, 4:, 2] - box3d_corner[:, :4, 2], axis=1, keepdims=True))\n",
    "    w = (np.sqrt(np.sum((box3d_corner[:, 0, [0, 1]] - box3d_corner[:, 1, [0, 1]]) ** 2, axis=1, keepdims=True)) +\n",
    "         np.sqrt(np.sum((box3d_corner[:, 2, [0, 1]] - box3d_corner[:, 3, [0, 1]]) ** 2, axis=1, keepdims=True)) +\n",
    "         np.sqrt(np.sum((box3d_corner[:, 4, [0, 1]] - box3d_corner[:, 5, [0, 1]]) ** 2, axis=1, keepdims=True)) +\n",
    "         np.sqrt(np.sum((box3d_corner[:, 6, [0, 1]] - box3d_corner[:, 7, [0, 1]]) ** 2, axis=1, keepdims=True))) / 4\n",
    "\n",
    "    l = (np.sqrt(np.sum((box3d_corner[:, 0, [0, 1]] - box3d_corner[:, 3, [0, 1]]) ** 2, axis=1, keepdims=True)) +\n",
    "         np.sqrt(np.sum((box3d_corner[:, 1, [0, 1]] - box3d_corner[:, 2, [0, 1]]) ** 2, axis=1, keepdims=True)) +\n",
    "         np.sqrt(np.sum((box3d_corner[:, 4, [0, 1]] - box3d_corner[:, 7, [0, 1]]) ** 2, axis=1, keepdims=True)) +\n",
    "         np.sqrt(np.sum((box3d_corner[:, 5, [0, 1]] - box3d_corner[:, 6, [0, 1]]) ** 2, axis=1, keepdims=True))) / 4\n",
    "\n",
    "    yaw = (np.arctan2(box3d_corner[:, 2, 1] - box3d_corner[:, 1, 1],\n",
    "                      box3d_corner[:, 2, 0] - box3d_corner[:, 1, 0]) +\n",
    "           np.arctan2(box3d_corner[:, 3, 1] - box3d_corner[:, 0, 1],\n",
    "                      box3d_corner[:, 3, 0] - box3d_corner[:, 0, 0]) +\n",
    "           np.arctan2(box3d_corner[:, 2, 0] - box3d_corner[:, 3, 0],\n",
    "                      box3d_corner[:, 3, 1] - box3d_corner[:, 2, 1]) +\n",
    "           np.arctan2(box3d_corner[:, 1, 0] - box3d_corner[:, 0, 0],\n",
    "                      box3d_corner[:, 0, 1] - box3d_corner[:, 1, 1]))[:, np.newaxis] / 4\n",
    "\n",
    "    return np.concatenate([h, w, l, xyz, yaw], axis=1).reshape(-1, 7)\n",
    "\n",
    "\n",
    "def box3d_center_to_conners(box3d_center):\n",
    "    h, w, l, x, y, z, yaw = box3d_center\n",
    "    Box = np.array([[-l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2],\n",
    "                    [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2],\n",
    "                    [0, 0, 0, 0, h, h, h, h]])\n",
    "\n",
    "    rotMat = np.array([\n",
    "        [np.cos(yaw), -np.sin(yaw), 0.0],\n",
    "        [np.sin(yaw), np.cos(yaw), 0.0],\n",
    "        [0.0, 0.0, 1.0]])\n",
    "\n",
    "    velo_box = np.dot(rotMat, Box)\n",
    "    cornerPosInVelo = velo_box + np.tile(np.array([x, y, z]), (8, 1)).T\n",
    "    box3d_corner = cornerPosInVelo.transpose()\n",
    "\n",
    "    return box3d_corner.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5c1a5",
   "metadata": {},
   "source": [
    "## Birds Eye View Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0c0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def makeBEVMap(PointCloud_, boundary):\n",
    "    Height = BEV_HEIGHT + 1\n",
    "    Width = BEV_WIDTH + 1\n",
    "\n",
    "    # Discretize Feature Map\n",
    "    PointCloud = np.copy(PointCloud_)\n",
    "    PointCloud[:, 0] = np.int_(np.floor(PointCloud[:, 0] / DISCRETIZATION))\n",
    "    PointCloud[:, 1] = np.int_(np.floor(PointCloud[:, 1] / DISCRETIZATION) + Width / 2)\n",
    "\n",
    "    # sort-3times\n",
    "    sorted_indices = np.lexsort((-PointCloud[:, 2], PointCloud[:, 1], PointCloud[:, 0]))\n",
    "    PointCloud = PointCloud[sorted_indices]\n",
    "    _, unique_indices, unique_counts = np.unique(PointCloud[:, 0:2], axis=0, return_index=True, return_counts=True)\n",
    "    PointCloud_top = PointCloud[unique_indices]\n",
    "\n",
    "    # Height Map, Intensity Map & Density Map\n",
    "    heightMap = np.zeros((Height, Width))\n",
    "    intensityMap = np.zeros((Height, Width))\n",
    "    densityMap = np.zeros((Height, Width))\n",
    "\n",
    "    # some important problem is image coordinate is (y,x), not (x,y)\n",
    "    max_height = float(np.abs(boundary['maxZ'] - boundary['minZ']))\n",
    "    heightMap[np.int_(PointCloud_top[:, 0]), np.int_(PointCloud_top[:, 1])] = PointCloud_top[:, 2] / max_height\n",
    "\n",
    "    normalizedCounts = np.minimum(1.0, np.log(unique_counts + 1) / np.log(64))\n",
    "    intensityMap[np.int_(PointCloud_top[:, 0]), np.int_(PointCloud_top[:, 1])] = PointCloud_top[:, 3]\n",
    "    densityMap[np.int_(PointCloud_top[:, 0]), np.int_(PointCloud_top[:, 1])] = normalizedCounts\n",
    "\n",
    "    RGB_Map = np.zeros((3, Height - 1, Width - 1))\n",
    "    RGB_Map[2, :, :] = densityMap[:BEV_HEIGHT, :BEV_WIDTH]  # r_map\n",
    "    RGB_Map[1, :, :] = heightMap[:BEV_HEIGHT, :BEV_WIDTH]  # g_map\n",
    "    RGB_Map[0, :, :] = intensityMap[:BEV_HEIGHT, :BEV_WIDTH]  # b_map\n",
    "\n",
    "    return RGB_Map\n",
    "\n",
    "\n",
    "# bev image coordinates format\n",
    "def get_corners(x, y, w, l, yaw):\n",
    "    bev_corners = np.zeros((4, 2), dtype=np.float32)\n",
    "    cos_yaw = np.cos(yaw)\n",
    "    sin_yaw = np.sin(yaw)\n",
    "    # front left\n",
    "    bev_corners[0, 0] = x - w / 2 * cos_yaw - l / 2 * sin_yaw\n",
    "    bev_corners[0, 1] = y - w / 2 * sin_yaw + l / 2 * cos_yaw\n",
    "\n",
    "    # rear left\n",
    "    bev_corners[1, 0] = x - w / 2 * cos_yaw + l / 2 * sin_yaw\n",
    "    bev_corners[1, 1] = y - w / 2 * sin_yaw - l / 2 * cos_yaw\n",
    "\n",
    "    # rear right\n",
    "    bev_corners[2, 0] = x + w / 2 * cos_yaw + l / 2 * sin_yaw\n",
    "    bev_corners[2, 1] = y + w / 2 * sin_yaw - l / 2 * cos_yaw\n",
    "\n",
    "    # front right\n",
    "    bev_corners[3, 0] = x + w / 2 * cos_yaw - l / 2 * sin_yaw\n",
    "    bev_corners[3, 1] = y + w / 2 * sin_yaw + l / 2 * cos_yaw\n",
    "\n",
    "    return bev_corners\n",
    "\n",
    "\n",
    "def drawRotatedBox(img, x, y, w, l, yaw, color):\n",
    "    bev_corners = get_corners(x, y, w, l, yaw)\n",
    "    corners_int = bev_corners.reshape(-1, 1, 2).astype(int)\n",
    "    cv2.polylines(img, [corners_int], True, color, 2)\n",
    "    corners_int = bev_corners.reshape(-1, 2)\n",
    "    cv2.line(img, (int(corners_int[0, 0]), int(corners_int[0, 1])), (int(corners_int[3, 0]), int(corners_int[3, 1])), (255, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567451f",
   "metadata": {},
   "source": [
    "## Dataset Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79708805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "from builtins import int\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "class KittiDataset(Dataset):\n",
    "    def __init__(self, configs, mode='train', lidar_aug=None, hflip_prob=None, num_samples=None):\n",
    "        self.dataset_dir = \"E:\\\\capstone\\\\dataset_kitti\\\\3D_object_detection\"\n",
    "        self.input_size = configs.input_size\n",
    "        self.hm_size = configs.hm_size\n",
    "\n",
    "        self.num_classes = configs.num_classes\n",
    "        self.max_objects = configs.max_objects\n",
    "\n",
    "        assert mode in ['train', 'val', 'test'], 'Invalid mode: {}'.format(mode)\n",
    "        self.mode = mode\n",
    "        self.is_test = (self.mode == 'test')\n",
    "        sub_folder = 'testing' if self.is_test else 'training'\n",
    "\n",
    "        self.lidar_aug = lidar_aug\n",
    "        self.hflip_prob = hflip_prob\n",
    "\n",
    "        self.image_dir = os.path.join(self.dataset_dir, sub_folder, \"image_2\")\n",
    "        self.lidar_dir = os.path.join(self.dataset_dir, sub_folder, \"velodyne\")\n",
    "        self.calib_dir = os.path.join(self.dataset_dir, sub_folder, \"calib\")\n",
    "        self.label_dir = os.path.join(self.dataset_dir, sub_folder, \"label_2\")\n",
    "        split_txt_path = os.path.join(configs.root_dir, 'dataset', 'kitti', 'ImageSets', '{}.txt'.format(mode))\n",
    "        self.sample_id_list = [int(x.strip()) for x in open(split_txt_path).readlines()]\n",
    "\n",
    "        if num_samples is not None:\n",
    "            self.sample_id_list = self.sample_id_list[:num_samples]\n",
    "        self.num_samples = len(self.sample_id_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_id_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.is_test:\n",
    "            return self.load_img_only(index)\n",
    "        else:\n",
    "            return self.load_img_with_targets(index)\n",
    "\n",
    "    def load_img_only(self, index):\n",
    "        \"\"\"Load only image for the testing phase\"\"\"\n",
    "        sample_id = int(self.sample_id_list[index])\n",
    "        img_path, img_rgb = self.get_image(sample_id)\n",
    "        lidarData = self.get_lidar(sample_id)\n",
    "        lidarData = get_filtered_lidar(lidarData, boundary)\n",
    "        bev_map = makeBEVMap(lidarData, boundary)\n",
    "        bev_map = torch.from_numpy(bev_map)\n",
    "\n",
    "        metadatas = {\n",
    "            'img_path': img_path,\n",
    "        }\n",
    "\n",
    "        return metadatas, bev_map, img_rgb\n",
    "\n",
    "    def load_img_with_targets(self, index):\n",
    "        \"\"\"Load images and targets for the training and validation phase\"\"\"\n",
    "        sample_id = int(self.sample_id_list[index])\n",
    "        img_path = os.path.join(self.image_dir, '{:06d}.png'.format(sample_id))\n",
    "        lidarData = self.get_lidar(sample_id)\n",
    "        calib = self.get_calib(sample_id)\n",
    "        labels, has_labels = self.get_label(sample_id)\n",
    "        if has_labels:\n",
    "            labels[:, 1:] = camera_to_lidar_box(labels[:, 1:], calib.V2C, calib.R0, calib.P2)\n",
    "\n",
    "        if self.lidar_aug:\n",
    "            lidarData, labels[:, 1:] = self.lidar_aug(lidarData, labels[:, 1:])\n",
    "\n",
    "        lidarData, labels = get_filtered_lidar(lidarData, boundary, labels)\n",
    "\n",
    "        bev_map = makeBEVMap(lidarData, boundary)\n",
    "        bev_map = torch.from_numpy(bev_map)\n",
    "\n",
    "        hflipped = False\n",
    "        if np.random.random() < self.hflip_prob:\n",
    "            hflipped = True\n",
    "            # C, H, W\n",
    "            bev_map = torch.flip(bev_map, [-1])\n",
    "\n",
    "        targets = self.build_targets(labels, hflipped)\n",
    "\n",
    "        metadatas = {\n",
    "            'img_path': img_path,\n",
    "            'hflipped': hflipped\n",
    "        }\n",
    "\n",
    "        return metadatas, bev_map, targets\n",
    "\n",
    "    def get_image(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, '{:06d}.png'.format(idx))\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        return img_path, img\n",
    "\n",
    "    def get_calib(self, idx):\n",
    "        calib_file = os.path.join(self.calib_dir, '{:06d}.txt'.format(idx))\n",
    "        # assert os.path.isfile(calib_file)\n",
    "        return Calibration(calib_file)\n",
    "\n",
    "    def get_lidar(self, idx):\n",
    "        lidar_file = os.path.join(self.lidar_dir, '{:06d}.bin'.format(idx))\n",
    "        # assert os.path.isfile(lidar_file)\n",
    "        return np.fromfile(lidar_file, dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "    def get_label(self, idx):\n",
    "        labels = []\n",
    "        label_path = os.path.join(self.label_dir, '{:06d}.txt'.format(idx))\n",
    "        for line in open(label_path, 'r'):\n",
    "            line = line.rstrip()\n",
    "            line_parts = line.split(' ')\n",
    "            obj_name = line_parts[0]  # 'Car', 'Pedestrian', ...\n",
    "            cat_id = int(CLASS_NAME_TO_ID[obj_name])\n",
    "            if cat_id <= -99:  # ignore Tram and Misc\n",
    "                continue\n",
    "            truncated = int(float(line_parts[1]))  # truncated pixel ratio [0..1]\n",
    "            occluded = int(line_parts[2])  # 0=visible, 1=partly occluded, 2=fully occluded, 3=unknown\n",
    "            alpha = float(line_parts[3])  # object observation angle [-pi..pi]\n",
    "            # xmin, ymin, xmax, ymax\n",
    "            bbox = np.array([float(line_parts[4]), float(line_parts[5]), float(line_parts[6]), float(line_parts[7])])\n",
    "            # height, width, length (h, w, l)\n",
    "            h, w, l = float(line_parts[8]), float(line_parts[9]), float(line_parts[10])\n",
    "            # location (x,y,z) in camera coord.\n",
    "            x, y, z = float(line_parts[11]), float(line_parts[12]), float(line_parts[13])\n",
    "            ry = float(line_parts[14])  # yaw angle (around Y-axis in camera coordinates) [-pi..pi]\n",
    "\n",
    "            object_label = [cat_id, x, y, z, h, w, l, ry]\n",
    "            labels.append(object_label)\n",
    "\n",
    "        if len(labels) == 0:\n",
    "            labels = np.zeros((1, 8), dtype=np.float32)\n",
    "            has_labels = False\n",
    "        else:\n",
    "            labels = np.array(labels, dtype=np.float32)\n",
    "            has_labels = True\n",
    "\n",
    "        return labels, has_labels\n",
    "\n",
    "    def build_targets(self, labels, hflipped):\n",
    "        minX = boundary['minX']\n",
    "        maxX = boundary['maxX']\n",
    "        minY = boundary['minY']\n",
    "        maxY = boundary['maxY']\n",
    "        minZ = boundary['minZ']\n",
    "        maxZ = boundary['maxZ']\n",
    "\n",
    "        num_objects = min(len(labels), self.max_objects)\n",
    "        hm_l, hm_w = self.hm_size\n",
    "\n",
    "        hm_main_center = np.zeros((self.num_classes, hm_l, hm_w), dtype=np.float32)\n",
    "        cen_offset = np.zeros((self.max_objects, 2), dtype=np.float32)\n",
    "        direction = np.zeros((self.max_objects, 2), dtype=np.float32)\n",
    "        z_coor = np.zeros((self.max_objects, 1), dtype=np.float32)\n",
    "        dimension = np.zeros((self.max_objects, 3), dtype=np.float32)\n",
    "\n",
    "        indices_center = np.zeros((self.max_objects), dtype=np.int64)\n",
    "        obj_mask = np.zeros((self.max_objects), dtype=np.uint8)\n",
    "\n",
    "        for k in range(num_objects):\n",
    "            cls_id, x, y, z, h, w, l, yaw = labels[k]\n",
    "            cls_id = int(cls_id)\n",
    "            # Invert yaw angle\n",
    "            yaw = -yaw\n",
    "            if not ((minX <= x <= maxX) and (minY <= y <= maxY) and (minZ <= z <= maxZ)):\n",
    "                continue\n",
    "            if (h <= 0) or (w <= 0) or (l <= 0):\n",
    "                continue\n",
    "\n",
    "            bbox_l = l / bound_size_x * hm_l\n",
    "            bbox_w = w / bound_size_y * hm_w\n",
    "            radius = compute_radius((math.ceil(bbox_l), math.ceil(bbox_w)))\n",
    "            radius = max(0, int(radius))\n",
    "\n",
    "            center_y = (x - minX) / bound_size_x * hm_l  # x --> y (invert to 2D image space)\n",
    "            center_x = (y - minY) / bound_size_y * hm_w  # y --> x\n",
    "            center = np.array([center_x, center_y], dtype=np.float32)\n",
    "\n",
    "            if hflipped:\n",
    "                center[0] = hm_w - center[0] - 1\n",
    "\n",
    "            center_int = center.astype(np.int32)\n",
    "            if cls_id < 0:\n",
    "                ignore_ids = [_ for _ in range(self.num_classes)] if cls_id == - 1 else [- cls_id - 2]\n",
    "                # Consider to make mask ignore\n",
    "                for cls_ig in ignore_ids:\n",
    "                    gen_hm_radius(hm_main_center[cls_ig], center_int, radius)\n",
    "                hm_main_center[ignore_ids, center_int[1], center_int[0]] = 0.9999\n",
    "                continue\n",
    "\n",
    "            # Generate heatmaps for main center\n",
    "            gen_hm_radius(hm_main_center[cls_id], center, radius)\n",
    "            # Index of the center\n",
    "            indices_center[k] = center_int[1] * hm_w + center_int[0]\n",
    "\n",
    "            # targets for center offset\n",
    "            cen_offset[k] = center - center_int\n",
    "\n",
    "            # targets for dimension\n",
    "            dimension[k, 0] = h\n",
    "            dimension[k, 1] = w\n",
    "            dimension[k, 2] = l\n",
    "\n",
    "            # targets for direction\n",
    "            direction[k, 0] = math.sin(float(yaw))  # im\n",
    "            direction[k, 1] = math.cos(float(yaw))  # re\n",
    "            # im -->> -im\n",
    "            if hflipped:\n",
    "                direction[k, 0] = - direction[k, 0]\n",
    "\n",
    "            # targets for depth\n",
    "            z_coor[k] = z - minZ\n",
    "\n",
    "            # Generate object masks\n",
    "            obj_mask[k] = 1\n",
    "\n",
    "        targets = {\n",
    "            'hm_cen': hm_main_center,\n",
    "            'cen_offset': cen_offset,\n",
    "            'direction': direction,\n",
    "            'z_coor': z_coor,\n",
    "            'dim': dimension,\n",
    "            'indices_center': indices_center,\n",
    "            'obj_mask': obj_mask,\n",
    "        }\n",
    "\n",
    "        return targets\n",
    "\n",
    "    def draw_img_with_label(self, index):\n",
    "        sample_id = int(self.sample_id_list[index])\n",
    "        img_path, img_rgb = self.get_image(sample_id)\n",
    "        lidarData = self.get_lidar(sample_id)\n",
    "        calib = self.get_calib(sample_id)\n",
    "        labels, has_labels = self.get_label(sample_id)\n",
    "        if has_labels:\n",
    "            labels[:, 1:] = camera_to_lidar_box(labels[:, 1:], calib.V2C, calib.R0, calib.P2)\n",
    "\n",
    "        if self.lidar_aug:\n",
    "            lidarData, labels[:, 1:] = self.lidar_aug(lidarData, labels[:, 1:])\n",
    "\n",
    "        lidarData, labels = get_filtered_lidar(lidarData, boundary, labels)\n",
    "        bev_map = makeBEVMap(lidarData, boundary)\n",
    "\n",
    "        return bev_map, labels, img_rgb, img_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315ac386",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94f82261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_train_dataloader(configs):\n",
    "    \"\"\"Create dataloader for training\"\"\"\n",
    "    train_lidar_aug = OneOf([\n",
    "        Random_Rotation(limit_angle=np.pi / 4, p=1.0),\n",
    "        Random_Scaling(scaling_range=(0.95, 1.05), p=1.0),\n",
    "    ], p=0.66)\n",
    "    train_dataset = KittiDataset(configs, mode='train', lidar_aug=train_lidar_aug, hflip_prob=configs.hflip_prob,\n",
    "                                 num_samples=configs.num_samples)\n",
    "    train_sampler = None\n",
    "    if configs.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=configs.batch_size, shuffle=(train_sampler is None),\n",
    "                                  pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=train_sampler)\n",
    "\n",
    "    return train_dataloader, train_sampler\n",
    "\n",
    "\n",
    "def create_val_dataloader(configs):\n",
    "    \"\"\"Create dataloader for validation\"\"\"\n",
    "    val_sampler = None\n",
    "    val_dataset = KittiDataset(configs, mode='val', lidar_aug=None, hflip_prob=0., num_samples=configs.num_samples)\n",
    "    if configs.distributed:\n",
    "        val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=False)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=configs.batch_size, shuffle=False,\n",
    "                                pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=val_sampler)\n",
    "\n",
    "    return val_dataloader\n",
    "\n",
    "\n",
    "def create_test_dataloader(configs):\n",
    "    \"\"\"Create dataloader for testing phase\"\"\"\n",
    "\n",
    "    test_dataset = KittiDataset(configs, mode='test', lidar_aug=None, hflip_prob=0., num_samples=configs.num_samples)\n",
    "    test_sampler = None\n",
    "    if configs.distributed:\n",
    "        test_sampler = torch.utils.data.distributed.DistributedSampler(test_dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=configs.batch_size, shuffle=False,\n",
    "                                 pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=test_sampler)\n",
    "\n",
    "    return test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b49550",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c98a1",
   "metadata": {},
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab627fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "\n",
    "class Logger():\n",
    "    \"\"\"\n",
    "        Create logger to save logs during training\n",
    "        Args:\n",
    "            logs_dir:\n",
    "            saved_fn:\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, logs_dir, saved_fn):\n",
    "        logger_fn = 'logger_{}.txt'.format(saved_fn)\n",
    "        logger_path = os.path.join(logs_dir, logger_fn)\n",
    "\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "        # formatter = logging.Formatter('%(asctime)s:File %(module)s.py:Func %(funcName)s:Line %(lineno)d:%(levelname)s: %(message)s')\n",
    "        formatter = logging.Formatter(\n",
    "            '%(asctime)s: %(module)s.py - %(funcName)s(), at Line %(lineno)d:%(levelname)s:\\n%(message)s')\n",
    "\n",
    "        file_handler = logging.FileHandler(logger_path)\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        file_handler.setFormatter(formatter)\n",
    "\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        stream_handler.setFormatter(formatter)\n",
    "\n",
    "        self.logger.addHandler(file_handler)\n",
    "        self.logger.addHandler(stream_handler)\n",
    "\n",
    "    def info(self, message):\n",
    "        self.logger.info(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f80537",
   "metadata": {},
   "source": [
    "## Pytorch Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b43a22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "__all__ = ['convert2cpu', 'convert2cpu_long', 'to_cpu', 'reduce_tensor', 'to_python_float', '_sigmoid']\n",
    "\n",
    "\n",
    "def convert2cpu(gpu_matrix):\n",
    "    return torch.FloatTensor(gpu_matrix.size()).copy_(gpu_matrix)\n",
    "\n",
    "\n",
    "def convert2cpu_long(gpu_matrix):\n",
    "    return torch.LongTensor(gpu_matrix.size()).copy_(gpu_matrix)\n",
    "\n",
    "\n",
    "def to_cpu(tensor):\n",
    "    return tensor.detach().cpu()\n",
    "\n",
    "\n",
    "def reduce_tensor(tensor, world_size):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    rt /= world_size\n",
    "    return rt\n",
    "\n",
    "\n",
    "def to_python_float(t):\n",
    "    if hasattr(t, 'item'):\n",
    "        return t.item()\n",
    "    else:\n",
    "        return t[0]\n",
    "\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return torch.clamp(x.sigmoid_(), min=1e-4, max=1 - 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6151dbe",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b57747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def make_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    # or os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def get_message(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        return '\\t'.join(entries)\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def time_synchronized():\n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "    return time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c19221",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37f7b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class _LRMomentumScheduler(lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, last_epoch=-1):\n",
    "        if last_epoch == -1:\n",
    "            for group in optimizer.param_groups:\n",
    "                group.setdefault('initial_momentum', group['momentum'])\n",
    "        else:\n",
    "            for i, group in enumerate(optimizer.param_groups):\n",
    "                if 'initial_momentum' not in group:\n",
    "                    raise KeyError(\"param 'initial_momentum' is not specified \"\n",
    "                                   \"in param_groups[{}] when resuming an optimizer\".format(i))\n",
    "        self.base_momentums = list(map(lambda group: group['initial_momentum'], optimizer.param_groups))\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_momentum(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "        self.last_epoch = epoch\n",
    "        for param_group, lr, momentum in zip(self.optimizer.param_groups, self.get_lr(), self.get_momentum()):\n",
    "            param_group['lr'] = lr\n",
    "            param_group['momentum'] = momentum\n",
    "\n",
    "\n",
    "class ParameterUpdate(object):\n",
    "    \"\"\"A callable class used to define an arbitrary schedule defined by a list.\n",
    "    This object is designed to be passed to the LambdaLR or LambdaScheduler scheduler to apply\n",
    "    the given schedule.\n",
    "    Arguments:\n",
    "        params {list or numpy.array} -- List or numpy array defining parameter schedule.\n",
    "        base_param {float} -- Parameter value used to initialize the optimizer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, base_param):\n",
    "        self.params = np.hstack([params, 0])\n",
    "        self.base_param = base_param\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        return self.params[epoch] / self.base_param\n",
    "\n",
    "\n",
    "def apply_lambda(last_epoch, bases, lambdas):\n",
    "    return [base * lmbda(last_epoch) for lmbda, base in zip(lambdas, bases)]\n",
    "\n",
    "\n",
    "class LambdaScheduler(_LRMomentumScheduler):\n",
    "    \"\"\"Sets the learning rate and momentum of each parameter group to the initial lr and momentum\n",
    "    times a given function. When last_epoch=-1, sets initial lr and momentum to the optimizer\n",
    "    values.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        lr_lambda (function or list): A function which computes a multiplicative\n",
    "            factor given an integer parameter epoch, or a list of such\n",
    "            functions, one for each group in optimizer.param_groups.\n",
    "            Default: lambda x:x.\n",
    "        momentum_lambda (function or list): As for lr_lambda but applied to momentum.\n",
    "            Default: lambda x:x.\n",
    "        last_epoch (int): The index of last epoch. Default: -1.\n",
    "    Example:\n",
    "        >>> # Assuming optimizer has two groups.\n",
    "        >>> lr_lambda = [\n",
    "        ...     lambda epoch: epoch // 30,\n",
    "        ...     lambda epoch: 0.95 ** epoch\n",
    "        ... ]\n",
    "        >>> mom_lambda = [\n",
    "        ...     lambda epoch: max(0, (50 - epoch) // 50),\n",
    "        ...     lambda epoch: 0.99 ** epoch\n",
    "        ... ]\n",
    "        >>> scheduler = LambdaScheduler(optimizer, lr_lambda, mom_lambda)\n",
    "        >>> for epoch in range(100):\n",
    "        >>>     train(...)\n",
    "        >>>     validate(...)\n",
    "        >>>     scheduler.step()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, lr_lambda=lambda x: x, momentum_lambda=lambda x: x, last_epoch=-1):\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if not isinstance(lr_lambda, (list, tuple)):\n",
    "            self.lr_lambdas = [lr_lambda] * len(optimizer.param_groups)\n",
    "        else:\n",
    "            if len(lr_lambda) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"Expected {} lr_lambdas, but got {}\".format(\n",
    "                    len(optimizer.param_groups), len(lr_lambda)))\n",
    "            self.lr_lambdas = list(lr_lambda)\n",
    "\n",
    "        if not isinstance(momentum_lambda, (list, tuple)):\n",
    "            self.momentum_lambdas = [momentum_lambda] * len(optimizer.param_groups)\n",
    "        else:\n",
    "            if len(momentum_lambda) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"Expected {} momentum_lambdas, but got {}\".format(\n",
    "                    len(optimizer.param_groups), len(momentum_lambda)))\n",
    "            self.momentum_lambdas = list(momentum_lambda)\n",
    "\n",
    "        self.last_epoch = last_epoch\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the state of the scheduler as a :class:`dict`.\n",
    "        It contains an entry for every variable in self.__dict__ which\n",
    "        is not the optimizer.\n",
    "        The learning rate and momentum lambda functions will only be saved if they are\n",
    "        callable objects and not if they are functions or lambdas.\n",
    "        \"\"\"\n",
    "        state_dict = {key: value for key, value in self.__dict__.items()\n",
    "                      if key not in ('optimizer', 'lr_lambdas', 'momentum_lambdas')}\n",
    "        state_dict['lr_lambdas'] = [None] * len(self.lr_lambdas)\n",
    "        state_dict['momentum_lambdas'] = [None] * len(self.momentum_lambdas)\n",
    "\n",
    "        for idx, (lr_fn, mom_fn) in enumerate(zip(self.lr_lambdas, self.momentum_lambdas)):\n",
    "            if not isinstance(lr_fn, types.FunctionType):\n",
    "                state_dict['lr_lambdas'][idx] = lr_fn.__dict__.copy()\n",
    "            if not isinstance(mom_fn, types.FunctionType):\n",
    "                state_dict['momentum_lambdas'][idx] = mom_fn.__dict__.copy()\n",
    "\n",
    "        return state_dict\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        \"\"\"Loads the schedulers state.\n",
    "        Arguments:\n",
    "            state_dict (dict): scheduler state. Should be an object returned\n",
    "                from a call to :meth:`state_dict`.\n",
    "        \"\"\"\n",
    "        lr_lambdas = state_dict.pop('lr_lambdas')\n",
    "        momentum_lambdas = state_dict.pop('momentum_lambdas')\n",
    "        self.__dict__.update(state_dict)\n",
    "\n",
    "        for idx, fn in enumerate(lr_lambdas):\n",
    "            if fn is not None:\n",
    "                self.lr_lambdas[idx].__dict__.update(fn)\n",
    "\n",
    "        for idx, fn in enumerate(momentum_lambdas):\n",
    "            if fn is not None:\n",
    "                self.momentum_lambdas[idx].__dict__.update(fn)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return apply_lambda(self.last_epoch, self.base_lrs, self.lr_lambdas)\n",
    "\n",
    "    def get_momentum(self):\n",
    "        return apply_lambda(self.last_epoch, self.base_momentums, self.momentum_lambdas)\n",
    "\n",
    "\n",
    "class ParameterUpdate(object):\n",
    "    \"\"\"A callable class used to define an arbitrary schedule defined by a list.\n",
    "    This object is designed to be passed to the LambdaLR or LambdaScheduler scheduler to apply\n",
    "    the given schedule. If a base_param is zero, no updates are applied.\n",
    "    Arguments:\n",
    "        params {list or numpy.array} -- List or numpy array defining parameter schedule.\n",
    "        base_param {float} -- Parameter value used to initialize the optimizer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, base_param):\n",
    "        self.params = np.hstack([params, 0])\n",
    "        self.base_param = base_param\n",
    "\n",
    "        if base_param < 1e-12:\n",
    "            self.base_param = 1\n",
    "            self.params = self.params * 0.0 + 1.0\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        return self.params[epoch] / self.base_param\n",
    "\n",
    "\n",
    "class ListScheduler(LambdaScheduler):\n",
    "    \"\"\"Sets the learning rate and momentum of each parameter group to values defined by lists.\n",
    "    When last_epoch=-1, sets initial lr and momentum to the optimizer values. One of both of lr\n",
    "    and momentum schedules may be specified.\n",
    "    Note that the parameters used to initialize the optimizer are overriden by those defined by\n",
    "    this scheduler.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        lrs (list or numpy.ndarray): A list of learning rates, or a list of lists, one for each\n",
    "            parameter group. One- or two-dimensional numpy arrays may also be passed.\n",
    "        momentum (list or numpy.ndarray): A list of momentums, or a list of lists, one for each\n",
    "            parameter group. One- or two-dimensional numpy arrays may also be passed.\n",
    "        last_epoch (int): The index of last epoch. Default: -1.\n",
    "    Example:\n",
    "        >>> # Assuming optimizer has two groups.\n",
    "        >>> lrs = [\n",
    "        ...     np.linspace(0.01, 0.1, 100),\n",
    "        ...     np.logspace(-2, 0, 100)\n",
    "        ... ]\n",
    "        >>> momentums = [\n",
    "        ...     np.linspace(0.85, 0.95, 100),\n",
    "        ...     np.linspace(0.8, 0.99, 100)\n",
    "        ... ]\n",
    "        >>> scheduler = ListScheduler(optimizer, lrs, momentums)\n",
    "        >>> for epoch in range(100):\n",
    "        >>>     train(...)\n",
    "        >>>     validate(...)\n",
    "        >>>     scheduler.step()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, lrs=None, momentums=None, last_epoch=-1):\n",
    "        groups = optimizer.param_groups\n",
    "        if lrs is None:\n",
    "            lr_lambda = lambda x: x\n",
    "        else:\n",
    "            lrs = np.array(lrs) if isinstance(lrs, (list, tuple)) else lrs\n",
    "            if len(lrs.shape) == 1:\n",
    "                lr_lambda = [ParameterUpdate(lrs, g['lr']) for g in groups]\n",
    "            else:\n",
    "                lr_lambda = [ParameterUpdate(l, g['lr']) for l, g in zip(lrs, groups)]\n",
    "\n",
    "        if momentums is None:\n",
    "            momentum_lambda = lambda x: x\n",
    "        else:\n",
    "            momentums = np.array(momentums) if isinstance(momentums, (list, tuple)) else momentums\n",
    "            if len(momentums.shape) == 1:\n",
    "                momentum_lambda = [ParameterUpdate(momentums, g['momentum']) for g in groups]\n",
    "            else:\n",
    "                momentum_lambda = [ParameterUpdate(l, g['momentum']) for l, g in zip(momentums, groups)]\n",
    "        super().__init__(optimizer, lr_lambda, momentum_lambda)\n",
    "\n",
    "\n",
    "class RangeFinder(ListScheduler):\n",
    "    \"\"\"Scheduler class that implements the LR range search specified in:\n",
    "        A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch\n",
    "        size, momentum, and weight decay. Leslie N. Smith, 2018, arXiv:1803.09820.\n",
    "    Logarithmically spaced learning rates from 1e-7 to 1 are searched. The number of increments in\n",
    "    that range is determined by 'epochs'.\n",
    "    Note that the parameters used to initialize the optimizer are overriden by those defined by\n",
    "    this scheduler.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        epochs (int): Number of epochs over which to run test.\n",
    "    Example:\n",
    "        >>> scheduler = RangeFinder(optimizer, 100)\n",
    "        >>> for epoch in range(100):\n",
    "        >>>     train(...)\n",
    "        >>>     validate(...)\n",
    "        >>>     scheduler.step()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, epochs):\n",
    "        lrs = np.logspace(-7, 0, epochs)\n",
    "        super().__init__(optimizer, lrs)\n",
    "\n",
    "\n",
    "class OneCyclePolicy(ListScheduler):\n",
    "    \"\"\"Scheduler class that implements the 1cycle policy search specified in:\n",
    "        A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch\n",
    "        size, momentum, and weight decay. Leslie N. Smith, 2018, arXiv:1803.09820.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        lr (float or list). Maximum learning rate in range. If a list of values is passed, they\n",
    "            should correspond to parameter groups.\n",
    "        epochs (int): The number of epochs to use during search.\n",
    "        momentum_rng (list). Optional upper and lower momentum values (may be both equal). Set to\n",
    "            None to run without momentum. Default: [0.85, 0.95]. If a list of lists is passed, they\n",
    "            should correspond to parameter groups.\n",
    "        phase_ratio (float): Fraction of epochs used for the increasing and decreasing phase of\n",
    "            the schedule. For example, if phase_ratio=0.45 and epochs=100, the learning rate will\n",
    "            increase from lr/10 to lr over 45 epochs, then decrease back to lr/10 over 45 epochs,\n",
    "            then decrease to lr/100 over the remaining 10 epochs. Default: 0.45.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, lr, epochs, momentum_rng=[0.85, 0.95], phase_ratio=0.45):\n",
    "        phase_epochs = int(phase_ratio * epochs)\n",
    "        if isinstance(lr, (list, tuple)):\n",
    "            lrs = [\n",
    "                np.hstack([\n",
    "                    np.linspace(l * 1e-1, l, phase_epochs),\n",
    "                    np.linspace(l, l * 1e-1, phase_epochs),\n",
    "                    np.linspace(l * 1e-1, l * 1e-2, epochs - 2 * phase_epochs),\n",
    "                ]) for l in lr\n",
    "            ]\n",
    "        else:\n",
    "            lrs = np.hstack([\n",
    "                np.linspace(lr * 1e-1, lr, phase_epochs),\n",
    "                np.linspace(lr, lr * 1e-1, phase_epochs),\n",
    "                np.linspace(lr * 1e-1, lr * 1e-2, epochs - 2 * phase_epochs),\n",
    "            ])\n",
    "\n",
    "        if momentum_rng is not None:\n",
    "            momentum_rng = np.array(momentum_rng)\n",
    "            if len(momentum_rng.shape) == 2:\n",
    "                for i, g in enumerate(optimizer.param_groups):\n",
    "                    g['momentum'] = momentum_rng[i][1]\n",
    "                momentums = [\n",
    "                    np.hstack([\n",
    "                        np.linspace(m[1], m[0], phase_epochs),\n",
    "                        np.linspace(m[0], m[1], phase_epochs),\n",
    "                        np.linspace(m[1], m[1], epochs - 2 * phase_epochs),\n",
    "                    ]) for m in momentum_rng\n",
    "                ]\n",
    "            else:\n",
    "                for i, g in enumerate(optimizer.param_groups):\n",
    "                    g['momentum'] = momentum_rng[1]\n",
    "                momentums = np.hstack([\n",
    "                    np.linspace(momentum_rng[1], momentum_rng[0], phase_epochs),\n",
    "                    np.linspace(momentum_rng[0], momentum_rng[1], phase_epochs),\n",
    "                    np.linspace(momentum_rng[1], momentum_rng[1], epochs - 2 * phase_epochs),\n",
    "                ])\n",
    "        else:\n",
    "            momentums = None\n",
    "\n",
    "        super().__init__(optimizer, lrs, momentums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ae318",
   "metadata": {},
   "source": [
    "## Train Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c7cc956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_optimizer(configs, model):\n",
    "    \"\"\"Create optimizer for training process\n",
    "    \"\"\"\n",
    "    if hasattr(model, 'module'):\n",
    "        train_params = [param for param in model.module.parameters() if param.requires_grad]\n",
    "    else:\n",
    "        train_params = [param for param in model.parameters() if param.requires_grad]\n",
    "\n",
    "    if configs.optimizer_type == 'sgd':\n",
    "        optimizer = torch.optim.SGD(train_params, lr=configs.lr, momentum=configs.momentum, nesterov=True)\n",
    "    elif configs.optimizer_type == 'adam':\n",
    "        optimizer = torch.optim.Adam(train_params, lr=configs.lr, weight_decay=configs.weight_decay)\n",
    "    else:\n",
    "        assert False, \"Unknown optimizer type\"\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def create_lr_scheduler(optimizer, configs):\n",
    "    \"\"\"Create learning rate scheduler for training process\"\"\"\n",
    "\n",
    "    if configs.lr_type == 'multi_step':\n",
    "        def multi_step_scheduler(i):\n",
    "            if i < configs.steps[0]:\n",
    "                factor = 1.\n",
    "            elif i < configs.steps[1]:\n",
    "                factor = 0.1\n",
    "            else:\n",
    "                factor = 0.01\n",
    "\n",
    "            return factor\n",
    "\n",
    "        lr_scheduler = LambdaLR(optimizer, multi_step_scheduler)\n",
    "\n",
    "    elif configs.lr_type == 'cosin':\n",
    "        # Scheduler https://arxiv.org/pdf/1812.01187.pdf\n",
    "        lf = lambda x: (((1 + math.cos(x * math.pi / configs.num_epochs)) / 2) ** 1.0) * 0.9 + 0.1  # cosine\n",
    "        lr_scheduler = LambdaLR(optimizer, lr_lambda=lf)\n",
    "    elif configs.lr_type == 'one_cycle':\n",
    "        lr_scheduler = OneCyclePolicy(optimizer, configs.lr, configs.num_epochs, momentum_rng=[0.85, 0.95],\n",
    "                                      phase_ratio=0.45)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    plot_lr_scheduler(optimizer, lr_scheduler, configs.num_epochs, save_dir=configs.logs_dir, lr_type=configs.lr_type)\n",
    "\n",
    "    return lr_scheduler\n",
    "\n",
    "\n",
    "def get_saved_state(model, optimizer, lr_scheduler, epoch, configs):\n",
    "    \"\"\"Get the information to save with checkpoints\"\"\"\n",
    "    if hasattr(model, 'module'):\n",
    "        model_state_dict = model.module.state_dict()\n",
    "    else:\n",
    "        model_state_dict = model.state_dict()\n",
    "    utils_state_dict = {\n",
    "        'epoch': epoch,\n",
    "        'configs': configs,\n",
    "        'optimizer': copy.deepcopy(optimizer.state_dict()),\n",
    "        'lr_scheduler': copy.deepcopy(lr_scheduler.state_dict())\n",
    "    }\n",
    "\n",
    "    return model_state_dict, utils_state_dict\n",
    "\n",
    "\n",
    "def save_checkpoint(checkpoints_dir, saved_fn, model_state_dict, utils_state_dict, epoch):\n",
    "    \"\"\"Save checkpoint every epoch only is best model or after every checkpoint_freq epoch\"\"\"\n",
    "    model_save_path = os.path.join(checkpoints_dir, 'Model_{}_epoch_{}.pth'.format(saved_fn, epoch))\n",
    "    utils_save_path = os.path.join(checkpoints_dir, 'Utils_{}_epoch_{}.pth'.format(saved_fn, epoch))\n",
    "\n",
    "    torch.save(model_state_dict, model_save_path)\n",
    "    torch.save(utils_state_dict, utils_save_path)\n",
    "\n",
    "    print('save a checkpoint at {}'.format(model_save_path))\n",
    "\n",
    "\n",
    "def plot_lr_scheduler(optimizer, scheduler, num_epochs=300, save_dir='', lr_type=''):\n",
    "    # Plot LR simulating training for full num_epochs\n",
    "    optimizer, scheduler = copy.copy(optimizer), copy.copy(scheduler)  # do not modify originals\n",
    "    y = []\n",
    "    for _ in range(num_epochs):\n",
    "        scheduler.step()\n",
    "        y.append(optimizer.param_groups[0]['lr'])\n",
    "    plt.plot(y, '.-', label='LR')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('LR')\n",
    "    plt.grid()\n",
    "    plt.xlim(0, num_epochs)\n",
    "    plt.ylim(0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'LR_{}.png'.format(lr_type)), dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f3192",
   "metadata": {},
   "source": [
    "## Evaluation Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5da94373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "def _nms(heat, kernel=3):\n",
    "    pad = (kernel - 1) // 2\n",
    "    hmax = F.max_pool2d(heat, (kernel, kernel), stride=1, padding=pad)\n",
    "    keep = (hmax == heat).float()\n",
    "\n",
    "    return heat * keep\n",
    "\n",
    "\n",
    "def _gather_feat(feat, ind, mask=None):\n",
    "    dim = feat.size(2)\n",
    "    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n",
    "    feat = feat.gather(1, ind)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(2).expand_as(feat)\n",
    "        feat = feat[mask]\n",
    "        feat = feat.view(-1, dim)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def _transpose_and_gather_feat(feat, ind):\n",
    "    feat = feat.permute(0, 2, 3, 1).contiguous()\n",
    "    feat = feat.view(feat.size(0), -1, feat.size(3))\n",
    "    feat = _gather_feat(feat, ind)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def _topk(scores, K=40):\n",
    "    batch, cat, height, width = scores.size()\n",
    "\n",
    "    topk_scores, topk_inds = torch.topk(scores.view(batch, cat, -1), K)\n",
    "\n",
    "    topk_inds = topk_inds % (height * width)\n",
    "    topk_ys = (torch.floor_divide(topk_inds, width)).float()\n",
    "    topk_xs = (topk_inds % width).int().float()\n",
    "\n",
    "    topk_score, topk_ind = torch.topk(topk_scores.view(batch, -1), K)\n",
    "    topk_clses = (torch.floor_divide(topk_ind, K)).int()\n",
    "    topk_inds = _gather_feat(topk_inds.view(batch, -1, 1), topk_ind).view(batch, K)\n",
    "    topk_ys = _gather_feat(topk_ys.view(batch, -1, 1), topk_ind).view(batch, K)\n",
    "    topk_xs = _gather_feat(topk_xs.view(batch, -1, 1), topk_ind).view(batch, K)\n",
    "\n",
    "    return topk_score, topk_inds, topk_clses, topk_ys, topk_xs\n",
    "\n",
    "\n",
    "def _topk_channel(scores, K=40):\n",
    "    batch, cat, height, width = scores.size()\n",
    "\n",
    "    topk_scores, topk_inds = torch.topk(scores.view(batch, cat, -1), K)\n",
    "\n",
    "    topk_inds = topk_inds % (height * width)\n",
    "    topk_ys = (topk_inds / width).int().float()\n",
    "    topk_xs = (topk_inds % width).int().float()\n",
    "\n",
    "    return topk_scores, topk_inds, topk_ys, topk_xs\n",
    "\n",
    "\n",
    "def decode(hm_cen, cen_offset, direction, z_coor, dim, K=40):\n",
    "    batch_size, num_classes, height, width = hm_cen.size()\n",
    "\n",
    "    hm_cen = _nms(hm_cen)\n",
    "    scores, inds, clses, ys, xs = _topk(hm_cen, K=K)\n",
    "    if cen_offset is not None:\n",
    "        cen_offset = _transpose_and_gather_feat(cen_offset, inds)\n",
    "        cen_offset = cen_offset.view(batch_size, K, 2)\n",
    "        xs = xs.view(batch_size, K, 1) + cen_offset[:, :, 0:1]\n",
    "        ys = ys.view(batch_size, K, 1) + cen_offset[:, :, 1:2]\n",
    "    else:\n",
    "        xs = xs.view(batch_size, K, 1) + 0.5\n",
    "        ys = ys.view(batch_size, K, 1) + 0.5\n",
    "\n",
    "    direction = _transpose_and_gather_feat(direction, inds)\n",
    "    direction = direction.view(batch_size, K, 2)\n",
    "    z_coor = _transpose_and_gather_feat(z_coor, inds)\n",
    "    z_coor = z_coor.view(batch_size, K, 1)\n",
    "    dim = _transpose_and_gather_feat(dim, inds)\n",
    "    dim = dim.view(batch_size, K, 3)\n",
    "    clses = clses.view(batch_size, K, 1).float()\n",
    "    scores = scores.view(batch_size, K, 1)\n",
    "\n",
    "    # (scores x 1, ys x 1, xs x 1, z_coor x 1, dim x 3, direction x 2, clses x 1)\n",
    "    # (scores-0:1, ys-1:2, xs-2:3, z_coor-3:4, dim-4:7, direction-7:9, clses-9:10)\n",
    "    # detections: [batch_size, K, 10]\n",
    "    detections = torch.cat([scores, xs, ys, z_coor, dim, direction, clses], dim=2)\n",
    "\n",
    "    return detections\n",
    "\n",
    "\n",
    "def get_yaw(direction):\n",
    "    return np.arctan2(direction[:, 0:1], direction[:, 1:2])\n",
    "\n",
    "\n",
    "def post_processing(detections, num_classes=3, down_ratio=4, peak_thresh=0.2):\n",
    "    \"\"\"\n",
    "    :param detections: [batch_size, K, 10]\n",
    "    # (scores x 1, xs x 1, ys x 1, z_coor x 1, dim x 3, direction x 2, clses x 1)\n",
    "    # (scores-0:1, xs-1:2, ys-2:3, z_coor-3:4, dim-4:7, direction-7:9, clses-9:10)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TODO: Need to consider rescale to the original scale: x, y\n",
    "\n",
    "    ret = []\n",
    "    for i in range(detections.shape[0]):\n",
    "        top_preds = {}\n",
    "        classes = detections[i, :, -1]\n",
    "        for j in range(num_classes):\n",
    "            inds = (classes == j)\n",
    "            # x, y, z, h, w, l, yaw\n",
    "            top_preds[j] = np.concatenate([\n",
    "                detections[i, inds, 0:1],\n",
    "                detections[i, inds, 1:2] * down_ratio,\n",
    "                detections[i, inds, 2:3] * down_ratio,\n",
    "                detections[i, inds, 3:4],\n",
    "                detections[i, inds, 4:5],\n",
    "                detections[i, inds, 5:6] / bound_size_y * BEV_WIDTH,\n",
    "                detections[i, inds, 6:7] / bound_size_x * BEV_HEIGHT,\n",
    "                get_yaw(detections[i, inds, 7:9]).astype(np.float32)], axis=1)\n",
    "            # Filter by peak_thresh\n",
    "            if len(top_preds[j]) > 0:\n",
    "                keep_inds = (top_preds[j][:, 0] > peak_thresh)\n",
    "                top_preds[j] = top_preds[j][keep_inds]\n",
    "        ret.append(top_preds)\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def draw_predictions(img, detections, num_classes=3):\n",
    "    for j in range(num_classes):\n",
    "        if len(detections[j]) > 0:\n",
    "            for det in detections[j]:\n",
    "                # (scores-0:1, x-1:2, y-2:3, z-3:4, dim-4:7, yaw-7:8)\n",
    "                _score, _x, _y, _z, _h, _w, _l, _yaw = det\n",
    "                drawRotatedBox(img, _x, _y, _w, _l, _yaw, colors[int(j)])\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def convert_det_to_real_values(detections, num_classes=3):\n",
    "    kitti_dets = []\n",
    "    for cls_id in range(num_classes):\n",
    "        if len(detections[cls_id]) > 0:\n",
    "            for det in detections[cls_id]:\n",
    "                # (scores-0:1, x-1:2, y-2:3, z-3:4, dim-4:7, yaw-7:8)\n",
    "                _score, _x, _y, _z, _h, _w, _l, _yaw = det\n",
    "                _yaw = -_yaw\n",
    "                x = _y / BEV_HEIGHT * bound_size_x + boundary['minX']\n",
    "                y = _x / BEV_WIDTH * bound_size_y + boundary['minY']\n",
    "                z = _z + boundary['minZ']\n",
    "                w = _w / BEV_WIDTH * bound_size_y\n",
    "                l = _l / BEV_HEIGHT * bound_size_x\n",
    "\n",
    "                kitti_dets.append([cls_id, x, y, z, _h, w, l, _yaw])\n",
    "\n",
    "    return np.array(kitti_dets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032bb430",
   "metadata": {},
   "source": [
    " ## Visualization Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f32c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def roty(angle):\n",
    "    # Rotation about the y-axis.\n",
    "    c = np.cos(angle)\n",
    "    s = np.sin(angle)\n",
    "    return np.array([[c, 0, s],\n",
    "                     [0, 1, 0],\n",
    "                     [-s, 0, c]])\n",
    "\n",
    "\n",
    "def compute_box_3d(dim, location, ry):\n",
    "    # dim: 3\n",
    "    # location: 3\n",
    "    # ry: 1\n",
    "    # return: 8 x 3\n",
    "    R = roty(ry)\n",
    "    h, w, l = dim\n",
    "    x_corners = [l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2]\n",
    "    y_corners = [0, 0, 0, 0, -h, -h, -h, -h]\n",
    "    z_corners = [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2]\n",
    "\n",
    "    corners = np.array([x_corners, y_corners, z_corners], dtype=np.float32)\n",
    "    corners_3d = np.dot(R, corners)\n",
    "    corners_3d = corners_3d + np.array(location, dtype=np.float32).reshape(3, 1)\n",
    "    return corners_3d.transpose(1, 0)\n",
    "\n",
    "\n",
    "def project_to_image(pts_3d, P):\n",
    "    # pts_3d: n x 3\n",
    "    # P: 3 x 4\n",
    "    # return: n x 2\n",
    "    pts_3d_homo = np.concatenate([pts_3d, np.ones((pts_3d.shape[0], 1), dtype=np.float32)], axis=1)\n",
    "    pts_2d = np.dot(P, pts_3d_homo.transpose(1, 0)).transpose(1, 0)\n",
    "    pts_2d = pts_2d[:, :2] / pts_2d[:, 2:]\n",
    "\n",
    "    return pts_2d.astype(np.int)\n",
    "\n",
    "\n",
    "def draw_box_3d_v2(image, qs, color=(255, 0, 255), thickness=2):\n",
    "    ''' Draw 3d bounding box in image\n",
    "        qs: (8,3) array of vertices for the 3d box in following order:\n",
    "            1 -------- 0\n",
    "           /|         /|\n",
    "          2 -------- 3 .\n",
    "          | |        | |\n",
    "          . 5 -------- 4\n",
    "          |/         |/\n",
    "          6 -------- 7\n",
    "    '''\n",
    "    qs = qs.astype(np.int32)\n",
    "    for k in range(0, 4):\n",
    "        # Ref: http://docs.enthought.com/mayavi/mayavi/auto/mlab_helper_functions.html\n",
    "        i, j = k, (k + 1) % 4\n",
    "        # use LINE_AA for opencv3\n",
    "        cv2.line(image, (qs[i, 0], qs[i, 1]), (qs[j, 0], qs[j, 1]), color, thickness)\n",
    "\n",
    "        i, j = k + 4, (k + 1) % 4 + 4\n",
    "        cv2.line(image, (qs[i, 0], qs[i, 1]), (qs[j, 0], qs[j, 1]), color, thickness)\n",
    "\n",
    "        i, j = k, k + 4\n",
    "        cv2.line(image, (qs[i, 0], qs[i, 1]), (qs[j, 0], qs[j, 1]), color, thickness)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_box_3d(image, corners, color=(0, 0, 255)):\n",
    "    ''' Draw 3d bounding box in image\n",
    "        corners: (8,3) array of vertices for the 3d box in following order:\n",
    "            1 -------- 0\n",
    "           /|         /|\n",
    "          2 -------- 3 .\n",
    "          | |        | |\n",
    "          . 5 -------- 4\n",
    "          |/         |/\n",
    "          6 -------- 7\n",
    "    '''\n",
    "\n",
    "    face_idx = [[0, 1, 5, 4],\n",
    "                [1, 2, 6, 5],\n",
    "                [2, 3, 7, 6],\n",
    "                [3, 0, 4, 7]]\n",
    "    for ind_f in range(3, -1, -1):\n",
    "        f = face_idx[ind_f]\n",
    "        for j in range(4):\n",
    "            cv2.line(image, (corners[f[j], 0], corners[f[j], 1]),\n",
    "                     (corners[f[(j + 1) % 4], 0], corners[f[(j + 1) % 4], 1]), color, 2, lineType=cv2.LINE_AA)\n",
    "        if ind_f == 0:\n",
    "            cv2.line(image, (corners[f[0], 0], corners[f[0], 1]),\n",
    "                     (corners[f[2], 0], corners[f[2], 1]), color, 1, lineType=cv2.LINE_AA)\n",
    "            cv2.line(image, (corners[f[1], 0], corners[f[1], 1]),\n",
    "                     (corners[f[3], 0], corners[f[3], 1]), color, 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def show_rgb_image_with_boxes(img, labels, calib):\n",
    "    for box_idx, label in enumerate(labels):\n",
    "        cls_id, location, dim, ry = label[0], label[1:4], label[4:7], label[7]\n",
    "        if location[2] < 2.0:  # The object is too close to the camera, ignore it during visualization\n",
    "            continue\n",
    "        if cls_id < 0:\n",
    "            continue\n",
    "        corners_3d = compute_box_3d(dim, location, ry)\n",
    "        corners_2d = project_to_image(corners_3d, calib.P2)\n",
    "        img = draw_box_3d(img, corners_2d, color=colors[int(cls_id)])\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def merge_rgb_to_bev(img_rgb, img_bev, output_width):\n",
    "    img_rgb_h, img_rgb_w = img_rgb.shape[:2]\n",
    "    ratio_rgb = output_width / img_rgb_w\n",
    "    output_rgb_h = int(ratio_rgb * img_rgb_h)\n",
    "    ret_img_rgb = cv2.resize(img_rgb, (output_width, output_rgb_h))\n",
    "\n",
    "    img_bev_h, img_bev_w = img_bev.shape[:2]\n",
    "    ratio_bev = output_width / img_bev_w\n",
    "    output_bev_h = int(ratio_bev * img_bev_h)\n",
    "\n",
    "    ret_img_bev = cv2.resize(img_bev, (output_width, output_bev_h))\n",
    "\n",
    "    out_img = np.zeros((output_rgb_h + output_bev_h, output_width, 3), dtype=np.uint8)\n",
    "    # Upper: RGB --> BEV\n",
    "    out_img[:output_rgb_h, ...] = ret_img_rgb\n",
    "    out_img[output_rgb_h:, ...] = ret_img_bev\n",
    "\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50479e67",
   "metadata": {},
   "source": [
    "## Demo Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a7ee89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from builtins import int\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "\n",
    "class Demo_KittiDataset(Dataset):\n",
    "    def __init__(self, configs):\n",
    "        self.dataset_dir = os.path.join(configs.dataset_dir, configs.foldername, configs.foldername[:10],\n",
    "                                        configs.foldername)\n",
    "        self.input_size = configs.input_size\n",
    "        self.hm_size = configs.hm_size\n",
    "\n",
    "        self.num_classes = configs.num_classes\n",
    "        self.max_objects = configs.max_objects\n",
    "\n",
    "        self.image_dir = os.path.join(self.dataset_dir, \"image_02\", \"data\")\n",
    "        self.lidar_dir = os.path.join(self.dataset_dir, \"velodyne_points\", \"data\")\n",
    "        self.label_dir = os.path.join(self.dataset_dir, \"label_2\", \"data\")\n",
    "        self.sample_id_list = sorted(glob(os.path.join(self.lidar_dir, '*.bin')))\n",
    "        self.sample_id_list = [float(os.path.basename(fn)[:-4]) for fn in self.sample_id_list]\n",
    "        self.num_samples = len(self.sample_id_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_id_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pass\n",
    "\n",
    "    def load_bevmap_front(self, index):\n",
    "        \"\"\"Load only image for the testing phase\"\"\"\n",
    "        sample_id = int(self.sample_id_list[index])\n",
    "        img_path, img_rgb = self.get_image(sample_id)\n",
    "        lidarData = self.get_lidar(sample_id)\n",
    "        front_lidar = get_filtered_lidar(lidarData, boundary)\n",
    "        front_bevmap = makeBEVMap(front_lidar, boundary)\n",
    "        front_bevmap = torch.from_numpy(front_bevmap)\n",
    "\n",
    "        metadatas = {\n",
    "            'img_path': img_path,\n",
    "        }\n",
    "\n",
    "        return metadatas, front_bevmap, img_rgb\n",
    "\n",
    "    def load_bevmap_front_vs_back(self, index):\n",
    "        \"\"\"Load only image for the testing phase\"\"\"\n",
    "        sample_id = int(self.sample_id_list[index])\n",
    "        img_path, img_rgb = self.get_image(sample_id)\n",
    "        lidarData = self.get_lidar(sample_id)\n",
    "\n",
    "        front_lidar = get_filtered_lidar(lidarData, boundary)\n",
    "        front_bevmap = makeBEVMap(front_lidar, boundary)\n",
    "        front_bevmap = torch.from_numpy(front_bevmap)\n",
    "\n",
    "        back_lidar = get_filtered_lidar(lidarData, boundary_back)\n",
    "        back_bevmap = makeBEVMap(back_lidar, boundary_back)\n",
    "        back_bevmap = torch.from_numpy(back_bevmap)\n",
    "\n",
    "        metadatas = {\n",
    "            'img_path': img_path,\n",
    "        }\n",
    "\n",
    "        return metadatas, front_bevmap, back_bevmap, img_rgb\n",
    "\n",
    "    def get_image(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, '{:010d}.png'.format(idx))\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        return img_path, img\n",
    "\n",
    "    def get_lidar(self, idx):\n",
    "        lidar_file = os.path.join(self.lidar_dir, '{:010d}.bin'.format(idx))\n",
    "        # assert os.path.isfile(lidar_file)\n",
    "        return np.fromfile(lidar_file, dtype=np.float32).reshape(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a36d40e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.2)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diya\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diya\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diya\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diya\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diya\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diya\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n",
      "--2023-11-21 16:20:15--  https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/demo/calib.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1616 (1.6K) [text/plain]\n",
      "Saving to: './dataset/kitti/demo/calib.txt'\n",
      "\n",
      "     0K .                                                     100%  217K=0.007s\n",
      "\n",
      "2023-11-21 16:20:16 (217 KB/s) - './dataset/kitti/demo/calib.txt' saved [1616/1616]\n",
      "\n",
      "--2023-11-21 16:20:16--  https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/test.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 52626 (51K) [text/plain]\n",
      "Saving to: './dataset/kitti/ImageSets/test.txt'\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 97%  416K 0s\n",
      "    50K .                                                     100% 6.51M=0.1s\n",
      "\n",
      "2023-11-21 16:20:17 (427 KB/s) - './dataset/kitti/ImageSets/test.txt' saved [52626/52626]\n",
      "\n",
      "--2023-11-21 16:20:17--  https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/train.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42000 (41K) [text/plain]\n",
      "Saving to: './dataset/kitti/ImageSets/train.txt'\n",
      "\n",
      "     0K .......... .......... .......... .......... .         100%  360K=0.1s\n",
      "\n",
      "2023-11-21 16:20:18 (360 KB/s) - './dataset/kitti/ImageSets/train.txt' saved [42000/42000]\n",
      "\n",
      "--2023-11-21 16:20:18--  https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/trainval.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 52367 (51K) [text/plain]\n",
      "Saving to: './dataset/kitti/ImageSets/trainval.txt'\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 97% 3.63M 0s\n",
      "    50K .                                                     100% 14.3M=0.01s\n",
      "\n",
      "2023-11-21 16:20:18 (3.69 MB/s) - './dataset/kitti/ImageSets/trainval.txt' saved [52367/52367]\n",
      "\n",
      "--2023-11-21 16:20:18--  https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/val.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10367 (10K) [text/plain]\n",
      "Saving to: './dataset/kitti/ImageSets/val.txt'\n",
      "\n",
      "     0K ..........                                            100% 1.34M=0.007s\n",
      "\n",
      "2023-11-21 16:20:19 (1.34 MB/s) - './dataset/kitti/ImageSets/val.txt' saved [10367/10367]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "!mkdir -p ./dataset/kitti/demo\n",
    "!mkdir -p ./dataset/kitti/ImageSets\n",
    "\n",
    "!wget https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/demo/calib.txt -P ./dataset/kitti/demo/\n",
    "!wget https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/test.txt -P ./dataset/kitti/ImageSets/\n",
    "!wget https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/train.txt -P ./dataset/kitti/ImageSets/\n",
    "!wget https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/trainval.txt -P ./dataset/kitti/ImageSets/\n",
    "!wget https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/val.txt -P ./dataset/kitti/ImageSets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b083d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "import numpy as np\n",
    "import wget\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "\n",
    "def parse_demo_configs():\n",
    "    config_dict = {}\n",
    "    config_dict['saved_fn'] = 'fpn_resnet_18'\n",
    "    config_dict['arch'] = 'fpn_resnet_18'\n",
    "    config_dict['pretrained_path'] = './checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth'\n",
    "    config_dict['foldername'] = '2011_09_26_drive_0014_sync'\n",
    "    config_dict['K'] = 50\n",
    "    config_dict['gpu_idx'] = 0\n",
    "    config_dict['peak_thresh'] = 0.2\n",
    "    config_dict['output_width'] = 608\n",
    "    config_dict['no_cuda'] = False\n",
    "\n",
    "    configs = edict(config_dict)\n",
    "    configs.pin_memory = True\n",
    "    configs.distributed = False  # For testing on 1 GPU only\n",
    "\n",
    "    configs.input_size = (608, 608)\n",
    "    configs.hm_size = (152, 152)\n",
    "    configs.down_ratio = 4\n",
    "    configs.max_objects = 50\n",
    "\n",
    "    configs.imagenet_pretrained = False\n",
    "    configs.head_conv = 64\n",
    "    configs.num_classes = 3\n",
    "    configs.num_center_offset = 2\n",
    "    configs.num_z = 1\n",
    "    configs.num_dim = 3\n",
    "    configs.num_direction = 2  # sin, cos\n",
    "\n",
    "    configs.heads = {\n",
    "        'hm_cen': configs.num_classes,\n",
    "        'cen_offset': configs.num_center_offset,\n",
    "        'direction': configs.num_direction,\n",
    "        'z_coor': configs.num_z,\n",
    "        'dim': configs.num_dim\n",
    "    }\n",
    "\n",
    "    ####################################################################\n",
    "    ##############Dataset, Checkpoints, and results dir configs#########\n",
    "    ####################################################################\n",
    "    configs.root_dir = './'\n",
    "    configs.dataset_dir = os.path.join(configs.root_dir, 'dataset', 'kitti', 'demo')\n",
    "    configs.calib_path = os.path.join(configs.root_dir, 'dataset', 'kitti', 'demo', 'calib.txt')\n",
    "    configs.results_dir = os.path.join(configs.root_dir, 'results', configs.saved_fn)\n",
    "    make_folder(configs.results_dir)\n",
    "\n",
    "    return configs\n",
    "\n",
    "\n",
    "def download_and_unzip(demo_dataset_dir, download_url):\n",
    "    filename = download_url.split('/')[-1]\n",
    "    filepath = os.path.join(demo_dataset_dir, filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        print('The dataset have been downloaded')\n",
    "        return\n",
    "    print('\\nDownloading data for demonstration...')\n",
    "    wget.download(download_url, filepath)\n",
    "    print('\\nUnzipping the downloaded data...')\n",
    "    with zipfile.ZipFile(filepath, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(os.path.join(demo_dataset_dir, filename[:-4]))\n",
    "\n",
    "\n",
    "def do_detect(configs, model, bevmap, is_front):\n",
    "    if not is_front:\n",
    "        bevmap = torch.flip(bevmap, [1, 2])\n",
    "\n",
    "    input_bev_maps = bevmap.unsqueeze(0).to(configs.device, non_blocking=True).float()\n",
    "    t1 = time_synchronized()\n",
    "    outputs = model(input_bev_maps)\n",
    "    outputs['hm_cen'] = _sigmoid(outputs['hm_cen'])\n",
    "    outputs['cen_offset'] = _sigmoid(outputs['cen_offset'])\n",
    "    # detections size (batch_size, K, 10)\n",
    "    detections = decode(outputs['hm_cen'], outputs['cen_offset'], outputs['direction'], outputs['z_coor'],\n",
    "                        outputs['dim'], K=configs.K)\n",
    "    detections = detections.cpu().numpy().astype(np.float32)\n",
    "    detections = post_processing(detections, configs.num_classes, configs.down_ratio, configs.peak_thresh)\n",
    "    t2 = time_synchronized()\n",
    "    # Inference speed\n",
    "    fps = 1 / (t2 - t1)\n",
    "\n",
    "    return detections[0], bevmap, fps\n",
    "\n",
    "\n",
    "def write_credit(img, org_author=(500, 400), text_author='github.com/maudzung', org_fps=(50, 1000), fps=None):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 1\n",
    "    color = (255, 255, 255)\n",
    "    thickness = 2\n",
    "\n",
    "    cv2.putText(img, text_author, org_author, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "    cv2.putText(img, 'Speed: {:.1f} FPS'.format(fps), org_fps, font, fontScale, color, thickness, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449eb76b",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d35b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def _gather_feat(feat, ind, mask=None):\n",
    "    dim = feat.size(2)\n",
    "    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n",
    "    feat = feat.gather(1, ind)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(2).expand_as(feat)\n",
    "        feat = feat[mask]\n",
    "        feat = feat.view(-1, dim)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def _transpose_and_gather_feat(feat, ind):\n",
    "    feat = feat.permute(0, 2, 3, 1).contiguous()\n",
    "    feat = feat.view(feat.size(0), -1, feat.size(3))\n",
    "    feat = _gather_feat(feat, ind)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def _neg_loss(pred, gt, alpha=2, beta=4):\n",
    "    ''' Modified focal loss. Exactly the same as CornerNet.\n",
    "        Runs faster and costs a little bit more memory\n",
    "      Arguments:\n",
    "        pred (batch x c x h x w)\n",
    "        gt_regr (batch x c x h x w)\n",
    "    '''\n",
    "    pos_inds = gt.eq(1).float()\n",
    "    neg_inds = gt.lt(1).float()\n",
    "\n",
    "    neg_weights = torch.pow(1 - gt, beta)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    pos_loss = torch.log(pred) * torch.pow(1 - pred, alpha) * pos_inds\n",
    "    neg_loss = torch.log(1 - pred) * torch.pow(pred, alpha) * neg_weights * neg_inds\n",
    "\n",
    "    num_pos = pos_inds.float().sum()\n",
    "    pos_loss = pos_loss.sum()\n",
    "    neg_loss = neg_loss.sum()\n",
    "\n",
    "    if num_pos == 0:\n",
    "        loss = loss - neg_loss\n",
    "    else:\n",
    "        loss = loss - (pos_loss + neg_loss) / num_pos\n",
    "    return loss\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    '''nn.Module warpper for focal loss'''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.neg_loss = _neg_loss\n",
    "\n",
    "    def forward(self, out, target):\n",
    "        return self.neg_loss(out, target)\n",
    "\n",
    "\n",
    "class L1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L1Loss, self).__init__()\n",
    "\n",
    "    def forward(self, output, mask, ind, target):\n",
    "        pred = _transpose_and_gather_feat(output, ind)\n",
    "        mask = mask.unsqueeze(2).expand_as(pred).float()\n",
    "        loss = F.l1_loss(pred * mask, target * mask, size_average=False)\n",
    "        loss = loss / (mask.sum() + 1e-4)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class L1Loss_Balanced(nn.Module):\n",
    "    \"\"\"Balanced L1 Loss\n",
    "    paper: https://arxiv.org/pdf/1904.02701.pdf (CVPR 2019)\n",
    "    Code refer from: https://github.com/OceanPang/Libra_R-CNN\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=0.5, gamma=1.5, beta=1.0):\n",
    "        super(L1Loss_Balanced, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        assert beta > 0\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, output, mask, ind, target):\n",
    "        pred = _transpose_and_gather_feat(output, ind)\n",
    "        mask = mask.unsqueeze(2).expand_as(pred).float()\n",
    "        loss = self.balanced_l1_loss(pred * mask, target * mask)\n",
    "        loss = loss.sum() / (mask.sum() + 1e-4)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def balanced_l1_loss(self, pred, target):\n",
    "        assert pred.size() == target.size() and target.numel() > 0\n",
    "\n",
    "        diff = torch.abs(pred - target)\n",
    "        b = math.exp(self.gamma / self.alpha) - 1\n",
    "        loss = torch.where(diff < self.beta,\n",
    "                           self.alpha / b * (b * diff + 1) * torch.log(b * diff / self.beta + 1) - self.alpha * diff,\n",
    "                           self.gamma * diff + self.gamma / b - self.alpha * self.beta)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class Compute_Loss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(Compute_Loss, self).__init__()\n",
    "        self.device = device\n",
    "        self.focal_loss = FocalLoss()\n",
    "        self.l1_loss = L1Loss()\n",
    "        self.l1_loss_balanced = L1Loss_Balanced(alpha=0.5, gamma=1.5, beta=1.0)\n",
    "        self.weight_hm_cen = 1.\n",
    "        self.weight_z_coor, self.weight_cenoff, self.weight_dim, self.weight_direction = 1., 1., 1., 1.\n",
    "\n",
    "    def forward(self, outputs, tg):\n",
    "        # tg: targets\n",
    "        outputs['hm_cen'] = _sigmoid(outputs['hm_cen'])\n",
    "        outputs['cen_offset'] = _sigmoid(outputs['cen_offset'])\n",
    "\n",
    "        l_hm_cen = self.focal_loss(outputs['hm_cen'], tg['hm_cen'])\n",
    "        l_cen_offset = self.l1_loss(outputs['cen_offset'], tg['obj_mask'], tg['indices_center'], tg['cen_offset'])\n",
    "        l_direction = self.l1_loss(outputs['direction'], tg['obj_mask'], tg['indices_center'], tg['direction'])\n",
    "        # Apply the L1_loss balanced for z coor and dimension regression\n",
    "        l_z_coor = self.l1_loss_balanced(outputs['z_coor'], tg['obj_mask'], tg['indices_center'], tg['z_coor'])\n",
    "        l_dim = self.l1_loss_balanced(outputs['dim'], tg['obj_mask'], tg['indices_center'], tg['dim'])\n",
    "\n",
    "        total_loss = l_hm_cen * self.weight_hm_cen + l_cen_offset * self.weight_cenoff + \\\n",
    "                     l_dim * self.weight_dim + l_direction * self.weight_direction + \\\n",
    "                     l_z_coor * self.weight_z_coor\n",
    "\n",
    "        loss_stats = {\n",
    "            'total_loss': to_cpu(total_loss).item(),\n",
    "            'hm_cen_loss': to_cpu(l_hm_cen).item(),\n",
    "            'cen_offset_loss': to_cpu(l_cen_offset).item(),\n",
    "            'dim_loss': to_cpu(l_dim).item(),\n",
    "            'direction_loss': to_cpu(l_direction).item(),\n",
    "            'z_coor_loss': to_cpu(l_z_coor).item(),\n",
    "        }\n",
    "\n",
    "        return total_loss, loss_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb050d51",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ef163",
   "metadata": {},
   "source": [
    "## FPN ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa2e192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BN_MOMENTUM = 0.1\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class PoseResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, heads, head_conv, **kwargs):\n",
    "        self.inplanes = 64\n",
    "        self.deconv_with_bias = False\n",
    "        self.heads = heads\n",
    "\n",
    "        super(PoseResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.conv_up_level1 = nn.Conv2d(768, 256, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_up_level2 = nn.Conv2d(384, 128, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_up_level3 = nn.Conv2d(192, 64, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        fpn_channels = [256, 128, 64]\n",
    "        for fpn_idx, fpn_c in enumerate(fpn_channels):\n",
    "            for head in sorted(self.heads):\n",
    "                num_output = self.heads[head]\n",
    "                if head_conv > 0:\n",
    "                    fc = nn.Sequential(\n",
    "                        nn.Conv2d(fpn_c, head_conv, kernel_size=3, padding=1, bias=True),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(head_conv, num_output, kernel_size=1, stride=1, padding=0))\n",
    "                else:\n",
    "                    fc = nn.Conv2d(in_channels=fpn_c, out_channels=num_output, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "                self.__setattr__('fpn{}_{}'.format(fpn_idx, head), fc)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, _, input_h, input_w = x.size()\n",
    "        hm_h, hm_w = input_h // 4, input_w // 4\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        out_layer1 = self.layer1(x)\n",
    "        out_layer2 = self.layer2(out_layer1)\n",
    "\n",
    "        out_layer3 = self.layer3(out_layer2)\n",
    "\n",
    "        out_layer4 = self.layer4(out_layer3)\n",
    "\n",
    "        # up_level1: torch.Size([b, 512, 14, 14])\n",
    "        up_level1 = F.interpolate(out_layer4, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        concat_level1 = torch.cat((up_level1, out_layer3), dim=1)\n",
    "        # up_level2: torch.Size([b, 256, 28, 28])\n",
    "        up_level2 = F.interpolate(self.conv_up_level1(concat_level1), scale_factor=2, mode='bilinear',\n",
    "                                  align_corners=True)\n",
    "\n",
    "        concat_level2 = torch.cat((up_level2, out_layer2), dim=1)\n",
    "        # up_level3: torch.Size([b, 128, 56, 56]),\n",
    "        up_level3 = F.interpolate(self.conv_up_level2(concat_level2), scale_factor=2, mode='bilinear',\n",
    "                                  align_corners=True)\n",
    "        # up_level4: torch.Size([b, 64, 56, 56])\n",
    "        up_level4 = self.conv_up_level3(torch.cat((up_level3, out_layer1), dim=1))\n",
    "\n",
    "        ret = {}\n",
    "        for head in self.heads:\n",
    "            temp_outs = []\n",
    "            for fpn_idx, fdn_input in enumerate([up_level2, up_level3, up_level4]):\n",
    "                fpn_out = self.__getattr__('fpn{}_{}'.format(fpn_idx, head))(fdn_input)\n",
    "                _, _, fpn_out_h, fpn_out_w = fpn_out.size()\n",
    "                # Make sure the added features having same size of heatmap output\n",
    "                if (fpn_out_w != hm_w) or (fpn_out_h != hm_h):\n",
    "                    fpn_out = F.interpolate(fpn_out, size=(hm_h, hm_w))\n",
    "                temp_outs.append(fpn_out)\n",
    "            # Take the softmax in the keypoint feature pyramid network\n",
    "            final_out = self.apply_kfpn(temp_outs)\n",
    "\n",
    "            ret[head] = final_out\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def apply_kfpn(self, outs):\n",
    "        outs = torch.cat([out.unsqueeze(-1) for out in outs], dim=-1)\n",
    "        softmax_outs = F.softmax(outs, dim=-1)\n",
    "        ret_outs = (outs * softmax_outs).sum(dim=-1)\n",
    "        return ret_outs\n",
    "\n",
    "    def init_weights(self, num_layers, pretrained=True):\n",
    "        if pretrained:\n",
    "            # TODO: Check initial weights for head later\n",
    "            for fpn_idx in [0, 1, 2]:  # 3 FPN layers\n",
    "                for head in self.heads:\n",
    "                    final_layer = self.__getattr__('fpn{}_{}'.format(fpn_idx, head))\n",
    "                    for i, m in enumerate(final_layer.modules()):\n",
    "                        if isinstance(m, nn.Conv2d):\n",
    "                            # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                            # print('=> init {}.weight as normal(0, 0.001)'.format(name))\n",
    "                            # print('=> init {}.bias as 0'.format(name))\n",
    "                            if m.weight.shape[0] == self.heads[head]:\n",
    "                                if 'hm' in head:\n",
    "                                    nn.init.constant_(m.bias, -2.19)\n",
    "                                else:\n",
    "                                    nn.init.normal_(m.weight, std=0.001)\n",
    "                                    nn.init.constant_(m.bias, 0)\n",
    "            # pretrained_state_dict = torch.load(pretrained)\n",
    "            url = model_urls['resnet{}'.format(num_layers)]\n",
    "            pretrained_state_dict = model_zoo.load_url(url)\n",
    "            print('=> loading pretrained model {}'.format(url))\n",
    "            self.load_state_dict(pretrained_state_dict, strict=False)\n",
    "\n",
    "\n",
    "resnet_spec = {18: (BasicBlock, [2, 2, 2, 2]),\n",
    "               34: (BasicBlock, [3, 4, 6, 3]),\n",
    "               50: (Bottleneck, [3, 4, 6, 3]),\n",
    "               101: (Bottleneck, [3, 4, 23, 3]),\n",
    "               152: (Bottleneck, [3, 8, 36, 3])}\n",
    "\n",
    "\n",
    "def get_pose_net(num_layers, heads, head_conv, imagenet_pretrained):\n",
    "    block_class, layers = resnet_spec[num_layers]\n",
    "\n",
    "    model = PoseResNet(block_class, layers, heads, head_conv=head_conv)\n",
    "    model.init_weights(num_layers, pretrained=imagenet_pretrained)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c4470d",
   "metadata": {},
   "source": [
    "## Model Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55eda936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def create_model(configs):\n",
    "    \"\"\"Create model based on architecture name\"\"\"\n",
    "    try:\n",
    "        arch_parts = configs.arch.split('_')\n",
    "        num_layers = int(arch_parts[-1])\n",
    "    except:\n",
    "        raise ValueError\n",
    "    if 'fpn_resnet' in configs.arch:\n",
    "        print('using ResNet architecture with feature pyramid')\n",
    "        model = get_pose_net(num_layers=num_layers, heads=configs.heads, head_conv=configs.head_conv,\n",
    "                             imagenet_pretrained=configs.imagenet_pretrained)\n",
    "    else:\n",
    "        assert False, 'Undefined model backbone'\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_num_parameters(model):\n",
    "    \"\"\"Count number of trained parameters of the model\"\"\"\n",
    "    if hasattr(model, 'module'):\n",
    "        num_parameters = sum(p.numel() for p in model.module.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    return num_parameters\n",
    "\n",
    "\n",
    "def make_data_parallel(model, configs):\n",
    "    if configs.distributed:\n",
    "        # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "        # should always set the single device scope, otherwise,\n",
    "        # DistributedDataParallel will use all available devices.\n",
    "        if configs.gpu_idx is not None:\n",
    "            torch.cuda.set_device(configs.gpu_idx)\n",
    "            model.cuda(configs.gpu_idx)\n",
    "            # When using a single GPU per process and per\n",
    "            # DistributedDataParallel, we need to divide the batch size\n",
    "            # ourselves based on the total number of GPUs we have\n",
    "            configs.batch_size = int(configs.batch_size / configs.ngpus_per_node)\n",
    "            configs.num_workers = int((configs.num_workers + configs.ngpus_per_node - 1) / configs.ngpus_per_node)\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[configs.gpu_idx])\n",
    "        else:\n",
    "            model.cuda()\n",
    "            # DistributedDataParallel will divide and allocate batch_size to all\n",
    "            # available GPUs if device_ids are not set\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "    elif configs.gpu_idx is not None:\n",
    "        torch.cuda.set_device(configs.gpu_idx)\n",
    "        model = model.cuda(configs.gpu_idx)\n",
    "    else:\n",
    "        # DataParallel will divide and allocate batch_size to all available GPUs\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ebd7ef",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "161bcc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data.distributed\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def main():\n",
    "    configs = parse_configs()\n",
    "\n",
    "    # Re-produce results\n",
    "    if configs.seed is not None:\n",
    "        random.seed(configs.seed)\n",
    "        np.random.seed(configs.seed)\n",
    "        torch.manual_seed(configs.seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    if configs.gpu_idx is not None:\n",
    "        print('You have chosen a specific GPU. This will completely disable data parallelism.')\n",
    "\n",
    "    if configs.dist_url == \"env://\" and configs.world_size == -1:\n",
    "        configs.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "    configs.distributed = configs.world_size > 1 or configs.multiprocessing_distributed\n",
    "\n",
    "    if configs.multiprocessing_distributed:\n",
    "        configs.world_size = configs.ngpus_per_node * configs.world_size\n",
    "        mp.spawn(main_worker, nprocs=configs.ngpus_per_node, args=(configs,))\n",
    "    else:\n",
    "        main_worker(configs.gpu_idx, configs)\n",
    "\n",
    "\n",
    "def main_worker(gpu_idx, configs):\n",
    "    configs.gpu_idx = gpu_idx\n",
    "    configs.device = torch.device('cpu' if configs.gpu_idx is None else 'cuda:{}'.format(configs.gpu_idx))\n",
    "\n",
    "    if configs.distributed:\n",
    "        if configs.dist_url == \"env://\" and configs.rank == -1:\n",
    "            configs.rank = int(os.environ[\"RANK\"])\n",
    "        if configs.multiprocessing_distributed:\n",
    "            # For multiprocessing distributed training, rank needs to be the\n",
    "            # global rank among all the processes\n",
    "            configs.rank = configs.rank * configs.ngpus_per_node + gpu_idx\n",
    "\n",
    "        dist.init_process_group(backend=configs.dist_backend, init_method=configs.dist_url,\n",
    "                                world_size=configs.world_size, rank=configs.rank)\n",
    "        configs.subdivisions = int(64 / configs.batch_size / configs.ngpus_per_node)\n",
    "    else:\n",
    "        configs.subdivisions = int(64 / configs.batch_size)\n",
    "\n",
    "    configs.is_master_node = (not configs.distributed) or (\n",
    "            configs.distributed and (configs.rank % configs.ngpus_per_node == 0))\n",
    "\n",
    "    if configs.is_master_node:\n",
    "        logger = Logger(configs.logs_dir, configs.saved_fn)\n",
    "        logger.info('>>> Created a new logger')\n",
    "        logger.info('>>> configs: {}'.format(configs))\n",
    "        tb_writer = SummaryWriter(log_dir=os.path.join(configs.logs_dir, 'tensorboard'))\n",
    "    else:\n",
    "        logger = None\n",
    "        tb_writer = None\n",
    "\n",
    "    # model\n",
    "    model = create_model(configs)\n",
    "\n",
    "    # load weight from a checkpoint\n",
    "    if configs.pretrained_path is not None:\n",
    "        assert os.path.isfile(configs.pretrained_path), \"=> no checkpoint found at '{}'\".format(configs.pretrained_path)\n",
    "        model.load_state_dict(torch.load(configs.pretrained_path, map_location='cpu'))\n",
    "        if logger is not None:\n",
    "            logger.info('loaded pretrained model at {}'.format(configs.pretrained_path))\n",
    "\n",
    "    # resume weights of model from a checkpoint\n",
    "    if configs.resume_path is not None:\n",
    "        assert os.path.isfile(configs.resume_path), \"=> no checkpoint found at '{}'\".format(configs.resume_path)\n",
    "        model.load_state_dict(torch.load(configs.resume_path, map_location='cpu'))\n",
    "        if logger is not None:\n",
    "            logger.info('resume training model from checkpoint {}'.format(configs.resume_path))\n",
    "\n",
    "    # Data Parallel\n",
    "    model = make_data_parallel(model, configs)\n",
    "\n",
    "    # Make sure to create optimizer after moving the model to cuda\n",
    "    optimizer = create_optimizer(configs, model)\n",
    "    lr_scheduler = create_lr_scheduler(optimizer, configs)\n",
    "    configs.step_lr_in_epoch = False if configs.lr_type in ['multi_step', 'cosin', 'one_cycle'] else True\n",
    "\n",
    "    # resume optimizer, lr_scheduler from a checkpoint\n",
    "    if configs.resume_path is not None:\n",
    "        utils_path = configs.resume_path.replace('Model_', 'Utils_')\n",
    "        assert os.path.isfile(utils_path), \"=> no checkpoint found at '{}'\".format(utils_path)\n",
    "        utils_state_dict = torch.load(utils_path, map_location='cuda:{}'.format(configs.gpu_idx))\n",
    "        optimizer.load_state_dict(utils_state_dict['optimizer'])\n",
    "        lr_scheduler.load_state_dict(utils_state_dict['lr_scheduler'])\n",
    "        configs.start_epoch = utils_state_dict['epoch'] + 1\n",
    "\n",
    "    if configs.is_master_node:\n",
    "        num_parameters = get_num_parameters(model)\n",
    "        logger.info('number of trained parameters of the model: {}'.format(num_parameters))\n",
    "\n",
    "    if logger is not None:\n",
    "        logger.info(\">>> Loading dataset & getting dataloader...\")\n",
    "    # Create dataloader\n",
    "    train_dataloader, train_sampler = create_train_dataloader(configs)\n",
    "    if logger is not None:\n",
    "        logger.info('number of batches in training set: {}'.format(len(train_dataloader)))\n",
    "\n",
    "    if configs.evaluate:\n",
    "        val_dataloader = create_val_dataloader(configs)\n",
    "        val_loss = validate(val_dataloader, model, configs)\n",
    "        print('val_loss: {:.4e}'.format(val_loss))\n",
    "        return\n",
    "\n",
    "    for epoch in range(configs.start_epoch, configs.num_epochs + 1):\n",
    "        if logger is not None:\n",
    "            logger.info('{}'.format('*-' * 40))\n",
    "            logger.info('{} {}/{} {}'.format('=' * 35, epoch, configs.num_epochs, '=' * 35))\n",
    "            logger.info('{}'.format('*-' * 40))\n",
    "            logger.info('>>> Epoch: [{}/{}]'.format(epoch, configs.num_epochs))\n",
    "\n",
    "        if configs.distributed:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        # train for one epoch\n",
    "        train_one_epoch(train_dataloader, model, optimizer, lr_scheduler, epoch, configs, logger, tb_writer)\n",
    "        if (not configs.no_val) and (epoch % configs.checkpoint_freq == 0):\n",
    "            val_dataloader = create_val_dataloader(configs)\n",
    "            print('number of batches in val_dataloader: {}'.format(len(val_dataloader)))\n",
    "            val_loss = validate(val_dataloader, model, configs)\n",
    "            print('val_loss: {:.4e}'.format(val_loss))\n",
    "            if tb_writer is not None:\n",
    "                tb_writer.add_scalar('Val_loss', val_loss, epoch)\n",
    "\n",
    "        # Save checkpoint\n",
    "        if configs.is_master_node and ((epoch % configs.checkpoint_freq) == 0):\n",
    "            model_state_dict, utils_state_dict = get_saved_state(model, optimizer, lr_scheduler, epoch, configs)\n",
    "            save_checkpoint(configs.checkpoints_dir, configs.saved_fn, model_state_dict, utils_state_dict, epoch)\n",
    "\n",
    "        if not configs.step_lr_in_epoch:\n",
    "            lr_scheduler.step()\n",
    "            if tb_writer is not None:\n",
    "                tb_writer.add_scalar('LR', lr_scheduler.get_lr()[0], epoch)\n",
    "\n",
    "    if tb_writer is not None:\n",
    "        tb_writer.close()\n",
    "    if configs.distributed:\n",
    "        cleanup()\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "\n",
    "def train_one_epoch(train_dataloader, model, optimizer, lr_scheduler, epoch, configs, logger, tb_writer):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "\n",
    "    progress = ProgressMeter(len(train_dataloader), [batch_time, data_time, losses],\n",
    "                             prefix=\"Train - Epoch: [{}/{}]\".format(epoch, configs.num_epochs))\n",
    "\n",
    "    criterion = Compute_Loss(device=configs.device)\n",
    "    num_iters_per_epoch = len(train_dataloader)\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch_idx, batch_data in enumerate(tqdm(train_dataloader)):\n",
    "        data_time.update(time.time() - start_time)\n",
    "        metadatas, imgs, targets = batch_data\n",
    "        batch_size = imgs.size(0)\n",
    "        global_step = num_iters_per_epoch * (epoch - 1) + batch_idx + 1\n",
    "        for k in targets.keys():\n",
    "            targets[k] = targets[k].to(configs.device, non_blocking=True)\n",
    "        imgs = imgs.to(configs.device, non_blocking=True).float()\n",
    "        outputs = model(imgs)\n",
    "        total_loss, loss_stats = criterion(outputs, targets)\n",
    "        # For torch.nn.DataParallel case\n",
    "        if (not configs.distributed) and (configs.gpu_idx is None):\n",
    "            total_loss = torch.mean(total_loss)\n",
    "\n",
    "        # compute gradient and perform backpropagation\n",
    "        total_loss.backward()\n",
    "        if global_step % configs.subdivisions == 0:\n",
    "            optimizer.step()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Adjust learning rate\n",
    "            if configs.step_lr_in_epoch:\n",
    "                lr_scheduler.step()\n",
    "                if tb_writer is not None:\n",
    "                    tb_writer.add_scalar('LR', lr_scheduler.get_lr()[0], global_step)\n",
    "\n",
    "        if configs.distributed:\n",
    "            reduced_loss = reduce_tensor(total_loss.data, configs.world_size)\n",
    "        else:\n",
    "            reduced_loss = total_loss.data\n",
    "        losses.update(to_python_float(reduced_loss), batch_size)\n",
    "        # measure elapsed time\n",
    "        # torch.cuda.synchronize()\n",
    "        batch_time.update(time.time() - start_time)\n",
    "\n",
    "        if tb_writer is not None:\n",
    "            if (global_step % configs.tensorboard_freq) == 0:\n",
    "                loss_stats['avg_loss'] = losses.avg\n",
    "                tb_writer.add_scalars('Train', loss_stats, global_step)\n",
    "        # Log message\n",
    "        if logger is not None:\n",
    "            if (global_step % configs.print_freq) == 0:\n",
    "                logger.info(progress.get_message(batch_idx))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "\n",
    "def validate(val_dataloader, model, configs):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    criterion = Compute_Loss(device=configs.device)\n",
    "    # switch to train mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(tqdm(val_dataloader)):\n",
    "            metadatas, imgs, targets = batch_data\n",
    "            batch_size = imgs.size(0)\n",
    "            for k in targets.keys():\n",
    "                targets[k] = targets[k].to(configs.device, non_blocking=True)\n",
    "            imgs = imgs.to(configs.device, non_blocking=True).float()\n",
    "            outputs = model(imgs)\n",
    "            total_loss, loss_stats = criterion(outputs, targets)\n",
    "            # For torch.nn.DataParallel case\n",
    "            if (not configs.distributed) and (configs.gpu_idx is None):\n",
    "                total_loss = torch.mean(total_loss)\n",
    "\n",
    "            if configs.distributed:\n",
    "                reduced_loss = reduce_tensor(total_loss.data, configs.world_size)\n",
    "            else:\n",
    "                reduced_loss = total_loss.data\n",
    "            losses.update(to_python_float(reduced_loss), batch_size)\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d22bb",
   "metadata": {},
   "source": [
    "## Demo Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1fdb92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "--2023-11-21 16:27:32--  https://github.com/maudzung/SFA3D/raw/master/checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth\n",
      "Resolving github.com (github.com)... 20.207.73.82\n",
      "Connecting to github.com (github.com)|20.207.73.82|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/maudzung/SFA3D/master/checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth [following]\n",
      "--2023-11-21 16:27:33--  https://raw.githubusercontent.com/maudzung/SFA3D/master/checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 50984463 (49M) [application/octet-stream]\n",
      "Saving to: './checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 1.38M 35s\n",
      "    50K .......... .......... .......... .......... ..........  0%  343M 18s\n",
      "   100K .......... .......... .......... .......... ..........  0% 3.18M 17s\n",
      "   150K .......... .......... .......... .......... ..........  0% 9.66M 14s\n",
      "   200K .......... .......... .......... .......... ..........  0% 7.44M 12s\n",
      "   250K .......... .......... .......... .......... ..........  0% 6.14M 12s\n",
      "   300K .......... .......... .......... .......... ..........  0% 5.07M 11s\n",
      "   350K .......... .......... .......... .......... ..........  0% 16.6M 10s\n",
      "   400K .......... .......... .......... .......... ..........  0% 12.2M 10s\n",
      "   450K .......... .......... .......... .......... ..........  1% 5.69M 9s\n",
      "   500K .......... .......... .......... .......... ..........  1% 7.20M 9s\n",
      "   550K .......... .......... .......... .......... ..........  1% 22.1M 9s\n",
      "   600K .......... .......... .......... .......... ..........  1% 5.79M 9s\n",
      "   650K .......... .......... .......... .......... ..........  1% 11.2M 8s\n",
      "   700K .......... .......... .......... .......... ..........  1% 8.63M 8s\n",
      "   750K .......... .......... .......... .......... ..........  1% 22.4M 8s\n",
      "   800K .......... .......... .......... .......... ..........  1% 7.50M 8s\n",
      "   850K .......... .......... .......... .......... ..........  1% 11.5M 7s\n",
      "   900K .......... .......... .......... .......... ..........  1% 12.5M 7s\n",
      "   950K .......... .......... .......... .......... ..........  2% 25.5M 7s\n",
      "  1000K .......... .......... .......... .......... ..........  2% 3.88M 7s\n",
      "  1050K .......... .......... .......... .......... ..........  2% 12.3M 7s\n",
      "  1100K .......... .......... .......... .......... ..........  2% 4.14M 7s\n",
      "  1150K .......... .......... .......... .......... ..........  2% 17.4M 7s\n",
      "  1200K .......... .......... .......... .......... ..........  2% 4.87M 7s\n",
      "  1250K .......... .......... .......... .......... ..........  2% 14.0M 7s\n",
      "  1300K .......... .......... .......... .......... ..........  2% 12.0M 7s\n",
      "  1350K .......... .......... .......... .......... ..........  2% 6.35M 7s\n",
      "  1400K .......... .......... .......... .......... ..........  2% 22.2M 7s\n",
      "  1450K .......... .......... .......... .......... ..........  3% 4.67M 7s\n",
      "  1500K .......... .......... .......... .......... ..........  3% 5.90M 7s\n",
      "  1550K .......... .......... .......... .......... ..........  3% 19.2M 7s\n",
      "  1600K .......... .......... .......... .......... ..........  3% 8.03M 7s\n",
      "  1650K .......... .......... .......... .......... ..........  3% 11.8M 7s\n",
      "  1700K .......... .......... .......... .......... ..........  3% 13.2M 6s\n",
      "  1750K .......... .......... .......... .......... ..........  3% 10.2M 6s\n",
      "  1800K .......... .......... .......... .......... ..........  3% 15.9M 6s\n",
      "  1850K .......... .......... .......... .......... ..........  3% 8.33M 6s\n",
      "  1900K .......... .......... .......... .......... ..........  3% 6.38M 6s\n",
      "  1950K .......... .......... .......... .......... ..........  4% 23.6M 6s\n",
      "  2000K .......... .......... .......... .......... ..........  4% 3.73M 6s\n",
      "  2050K .......... .......... .......... .......... ..........  4% 12.0M 6s\n",
      "  2100K .......... .......... .......... .......... ..........  4% 22.9M 6s\n",
      "  2150K .......... .......... .......... .......... ..........  4% 8.44M 6s\n",
      "  2200K .......... .......... .......... .......... ..........  4% 11.4M 6s\n",
      "  2250K .......... .......... .......... .......... ..........  4% 9.20M 6s\n",
      "  2300K .......... .......... .......... .......... ..........  4% 6.62M 6s\n",
      "  2350K .......... .......... .......... .......... ..........  4% 17.0M 6s\n",
      "  2400K .......... .......... .......... .......... ..........  4% 6.37M 6s\n",
      "  2450K .......... .......... .......... .......... ..........  5% 7.37M 6s\n",
      "  2500K .......... .......... .......... .......... ..........  5% 12.7M 6s\n",
      "  2550K .......... .......... .......... .......... ..........  5% 13.7M 6s\n",
      "  2600K .......... .......... .......... .......... ..........  5% 24.3M 6s\n",
      "  2650K .......... .......... .......... .......... ..........  5% 6.76M 6s\n",
      "  2700K .......... .......... .......... .......... ..........  5% 10.6M 6s\n",
      "  2750K .......... .......... .......... .......... ..........  5% 26.3M 6s\n",
      "  2800K .......... .......... .......... .......... ..........  5% 7.51M 6s\n",
      "  2850K .......... .......... .......... .......... ..........  5% 22.0M 6s\n",
      "  2900K .......... .......... .......... .......... ..........  5% 14.7M 6s\n",
      "  2950K .......... .......... .......... .......... ..........  6% 9.54M 6s\n",
      "  3000K .......... .......... .......... .......... ..........  6% 4.19M 6s\n",
      "  3050K .......... .......... .......... .......... ..........  6% 6.43M 6s\n",
      "  3100K .......... .......... .......... .......... ..........  6% 22.5M 6s\n",
      "  3150K .......... .......... .......... .......... ..........  6% 11.6M 6s\n",
      "  3200K .......... .......... .......... .......... ..........  6% 6.46M 6s\n",
      "  3250K .......... .......... .......... .......... ..........  6% 11.4M 6s\n",
      "  3300K .......... .......... .......... .......... ..........  6% 19.3M 6s\n",
      "  3350K .......... .......... .......... .......... ..........  6% 11.1M 5s\n",
      "  3400K .......... .......... .......... .......... ..........  6% 7.36M 5s\n",
      "  3450K .......... .......... .......... .......... ..........  7% 21.9M 5s\n",
      "  3500K .......... .......... .......... .......... ..........  7% 8.49M 5s\n",
      "  3550K .......... .......... .......... .......... ..........  7% 6.92M 5s\n",
      "  3600K .......... .......... .......... .......... ..........  7% 11.8M 5s\n",
      "  3650K .......... .......... .......... .......... ..........  7% 11.0M 5s\n",
      "  3700K .......... .......... .......... .......... ..........  7% 10.3M 5s\n",
      "  3750K .......... .......... .......... .......... ..........  7% 7.94M 5s\n",
      "  3800K .......... .......... .......... .......... ..........  7% 17.5M 5s\n",
      "  3850K .......... .......... .......... .......... ..........  7% 13.1M 5s\n",
      "  3900K .......... .......... .......... .......... ..........  7% 8.03M 5s\n",
      "  3950K .......... .......... .......... .......... ..........  8% 17.8M 5s\n",
      "  4000K .......... .......... .......... .......... ..........  8% 4.47M 5s\n",
      "  4050K .......... .......... .......... .......... ..........  8% 20.3M 5s\n",
      "  4100K .......... .......... .......... .......... ..........  8% 6.44M 5s\n",
      "  4150K .......... .......... .......... .......... ..........  8% 12.1M 5s\n",
      "  4200K .......... .......... .......... .......... ..........  8% 22.8M 5s\n",
      "  4250K .......... .......... .......... .......... ..........  8% 11.0M 5s\n",
      "  4300K .......... .......... .......... .......... ..........  8% 11.8M 5s\n",
      "  4350K .......... .......... .......... .......... ..........  8% 9.42M 5s\n",
      "  4400K .......... .......... .......... .......... ..........  8% 9.15M 5s\n",
      "  4450K .......... .......... .......... .......... ..........  9% 6.49M 5s\n",
      "  4500K .......... .......... .......... .......... ..........  9% 21.0M 5s\n",
      "  4550K .......... .......... .......... .......... ..........  9% 5.10M 5s\n",
      "  4600K .......... .......... .......... .......... ..........  9% 13.7M 5s\n",
      "  4650K .......... .......... .......... .......... ..........  9% 6.17M 5s\n",
      "  4700K .......... .......... .......... .......... ..........  9% 12.5M 5s\n",
      "  4750K .......... .......... .......... .......... ..........  9% 6.44M 5s\n",
      "  4800K .......... .......... .......... .......... ..........  9% 9.82M 5s\n",
      "  4850K .......... .......... .......... .......... ..........  9% 21.6M 5s\n",
      "  4900K .......... .......... .......... .......... ..........  9% 12.0M 5s\n",
      "  4950K .......... .......... .......... .......... .......... 10% 10.7M 5s\n",
      "  5000K .......... .......... .......... .......... .......... 10% 18.8M 5s\n",
      "  5050K .......... .......... .......... .......... .......... 10% 5.12M 5s\n",
      "  5100K .......... .......... .......... .......... .......... 10% 6.76M 5s\n",
      "  5150K .......... .......... .......... .......... .......... 10% 20.0M 5s\n",
      "  5200K .......... .......... .......... .......... .......... 10% 7.72M 5s\n",
      "  5250K .......... .......... .......... .......... .......... 10% 9.14M 5s\n",
      "  5300K .......... .......... .......... .......... .......... 10% 13.2M 5s\n",
      "  5350K .......... .......... .......... .......... .......... 10% 8.01M 5s\n",
      "  5400K .......... .......... .......... .......... .......... 10% 6.63M 5s\n",
      "  5450K .......... .......... .......... .......... .......... 11% 20.9M 5s\n",
      "  5500K .......... .......... .......... .......... .......... 11% 5.64M 5s\n",
      "  5550K .......... .......... .......... .......... .......... 11% 12.9M 5s\n",
      "  5600K .......... .......... .......... .......... .......... 11% 12.0M 5s\n",
      "  5650K .......... .......... .......... .......... .......... 11% 12.2M 5s\n",
      "  5700K .......... .......... .......... .......... .......... 11% 9.97M 5s\n",
      "  5750K .......... .......... .......... .......... .......... 11% 9.13M 5s\n",
      "  5800K .......... .......... .......... .......... .......... 11% 7.90M 5s\n",
      "  5850K .......... .......... .......... .......... .......... 11% 10.6M 5s\n",
      "  5900K .......... .......... .......... .......... .......... 11% 15.3M 5s\n",
      "  5950K .......... .......... .......... .......... .......... 12% 7.26M 5s\n",
      "  6000K .......... .......... .......... .......... .......... 12% 5.71M 5s\n",
      "  6050K .......... .......... .......... .......... .......... 12% 22.5M 5s\n",
      "  6100K .......... .......... .......... .......... .......... 12% 5.10M 5s\n",
      "  6150K .......... .......... .......... .......... .......... 12% 8.51M 5s\n",
      "  6200K .......... .......... .......... .......... .......... 12% 18.9M 5s\n",
      "  6250K .......... .......... .......... .......... .......... 12% 7.76M 5s\n",
      "  6300K .......... .......... .......... .......... .......... 12% 20.2M 5s\n",
      "  6350K .......... .......... .......... .......... .......... 12% 4.16M 5s\n",
      "  6400K .......... .......... .......... .......... .......... 12% 11.5M 5s\n",
      "  6450K .......... .......... .......... .......... .......... 13% 7.22M 5s\n",
      "  6500K .......... .......... .......... .......... .......... 13% 13.0M 5s\n",
      "  6550K .......... .......... .......... .......... .......... 13% 7.25M 5s\n",
      "  6600K .......... .......... .......... .......... .......... 13% 7.05M 5s\n",
      "  6650K .......... .......... .......... .......... .......... 13% 22.0M 5s\n",
      "  6700K .......... .......... .......... .......... .......... 13% 12.4M 5s\n",
      "  6750K .......... .......... .......... .......... .......... 13% 10.3M 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6800K .......... .......... .......... .......... .......... 13% 13.6M 5s\n",
      "  6850K .......... .......... .......... .......... .......... 13% 11.8M 5s\n",
      "  6900K .......... .......... .......... .......... .......... 13% 7.26M 5s\n",
      "  6950K .......... .......... .......... .......... .......... 14% 5.73M 5s\n",
      "  7000K .......... .......... .......... .......... .......... 14% 10.6M 5s\n",
      "  7050K .......... .......... .......... .......... .......... 14% 9.77M 5s\n",
      "  7100K .......... .......... .......... .......... .......... 14% 6.19M 5s\n",
      "  7150K .......... .......... .......... .......... .......... 14% 12.5M 5s\n",
      "  7200K .......... .......... .......... .......... .......... 14% 5.83M 5s\n",
      "  7250K .......... .......... .......... .......... .......... 14% 10.2M 5s\n",
      "  7300K .......... .......... .......... .......... .......... 14% 23.9M 5s\n",
      "  7350K .......... .......... .......... .......... .......... 14% 7.37M 5s\n",
      "  7400K .......... .......... .......... .......... .......... 14% 5.52M 5s\n",
      "  7450K .......... .......... .......... .......... .......... 15% 7.26M 5s\n",
      "  7500K .......... .......... .......... .......... .......... 15% 22.0M 5s\n",
      "  7550K .......... .......... .......... .......... .......... 15% 6.63M 5s\n",
      "  7600K .......... .......... .......... .......... .......... 15% 12.5M 5s\n",
      "  7650K .......... .......... .......... .......... .......... 15% 10.3M 5s\n",
      "  7700K .......... .......... .......... .......... .......... 15% 23.8M 5s\n",
      "  7750K .......... .......... .......... .......... .......... 15% 11.9M 5s\n",
      "  7800K .......... .......... .......... .......... .......... 15% 20.1M 5s\n",
      "  7850K .......... .......... .......... .......... .......... 15% 8.91M 5s\n",
      "  7900K .......... .......... .......... .......... .......... 15% 8.58M 5s\n",
      "  7950K .......... .......... .......... .......... .......... 16% 7.04M 5s\n",
      "  8000K .......... .......... .......... .......... .......... 16% 5.79M 5s\n",
      "  8050K .......... .......... .......... .......... .......... 16% 7.24M 5s\n",
      "  8100K .......... .......... .......... .......... .......... 16% 10.2M 5s\n",
      "  8150K .......... .......... .......... .......... .......... 16% 24.5M 5s\n",
      "  8200K .......... .......... .......... .......... .......... 16% 10.1M 5s\n",
      "  8250K .......... .......... .......... .......... .......... 16% 10.2M 5s\n",
      "  8300K .......... .......... .......... .......... .......... 16% 22.5M 5s\n",
      "  8350K .......... .......... .......... .......... .......... 16% 7.59M 5s\n",
      "  8400K .......... .......... .......... .......... .......... 16% 5.54M 5s\n",
      "  8450K .......... .......... .......... .......... .......... 17% 10.5M 5s\n",
      "  8500K .......... .......... .......... .......... .......... 17% 31.5M 5s\n",
      "  8550K .......... .......... .......... .......... .......... 17% 8.36M 5s\n",
      "  8600K .......... .......... .......... .......... .......... 17% 5.09M 5s\n",
      "  8650K .......... .......... .......... .......... .......... 17% 21.3M 5s\n",
      "  8700K .......... .......... .......... .......... .......... 17% 24.3M 4s\n",
      "  8750K .......... .......... .......... .......... .......... 17% 11.2M 4s\n",
      "  8800K .......... .......... .......... .......... .......... 17% 11.2M 4s\n",
      "  8850K .......... .......... .......... .......... .......... 17% 9.87M 4s\n",
      "  8900K .......... .......... .......... .......... .......... 17% 9.61M 4s\n",
      "  8950K .......... .......... .......... .......... .......... 18% 20.6M 4s\n",
      "  9000K .......... .......... .......... .......... .......... 18% 4.75M 4s\n",
      "  9050K .......... .......... .......... .......... .......... 18% 10.1M 4s\n",
      "  9100K .......... .......... .......... .......... .......... 18% 23.2M 4s\n",
      "  9150K .......... .......... .......... .......... .......... 18% 7.70M 4s\n",
      "  9200K .......... .......... .......... .......... .......... 18% 9.06M 4s\n",
      "  9250K .......... .......... .......... .......... .......... 18% 10.2M 4s\n",
      "  9300K .......... .......... .......... .......... .......... 18% 14.9M 4s\n",
      "  9350K .......... .......... .......... .......... .......... 18% 10.1M 4s\n",
      "  9400K .......... .......... .......... .......... .......... 18% 7.36M 4s\n",
      "  9450K .......... .......... .......... .......... .......... 19% 30.6M 4s\n",
      "  9500K .......... .......... .......... .......... .......... 19% 2.99M 4s\n",
      "  9550K .......... .......... .......... .......... .......... 19% 11.6M 4s\n",
      "  9600K .......... .......... .......... .......... .......... 19% 10.8M 4s\n",
      "  9650K .......... .......... .......... .......... .......... 19% 11.5M 4s\n",
      "  9700K .......... .......... .......... .......... .......... 19% 26.6M 4s\n",
      "  9750K .......... .......... .......... .......... .......... 19% 11.8M 4s\n",
      "  9800K .......... .......... .......... .......... .......... 19% 8.82M 4s\n",
      "  9850K .......... .......... .......... .......... .......... 19% 9.41M 4s\n",
      "  9900K .......... .......... .......... .......... .......... 19% 9.89M 4s\n",
      "  9950K .......... .......... .......... .......... .......... 20% 8.01M 4s\n",
      " 10000K .......... .......... .......... .......... .......... 20% 5.77M 4s\n",
      " 10050K .......... .......... .......... .......... .......... 20% 15.4M 4s\n",
      " 10100K .......... .......... .......... .......... .......... 20% 12.2M 4s\n",
      " 10150K .......... .......... .......... .......... .......... 20% 6.08M 4s\n",
      " 10200K .......... .......... .......... .......... .......... 20% 23.7M 4s\n",
      " 10250K .......... .......... .......... .......... .......... 20% 10.4M 4s\n",
      " 10300K .......... .......... .......... .......... .......... 20% 18.7M 4s\n",
      " 10350K .......... .......... .......... .......... .......... 20% 5.68M 4s\n",
      " 10400K .......... .......... .......... .......... .......... 20% 4.47M 4s\n",
      " 10450K .......... .......... .......... .......... .......... 21% 24.9M 4s\n",
      " 10500K .......... .......... .......... .......... .......... 21% 9.05M 4s\n",
      " 10550K .......... .......... .......... .......... .......... 21% 6.84M 4s\n",
      " 10600K .......... .......... .......... .......... .......... 21% 9.15M 4s\n",
      " 10650K .......... .......... .......... .......... .......... 21% 22.6M 4s\n",
      " 10700K .......... .......... .......... .......... .......... 21% 11.0M 4s\n",
      " 10750K .......... .......... .......... .......... .......... 21% 19.9M 4s\n",
      " 10800K .......... .......... .......... .......... .......... 21% 6.64M 4s\n",
      " 10850K .......... .......... .......... .......... .......... 21% 22.4M 4s\n",
      " 10900K .......... .......... .......... .......... .......... 21% 5.11M 4s\n",
      " 10950K .......... .......... .......... .......... .......... 22% 12.8M 4s\n",
      " 11000K .......... .......... .......... .......... .......... 22% 8.95M 4s\n",
      " 11050K .......... .......... .......... .......... .......... 22% 7.93M 4s\n",
      " 11100K .......... .......... .......... .......... .......... 22% 25.3M 4s\n",
      " 11150K .......... .......... .......... .......... .......... 22% 18.4M 4s\n",
      " 11200K .......... .......... .......... .......... .......... 22% 5.55M 4s\n",
      " 11250K .......... .......... .......... .......... .......... 22% 18.2M 4s\n",
      " 11300K .......... .......... .......... .......... .......... 22% 11.1M 4s\n",
      " 11350K .......... .......... .......... .......... .......... 22% 7.68M 4s\n",
      " 11400K .......... .......... .......... .......... .......... 22% 11.8M 4s\n",
      " 11450K .......... .......... .......... .......... .......... 23% 11.9M 4s\n",
      " 11500K .......... .......... .......... .......... .......... 23% 7.35M 4s\n",
      " 11550K .......... .......... .......... .......... .......... 23% 11.3M 4s\n",
      " 11600K .......... .......... .......... .......... .......... 23% 4.59M 4s\n",
      " 11650K .......... .......... .......... .......... .......... 23% 21.0M 4s\n",
      " 11700K .......... .......... .......... .......... .......... 23% 13.6M 4s\n",
      " 11750K .......... .......... .......... .......... .......... 23% 7.97M 4s\n",
      " 11800K .......... .......... .......... .......... .......... 23% 16.0M 4s\n",
      " 11850K .......... .......... .......... .......... .......... 23% 10.7M 4s\n",
      " 11900K .......... .......... .......... .......... .......... 24% 9.98M 4s\n",
      " 11950K .......... .......... .......... .......... .......... 24% 8.61M 4s\n",
      " 12000K .......... .......... .......... .......... .......... 24% 7.35M 4s\n",
      " 12050K .......... .......... .......... .......... .......... 24% 7.42M 4s\n",
      " 12100K .......... .......... .......... .......... .......... 24% 15.6M 4s\n",
      " 12150K .......... .......... .......... .......... .......... 24% 14.9M 4s\n",
      " 12200K .......... .......... .......... .......... .......... 24% 13.0M 4s\n",
      " 12250K .......... .......... .......... .......... .......... 24% 14.3M 4s\n",
      " 12300K .......... .......... .......... .......... .......... 24% 11.9M 4s\n",
      " 12350K .......... .......... .......... .......... .......... 24% 11.1M 4s\n",
      " 12400K .......... .......... .......... .......... .......... 25% 15.8M 4s\n",
      " 12450K .......... .......... .......... .......... .......... 25% 9.07M 4s\n",
      " 12500K .......... .......... .......... .......... .......... 25% 4.32M 4s\n",
      " 12550K .......... .......... .......... .......... .......... 25% 11.5M 4s\n",
      " 12600K .......... .......... .......... .......... .......... 25% 9.92M 4s\n",
      " 12650K .......... .......... .......... .......... .......... 25% 7.57M 4s\n",
      " 12700K .......... .......... .......... .......... .......... 25% 15.7M 4s\n",
      " 12750K .......... .......... .......... .......... .......... 25% 9.96M 4s\n",
      " 12800K .......... .......... .......... .......... .......... 25% 8.90M 4s\n",
      " 12850K .......... .......... .......... .......... .......... 25% 12.8M 4s\n",
      " 12900K .......... .......... .......... .......... .......... 26% 8.89M 4s\n",
      " 12950K .......... .......... .......... .......... .......... 26% 15.0M 4s\n",
      " 13000K .......... .......... .......... .......... .......... 26% 5.36M 4s\n",
      " 13050K .......... .......... .......... .......... .......... 26% 7.82M 4s\n",
      " 13100K .......... .......... .......... .......... .......... 26% 15.2M 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13150K .......... .......... .......... .......... .......... 26% 16.0M 4s\n",
      " 13200K .......... .......... .......... .......... .......... 26% 15.7M 4s\n",
      " 13250K .......... .......... .......... .......... .......... 26% 10.7M 4s\n",
      " 13300K .......... .......... .......... .......... .......... 26% 9.73M 4s\n",
      " 13350K .......... .......... .......... .......... .......... 26% 9.96M 4s\n",
      " 13400K .......... .......... .......... .......... .......... 27% 10.8M 4s\n",
      " 13450K .......... .......... .......... .......... .......... 27% 7.70M 4s\n",
      " 13500K .......... .......... .......... .......... .......... 27% 12.9M 4s\n",
      " 13550K .......... .......... .......... .......... .......... 27% 5.94M 4s\n",
      " 13600K .......... .......... .......... .......... .......... 27% 15.2M 4s\n",
      " 13650K .......... .......... .......... .......... .......... 27% 14.0M 4s\n",
      " 13700K .......... .......... .......... .......... .......... 27% 9.63M 4s\n",
      " 13750K .......... .......... .......... .......... .......... 27% 8.00M 4s\n",
      " 13800K .......... .......... .......... .......... .......... 27% 7.10M 4s\n",
      " 13850K .......... .......... .......... .......... .......... 27% 11.8M 4s\n",
      " 13900K .......... .......... .......... .......... .......... 28% 9.35M 4s\n",
      " 13950K .......... .......... .......... .......... .......... 28% 11.0M 4s\n",
      " 14000K .......... .......... .......... .......... .......... 28% 4.64M 4s\n",
      " 14050K .......... .......... .......... .......... .......... 28% 6.99M 4s\n",
      " 14100K .......... .......... .......... .......... .......... 28% 8.02M 4s\n",
      " 14150K .......... .......... .......... .......... .......... 28% 32.6M 4s\n",
      " 14200K .......... .......... .......... .......... .......... 28% 7.27M 4s\n",
      " 14250K .......... .......... .......... .......... .......... 28% 21.5M 4s\n",
      " 14300K .......... .......... .......... .......... .......... 28% 10.2M 4s\n",
      " 14350K .......... .......... .......... .......... .......... 28% 14.8M 4s\n",
      " 14400K .......... .......... .......... .......... .......... 29% 5.58M 4s\n",
      " 14450K .......... .......... .......... .......... .......... 29% 17.3M 4s\n",
      " 14500K .......... .......... .......... .......... .......... 29% 9.00M 4s\n",
      " 14550K .......... .......... .......... .......... .......... 29% 5.72M 4s\n",
      " 14600K .......... .......... .......... .......... .......... 29% 14.6M 4s\n",
      " 14650K .......... .......... .......... .......... .......... 29% 14.9M 4s\n",
      " 14700K .......... .......... .......... .......... .......... 29% 12.5M 4s\n",
      " 14750K .......... .......... .......... .......... .......... 29% 6.54M 4s\n",
      " 14800K .......... .......... .......... .......... .......... 29% 11.1M 4s\n",
      " 14850K .......... .......... .......... .......... .......... 29% 9.23M 4s\n",
      " 14900K .......... .......... .......... .......... .......... 30% 8.30M 4s\n",
      " 14950K .......... .......... .......... .......... .......... 30% 13.8M 4s\n",
      " 15000K .......... .......... .......... .......... .......... 30% 7.17M 4s\n",
      " 15050K .......... .......... .......... .......... .......... 30% 5.16M 4s\n",
      " 15100K .......... .......... .......... .......... .......... 30% 14.8M 4s\n",
      " 15150K .......... .......... .......... .......... .......... 30% 15.4M 4s\n",
      " 15200K .......... .......... .......... .......... .......... 30% 7.73M 4s\n",
      " 15250K .......... .......... .......... .......... .......... 30% 13.7M 4s\n",
      " 15300K .......... .......... .......... .......... .......... 30% 16.1M 4s\n",
      " 15350K .......... .......... .......... .......... .......... 30% 9.70M 4s\n",
      " 15400K .......... .......... .......... .......... .......... 31% 14.8M 4s\n",
      " 15450K .......... .......... .......... .......... .......... 31% 8.72M 4s\n",
      " 15500K .......... .......... .......... .......... .......... 31% 8.21M 4s\n",
      " 15550K .......... .......... .......... .......... .......... 31% 7.69M 4s\n",
      " 15600K .......... .......... .......... .......... .......... 31% 11.1M 4s\n",
      " 15650K .......... .......... .......... .......... .......... 31% 13.6M 4s\n",
      " 15700K .......... .......... .......... .......... .......... 31% 8.86M 4s\n",
      " 15750K .......... .......... .......... .......... .......... 31% 9.39M 4s\n",
      " 15800K .......... .......... .......... .......... .......... 31% 16.8M 4s\n",
      " 15850K .......... .......... .......... .......... .......... 31% 10.5M 4s\n",
      " 15900K .......... .......... .......... .......... .......... 32% 1.51M 4s\n",
      " 15950K .......... .......... .......... .......... .......... 32% 8.13M 4s\n",
      " 16000K .......... .......... .......... .......... .......... 32% 9.86M 4s\n",
      " 16050K .......... .......... .......... .......... .......... 32% 7.75M 4s\n",
      " 16100K .......... .......... .......... .......... .......... 32% 11.4M 4s\n",
      " 16150K .......... .......... .......... .......... .......... 32% 14.8M 4s\n",
      " 16200K .......... .......... .......... .......... .......... 32% 9.02M 4s\n",
      " 16250K .......... .......... .......... .......... .......... 32% 13.7M 4s\n",
      " 16300K .......... .......... .......... .......... .......... 32% 4.68M 4s\n",
      " 16350K .......... .......... .......... .......... .......... 32% 10.1M 4s\n",
      " 16400K .......... .......... .......... .......... .......... 33% 6.18M 4s\n",
      " 16450K .......... .......... .......... .......... .......... 33% 14.1M 4s\n",
      " 16500K .......... .......... .......... .......... .......... 33% 11.7M 4s\n",
      " 16550K .......... .......... .......... .......... .......... 33% 16.4M 4s\n",
      " 16600K .......... .......... .......... .......... .......... 33% 11.4M 4s\n",
      " 16650K .......... .......... .......... .......... .......... 33% 10.4M 4s\n",
      " 16700K .......... .......... .......... .......... .......... 33% 7.54M 4s\n",
      " 16750K .......... .......... .......... .......... .......... 33% 6.94M 4s\n",
      " 16800K .......... .......... .......... .......... .......... 33% 5.86M 4s\n",
      " 16850K .......... .......... .......... .......... .......... 33% 15.4M 4s\n",
      " 16900K .......... .......... .......... .......... .......... 34% 15.1M 4s\n",
      " 16950K .......... .......... .......... .......... .......... 34% 15.0M 4s\n",
      " 17000K .......... .......... .......... .......... .......... 34% 17.2M 4s\n",
      " 17050K .......... .......... .......... .......... .......... 34% 4.76M 4s\n",
      " 17100K .......... .......... .......... .......... .......... 34% 7.79M 4s\n",
      " 17150K .......... .......... .......... .......... .......... 34% 8.43M 3s\n",
      " 17200K .......... .......... .......... .......... .......... 34% 5.54M 3s\n",
      " 17250K .......... .......... .......... .......... .......... 34% 11.0M 3s\n",
      " 17300K .......... .......... .......... .......... .......... 34% 15.3M 3s\n",
      " 17350K .......... .......... .......... .......... .......... 34% 16.3M 3s\n",
      " 17400K .......... .......... .......... .......... .......... 35% 11.9M 3s\n",
      " 17450K .......... .......... .......... .......... .......... 35% 9.94M 3s\n",
      " 17500K .......... .......... .......... .......... .......... 35% 10.2M 3s\n",
      " 17550K .......... .......... .......... .......... .......... 35% 11.3M 3s\n",
      " 17600K .......... .......... .......... .......... .......... 35% 8.19M 3s\n",
      " 17650K .......... .......... .......... .......... .......... 35% 11.3M 3s\n",
      " 17700K .......... .......... .......... .......... .......... 35% 10.6M 3s\n",
      " 17750K .......... .......... .......... .......... .......... 35% 6.76M 3s\n",
      " 17800K .......... .......... .......... .......... .......... 35% 8.50M 3s\n",
      " 17850K .......... .......... .......... .......... .......... 35% 16.3M 3s\n",
      " 17900K .......... .......... .......... .......... .......... 36% 10.2M 3s\n",
      " 17950K .......... .......... .......... .......... .......... 36% 9.64M 3s\n",
      " 18000K .......... .......... .......... .......... .......... 36% 5.66M 3s\n",
      " 18050K .......... .......... .......... .......... .......... 36% 14.6M 3s\n",
      " 18100K .......... .......... .......... .......... .......... 36% 9.47M 3s\n",
      " 18150K .......... .......... .......... .......... .......... 36% 7.39M 3s\n",
      " 18200K .......... .......... .......... .......... .......... 36% 15.8M 3s\n",
      " 18250K .......... .......... .......... .......... .......... 36% 6.00M 3s\n",
      " 18300K .......... .......... .......... .......... .......... 36% 16.0M 3s\n",
      " 18350K .......... .......... .......... .......... .......... 36% 12.8M 3s\n",
      " 18400K .......... .......... .......... .......... .......... 37% 6.81M 3s\n",
      " 18450K .......... .......... .......... .......... .......... 37% 16.1M 3s\n",
      " 18500K .......... .......... .......... .......... .......... 37% 11.5M 3s\n",
      " 18550K .......... .......... .......... .......... .......... 37% 13.9M 3s\n",
      " 18600K .......... .......... .......... .......... .......... 37% 13.2M 3s\n",
      " 18650K .......... .......... .......... .......... .......... 37% 15.9M 3s\n",
      " 18700K .......... .......... .......... .......... .......... 37% 9.46M 3s\n",
      " 18750K .......... .......... .......... .......... .......... 37% 10.0M 3s\n",
      " 18800K .......... .......... .......... .......... .......... 37% 6.31M 3s\n",
      " 18850K .......... .......... .......... .......... .......... 37% 4.76M 3s\n",
      " 18900K .......... .......... .......... .......... .......... 38% 22.4M 3s\n",
      " 18950K .......... .......... .......... .......... .......... 38% 17.6M 3s\n",
      " 19000K .......... .......... .......... .......... .......... 38% 4.88M 3s\n",
      " 19050K .......... .......... .......... .......... .......... 38% 14.8M 3s\n",
      " 19100K .......... .......... .......... .......... .......... 38% 14.3M 3s\n",
      " 19150K .......... .......... .......... .......... .......... 38% 16.4M 3s\n",
      " 19200K .......... .......... .......... .......... .......... 38% 6.49M 3s\n",
      " 19250K .......... .......... .......... .......... .......... 38% 14.7M 3s\n",
      " 19300K .......... .......... .......... .......... .......... 38% 5.96M 3s\n",
      " 19350K .......... .......... .......... .......... .......... 38% 11.5M 3s\n",
      " 19400K .......... .......... .......... .......... .......... 39% 7.91M 3s\n",
      " 19450K .......... .......... .......... .......... .......... 39% 9.47M 3s\n",
      " 19500K .......... .......... .......... .......... .......... 39% 15.3M 3s\n",
      " 19550K .......... .......... .......... .......... .......... 39% 16.2M 3s\n",
      " 19600K .......... .......... .......... .......... .......... 39% 8.30M 3s\n",
      " 19650K .......... .......... .......... .......... .......... 39% 8.81M 3s\n",
      " 19700K .......... .......... .......... .......... .......... 39% 10.9M 3s\n",
      " 19750K .......... .......... .......... .......... .......... 39% 10.7M 3s\n",
      " 19800K .......... .......... .......... .......... .......... 39% 5.89M 3s\n",
      " 19850K .......... .......... .......... .......... .......... 39% 6.60M 3s\n",
      " 19900K .......... .......... .......... .......... .......... 40% 11.6M 3s\n",
      " 19950K .......... .......... .......... .......... .......... 40% 9.09M 3s\n",
      " 20000K .......... .......... .......... .......... .......... 40% 14.5M 3s\n",
      " 20050K .......... .......... .......... .......... .......... 40% 13.4M 3s\n",
      " 20100K .......... .......... .......... .......... .......... 40% 15.3M 3s\n",
      " 20150K .......... .......... .......... .......... .......... 40% 15.5M 3s\n",
      " 20200K .......... .......... .......... .......... .......... 40% 10.6M 3s\n",
      " 20250K .......... .......... .......... .......... .......... 40% 7.27M 3s\n",
      " 20300K .......... .......... .......... .......... .......... 40% 8.52M 3s\n",
      " 20350K .......... .......... .......... .......... .......... 40% 6.74M 3s\n",
      " 20400K .......... .......... .......... .......... .......... 41% 8.49M 3s\n",
      " 20450K .......... .......... .......... .......... .......... 41% 15.2M 3s\n",
      " 20500K .......... .......... .......... .......... .......... 41% 8.18M 3s\n",
      " 20550K .......... .......... .......... .......... .......... 41% 15.5M 3s\n",
      " 20600K .......... .......... .......... .......... .......... 41% 7.34M 3s\n",
      " 20650K .......... .......... .......... .......... .......... 41% 16.3M 3s\n",
      " 20700K .......... .......... .......... .......... .......... 41% 16.6M 3s\n",
      " 20750K .......... .......... .......... .......... .......... 41% 11.1M 3s\n",
      " 20800K .......... .......... .......... .......... .......... 41% 5.46M 3s\n",
      " 20850K .......... .......... .......... .......... .......... 41% 15.6M 3s\n",
      " 20900K .......... .......... .......... .......... .......... 42% 5.03M 3s\n",
      " 20950K .......... .......... .......... .......... .......... 42% 8.28M 3s\n",
      " 21000K .......... .......... .......... .......... .......... 42% 12.0M 3s\n",
      " 21050K .......... .......... .......... .......... .......... 42% 14.8M 3s\n",
      " 21100K .......... .......... .......... .......... .......... 42% 9.73M 3s\n",
      " 21150K .......... .......... .......... .......... .......... 42% 15.0M 3s\n",
      " 21200K .......... .......... .......... .......... .......... 42% 6.27M 3s\n",
      " 21250K .......... .......... .......... .......... .......... 42% 15.1M 3s\n",
      " 21300K .......... .......... .......... .......... .......... 42% 6.02M 3s\n",
      " 21350K .......... .......... .......... .......... .......... 42% 15.4M 3s\n",
      " 21400K .......... .......... .......... .......... .......... 43% 8.87M 3s\n",
      " 21450K .......... .......... .......... .......... .......... 43% 31.0M 3s\n",
      " 21500K .......... .......... .......... .......... .......... 43% 17.3M 3s\n",
      " 21550K .......... .......... .......... .......... .......... 43% 8.23M 3s\n",
      " 21600K .......... .......... .......... .......... .......... 43% 8.52M 3s\n",
      " 21650K .......... .......... .......... .......... .......... 43% 14.5M 3s\n",
      " 21700K .......... .......... .......... .......... .......... 43% 16.3M 3s\n",
      " 21750K .......... .......... .......... .......... .......... 43% 12.3M 3s\n",
      " 21800K .......... .......... .......... .......... .......... 43% 7.88M 3s\n",
      " 21850K .......... .......... .......... .......... .......... 43% 14.3M 3s\n",
      " 21900K .......... .......... .......... .......... .......... 44% 7.86M 3s\n",
      " 21950K .......... .......... .......... .......... .......... 44% 17.3M 3s\n",
      " 22000K .......... .......... .......... .......... .......... 44% 5.00M 3s\n",
      " 22050K .......... .......... .......... .......... .......... 44% 6.23M 3s\n",
      " 22100K .......... .......... .......... .......... .......... 44% 11.6M 3s\n",
      " 22150K .......... .......... .......... .......... .......... 44% 11.5M 3s\n",
      " 22200K .......... .......... .......... .......... .......... 44% 7.97M 3s\n",
      " 22250K .......... .......... .......... .......... .......... 44% 8.12M 3s\n",
      " 22300K .......... .......... .......... .......... .......... 44% 14.3M 3s\n",
      " 22350K .......... .......... .......... .......... .......... 44% 7.50M 3s\n",
      " 22400K .......... .......... .......... .......... .......... 45% 10.6M 3s\n",
      " 22450K .......... .......... .......... .......... .......... 45% 14.9M 3s\n",
      " 22500K .......... .......... .......... .......... .......... 45% 15.5M 3s\n",
      " 22550K .......... .......... .......... .......... .......... 45% 7.10M 3s\n",
      " 22600K .......... .......... .......... .......... .......... 45% 15.9M 3s\n",
      " 22650K .......... .......... .......... .......... .......... 45% 15.7M 3s\n",
      " 22700K .......... .......... .......... .......... .......... 45% 5.22M 3s\n",
      " 22750K .......... .......... .......... .......... .......... 45% 13.8M 3s\n",
      " 22800K .......... .......... .......... .......... .......... 45% 5.97M 3s\n",
      " 22850K .......... .......... .......... .......... .......... 45% 8.04M 3s\n",
      " 22900K .......... .......... .......... .......... .......... 46% 12.0M 3s\n",
      " 22950K .......... .......... .......... .......... .......... 46% 8.32M 3s\n",
      " 23000K .......... .......... .......... .......... .......... 46% 14.5M 3s\n",
      " 23050K .......... .......... .......... .......... .......... 46% 5.01M 3s\n",
      " 23100K .......... .......... .......... .......... .......... 46% 10.9M 3s\n",
      " 23150K .......... .......... .......... .......... .......... 46% 16.0M 3s\n",
      " 23200K .......... .......... .......... .......... .......... 46% 4.51M 3s\n",
      " 23250K .......... .......... .......... .......... .......... 46% 16.0M 3s\n",
      " 23300K .......... .......... .......... .......... .......... 46% 7.54M 3s\n",
      " 23350K .......... .......... .......... .......... .......... 46% 14.1M 3s\n",
      " 23400K .......... .......... .......... .......... .......... 47% 14.5M 3s\n",
      " 23450K .......... .......... .......... .......... .......... 47% 13.6M 3s\n",
      " 23500K .......... .......... .......... .......... .......... 47% 8.79M 3s\n",
      " 23550K .......... .......... .......... .......... .......... 47% 14.5M 3s\n",
      " 23600K .......... .......... .......... .......... .......... 47% 5.47M 3s\n",
      " 23650K .......... .......... .......... .......... .......... 47% 16.3M 3s\n",
      " 23700K .......... .......... .......... .......... .......... 47% 15.5M 3s\n",
      " 23750K .......... .......... .......... .......... .......... 47% 14.1M 3s\n",
      " 23800K .......... .......... .......... .......... .......... 47% 15.7M 3s\n",
      " 23850K .......... .......... .......... .......... .......... 48% 13.1M 3s\n",
      " 23900K .......... .......... .......... .......... .......... 48% 13.0M 3s\n",
      " 23950K .......... .......... .......... .......... .......... 48% 4.41M 3s\n",
      " 24000K .......... .......... .......... .......... .......... 48% 14.8M 3s\n",
      " 24050K .......... .......... .......... .......... .......... 48% 10.1M 3s\n",
      " 24100K .......... .......... .......... .......... .......... 48% 9.35M 3s\n",
      " 24150K .......... .......... .......... .......... .......... 48% 14.9M 3s\n",
      " 24200K .......... .......... .......... .......... .......... 48% 11.0M 3s\n",
      " 24250K .......... .......... .......... .......... .......... 48% 8.97M 3s\n",
      " 24300K .......... .......... .......... .......... .......... 48% 9.53M 3s\n",
      " 24350K .......... .......... .......... .......... .......... 49% 15.7M 3s\n",
      " 24400K .......... .......... .......... .......... .......... 49% 5.15M 3s\n",
      " 24450K .......... .......... .......... .......... .......... 49% 15.5M 3s\n",
      " 24500K .......... .......... .......... .......... .......... 49% 11.3M 3s\n",
      " 24550K .......... .......... .......... .......... .......... 49% 13.3M 3s\n",
      " 24600K .......... .......... .......... .......... .......... 49% 17.5M 3s\n",
      " 24650K .......... .......... .......... .......... .......... 49% 16.4M 3s\n",
      " 24700K .......... .......... .......... .......... .......... 49% 7.97M 3s\n",
      " 24750K .......... .......... .......... .......... .......... 49% 15.1M 3s\n",
      " 24800K .......... .......... .......... .......... .......... 49% 2.71M 3s\n",
      " 24850K .......... .......... .......... .......... .......... 50% 8.74M 3s\n",
      " 24900K .......... .......... .......... .......... .......... 50% 16.1M 3s\n",
      " 24950K .......... .......... .......... .......... .......... 50% 5.36M 3s\n",
      " 25000K .......... .......... .......... .......... .......... 50% 21.1M 3s\n",
      " 25050K .......... .......... .......... .......... .......... 50% 14.8M 3s\n",
      " 25100K .......... .......... .......... .......... .......... 50% 9.96M 3s\n",
      " 25150K .......... .......... .......... .......... .......... 50% 8.42M 3s\n",
      " 25200K .......... .......... .......... .......... .......... 50% 10.3M 3s\n",
      " 25250K .......... .......... .......... .......... .......... 50% 13.7M 3s\n",
      " 25300K .......... .......... .......... .......... .......... 50% 7.40M 3s\n",
      " 25350K .......... .......... .......... .......... .......... 51% 13.9M 3s\n",
      " 25400K .......... .......... .......... .......... .......... 51% 7.33M 3s\n",
      " 25450K .......... .......... .......... .......... .......... 51% 15.6M 3s\n",
      " 25500K .......... .......... .......... .......... .......... 51% 6.57M 3s\n",
      " 25550K .......... .......... .......... .......... .......... 51% 15.7M 3s\n",
      " 25600K .......... .......... .......... .......... .......... 51% 6.32M 3s\n",
      " 25650K .......... .......... .......... .......... .......... 51% 15.7M 3s\n",
      " 25700K .......... .......... .......... .......... .......... 51% 15.0M 3s\n",
      " 25750K .......... .......... .......... .......... .......... 51% 11.4M 3s\n",
      " 25800K .......... .......... .......... .......... .......... 51% 15.5M 3s\n",
      " 25850K .......... .......... .......... .......... .......... 52% 10.1M 3s\n",
      " 25900K .......... .......... .......... .......... .......... 52% 12.7M 2s\n",
      " 25950K .......... .......... .......... .......... .......... 52% 14.6M 2s\n",
      " 26000K .......... .......... .......... .......... .......... 52% 3.68M 2s\n",
      " 26050K .......... .......... .......... .......... .......... 52% 6.95M 2s\n",
      " 26100K .......... .......... .......... .......... .......... 52% 9.65M 2s\n",
      " 26150K .......... .......... .......... .......... .......... 52% 12.5M 2s\n",
      " 26200K .......... .......... .......... .......... .......... 52% 9.55M 2s\n",
      " 26250K .......... .......... .......... .......... .......... 52% 15.4M 2s\n",
      " 26300K .......... .......... .......... .......... .......... 52% 5.25M 2s\n",
      " 26350K .......... .......... .......... .......... .......... 53% 6.13M 2s\n",
      " 26400K .......... .......... .......... .......... .......... 53% 11.5M 2s\n",
      " 26450K .......... .......... .......... .......... .......... 53% 12.9M 2s\n",
      " 26500K .......... .......... .......... .......... .......... 53% 6.89M 2s\n",
      " 26550K .......... .......... .......... .......... .......... 53% 13.6M 2s\n",
      " 26600K .......... .......... .......... .......... .......... 53% 13.2M 2s\n",
      " 26650K .......... .......... .......... .......... .......... 53% 13.0M 2s\n",
      " 26700K .......... .......... .......... .......... .......... 53% 18.1M 2s\n",
      " 26750K .......... .......... .......... .......... .......... 53% 17.7M 2s\n",
      " 26800K .......... .......... .......... .......... .......... 53% 7.88M 2s\n",
      " 26850K .......... .......... .......... .......... .......... 54% 7.79M 2s\n",
      " 26900K .......... .......... .......... .......... .......... 54% 8.83M 2s\n",
      " 26950K .......... .......... .......... .......... .......... 54% 15.9M 2s\n",
      " 27000K .......... .......... .......... .......... .......... 54% 7.07M 2s\n",
      " 27050K .......... .......... .......... .......... .......... 54% 10.7M 2s\n",
      " 27100K .......... .......... .......... .......... .......... 54% 3.50M 2s\n",
      " 27150K .......... .......... .......... .......... .......... 54% 12.6M 2s\n",
      " 27200K .......... .......... .......... .......... .......... 54% 14.5M 2s\n",
      " 27250K .......... .......... .......... .......... .......... 54% 8.95M 2s\n",
      " 27300K .......... .......... .......... .......... .......... 54% 12.8M 2s\n",
      " 27350K .......... .......... .......... .......... .......... 55% 7.61M 2s\n",
      " 27400K .......... .......... .......... .......... .......... 55% 15.5M 2s\n",
      " 27450K .......... .......... .......... .......... .......... 55% 4.99M 2s\n",
      " 27500K .......... .......... .......... .......... .......... 55% 6.22M 2s\n",
      " 27550K .......... .......... .......... .......... .......... 55% 13.8M 2s\n",
      " 27600K .......... .......... .......... .......... .......... 55% 11.1M 2s\n",
      " 27650K .......... .......... .......... .......... .......... 55% 14.5M 2s\n",
      " 27700K .......... .......... .......... .......... .......... 55% 12.3M 2s\n",
      " 27750K .......... .......... .......... .......... .......... 55% 13.5M 2s\n",
      " 27800K .......... .......... .......... .......... .......... 55% 5.30M 2s\n",
      " 27850K .......... .......... .......... .......... .......... 56% 6.79M 2s\n",
      " 27900K .......... .......... .......... .......... .......... 56% 6.37M 2s\n",
      " 27950K .......... .......... .......... .......... .......... 56% 23.9M 2s\n",
      " 28000K .......... .......... .......... .......... .......... 56% 14.0M 2s\n",
      " 28050K .......... .......... .......... .......... .......... 56% 12.4M 2s\n",
      " 28100K .......... .......... .......... .......... .......... 56% 13.3M 2s\n",
      " 28150K .......... .......... .......... .......... .......... 56% 12.0M 2s\n",
      " 28200K .......... .......... .......... .......... .......... 56% 7.74M 2s\n",
      " 28250K .......... .......... .......... .......... .......... 56% 8.57M 2s\n",
      " 28300K .......... .......... .......... .......... .......... 56% 14.3M 2s\n",
      " 28350K .......... .......... .......... .......... .......... 57% 5.96M 2s\n",
      " 28400K .......... .......... .......... .......... .......... 57% 8.38M 2s\n",
      " 28450K .......... .......... .......... .......... .......... 57% 9.57M 2s\n",
      " 28500K .......... .......... .......... .......... .......... 57% 6.98M 2s\n",
      " 28550K .......... .......... .......... .......... .......... 57% 6.92M 2s\n",
      " 28600K .......... .......... .......... .......... .......... 57% 10.0M 2s\n",
      " 28650K .......... .......... .......... .......... .......... 57% 12.3M 2s\n",
      " 28700K .......... .......... .......... .......... .......... 57% 8.68M 2s\n",
      " 28750K .......... .......... .......... .......... .......... 57% 14.2M 2s\n",
      " 28800K .......... .......... .......... .......... .......... 57% 5.52M 2s\n",
      " 28850K .......... .......... .......... .......... .......... 58% 3.93M 2s\n",
      " 28900K .......... .......... .......... .......... .......... 58% 33.2M 2s\n",
      " 28950K .......... .......... .......... .......... .......... 58% 14.2M 2s\n",
      " 29000K .......... .......... .......... .......... .......... 58% 15.1M 2s\n",
      " 29050K .......... .......... .......... .......... .......... 58% 10.6M 2s\n",
      " 29100K .......... .......... .......... .......... .......... 58% 12.6M 2s\n",
      " 29150K .......... .......... .......... .......... .......... 58% 6.07M 2s\n",
      " 29200K .......... .......... .......... .......... .......... 58% 11.7M 2s\n",
      " 29250K .......... .......... .......... .......... .......... 58% 6.33M 2s\n",
      " 29300K .......... .......... .......... .......... .......... 58% 14.4M 2s\n",
      " 29350K .......... .......... .......... .......... .......... 59% 14.3M 2s\n",
      " 29400K .......... .......... .......... .......... .......... 59% 10.4M 2s\n",
      " 29450K .......... .......... .......... .......... .......... 59% 9.38M 2s\n",
      " 29500K .......... .......... .......... .......... .......... 59% 15.1M 2s\n",
      " 29550K .......... .......... .......... .......... .......... 59% 5.35M 2s\n",
      " 29600K .......... .......... .......... .......... .......... 59% 7.43M 2s\n",
      " 29650K .......... .......... .......... .......... .......... 59% 7.77M 2s\n",
      " 29700K .......... .......... .......... .......... .......... 59% 15.4M 2s\n",
      " 29750K .......... .......... .......... .......... .......... 59% 8.66M 2s\n",
      " 29800K .......... .......... .......... .......... .......... 59% 3.40M 2s\n",
      " 29850K .......... .......... .......... .......... .......... 60% 15.5M 2s\n",
      " 29900K .......... .......... .......... .......... .......... 60% 14.1M 2s\n",
      " 29950K .......... .......... .......... .......... .......... 60% 11.4M 2s\n",
      " 30000K .......... .......... .......... .......... .......... 60% 7.95M 2s\n",
      " 30050K .......... .......... .......... .......... .......... 60% 13.5M 2s\n",
      " 30100K .......... .......... .......... .......... .......... 60% 8.14M 2s\n",
      " 30150K .......... .......... .......... .......... .......... 60% 16.4M 2s\n",
      " 30200K .......... .......... .......... .......... .......... 60% 6.03M 2s\n",
      " 30250K .......... .......... .......... .......... .......... 60% 16.1M 2s\n",
      " 30300K .......... .......... .......... .......... .......... 60% 14.0M 2s\n",
      " 30350K .......... .......... .......... .......... .......... 61% 14.5M 2s\n",
      " 30400K .......... .......... .......... .......... .......... 61% 4.93M 2s\n",
      " 30450K .......... .......... .......... .......... .......... 61% 5.43M 2s\n",
      " 30500K .......... .......... .......... .......... .......... 61% 20.4M 2s\n",
      " 30550K .......... .......... .......... .......... .......... 61% 14.9M 2s\n",
      " 30600K .......... .......... .......... .......... .......... 61% 12.7M 2s\n",
      " 30650K .......... .......... .......... .......... .......... 61% 11.8M 2s\n",
      " 30700K .......... .......... .......... .......... .......... 61% 6.58M 2s\n",
      " 30750K .......... .......... .......... .......... .......... 61% 14.7M 2s\n",
      " 30800K .......... .......... .......... .......... .......... 61% 7.32M 2s\n",
      " 30850K .......... .......... .......... .......... .......... 62% 15.8M 2s\n",
      " 30900K .......... .......... .......... .......... .......... 62% 10.1M 2s\n",
      " 30950K .......... .......... .......... .......... .......... 62% 4.73M 2s\n",
      " 31000K .......... .......... .......... .......... .......... 62% 13.1M 2s\n",
      " 31050K .......... .......... .......... .......... .......... 62% 11.4M 2s\n",
      " 31100K .......... .......... .......... .......... .......... 62% 7.36M 2s\n",
      " 31150K .......... .......... .......... .......... .......... 62% 13.4M 2s\n",
      " 31200K .......... .......... .......... .......... .......... 62% 3.39M 2s\n",
      " 31250K .......... .......... .......... .......... .......... 62% 7.12M 2s\n",
      " 31300K .......... .......... .......... .......... .......... 62% 27.6M 2s\n",
      " 31350K .......... .......... .......... .......... .......... 63% 14.1M 2s\n",
      " 31400K .......... .......... .......... .......... .......... 63% 14.7M 2s\n",
      " 31450K .......... .......... .......... .......... .......... 63% 7.27M 2s\n",
      " 31500K .......... .......... .......... .......... .......... 63% 33.3M 2s\n",
      " 31550K .......... .......... .......... .......... .......... 63% 7.86M 2s\n",
      " 31600K .......... .......... .......... .......... .......... 63% 2.95M 2s\n",
      " 31650K .......... .......... .......... .......... .......... 63% 15.8M 2s\n",
      " 31700K .......... .......... .......... .......... .......... 63% 15.1M 2s\n",
      " 31750K .......... .......... .......... .......... .......... 63% 10.2M 2s\n",
      " 31800K .......... .......... .......... .......... .......... 63% 10.6M 2s\n",
      " 31850K .......... .......... .......... .......... .......... 64% 15.2M 2s\n",
      " 31900K .......... .......... .......... .......... .......... 64% 11.5M 2s\n",
      " 31950K .......... .......... .......... .......... .......... 64% 3.38M 2s\n",
      " 32000K .......... .......... .......... .......... .......... 64% 5.99M 2s\n",
      " 32050K .......... .......... .......... .......... .......... 64% 5.14M 2s\n",
      " 32100K .......... .......... .......... .......... .......... 64% 9.57M 2s\n",
      " 32150K .......... .......... .......... .......... .......... 64% 8.57M 2s\n",
      " 32200K .......... .......... .......... .......... .......... 64% 7.94M 2s\n",
      " 32250K .......... .......... .......... .......... .......... 64% 7.52M 2s\n",
      " 32300K .......... .......... .......... .......... .......... 64% 15.8M 2s\n",
      " 32350K .......... .......... .......... .......... .......... 65% 6.00M 2s\n",
      " 32400K .......... .......... .......... .......... .......... 65% 3.76M 2s\n",
      " 32450K .......... .......... .......... .......... .......... 65% 15.1M 2s\n",
      " 32500K .......... .......... .......... .......... .......... 65% 10.1M 2s\n",
      " 32550K .......... .......... .......... .......... .......... 65% 16.7M 2s\n",
      " 32600K .......... .......... .......... .......... .......... 65% 13.3M 2s\n",
      " 32650K .......... .......... .......... .......... .......... 65% 9.78M 2s\n",
      " 32700K .......... .......... .......... .......... .......... 65% 11.5M 2s\n",
      " 32750K .......... .......... .......... .......... .......... 65% 9.46M 2s\n",
      " 32800K .......... .......... .......... .......... .......... 65% 6.42M 2s\n",
      " 32850K .......... .......... .......... .......... .......... 66% 5.66M 2s\n",
      " 32900K .......... .......... .......... .......... .......... 66% 16.0M 2s\n",
      " 32950K .......... .......... .......... .......... .......... 66% 15.0M 2s\n",
      " 33000K .......... .......... .......... .......... .......... 66% 14.1M 2s\n",
      " 33050K .......... .......... .......... .......... .......... 66% 14.4M 2s\n",
      " 33100K .......... .......... .......... .......... .......... 66% 17.6M 2s\n",
      " 33150K .......... .......... .......... .......... .......... 66% 6.31M 2s\n",
      " 33200K .......... .......... .......... .......... .......... 66% 13.0M 2s\n",
      " 33250K .......... .......... .......... .......... .......... 66% 12.4M 2s\n",
      " 33300K .......... .......... .......... .......... .......... 66% 7.87M 2s\n",
      " 33350K .......... .......... .......... .......... .......... 67% 16.2M 2s\n",
      " 33400K .......... .......... .......... .......... .......... 67% 9.69M 2s\n",
      " 33450K .......... .......... .......... .......... .......... 67% 8.38M 2s\n",
      " 33500K .......... .......... .......... .......... .......... 67% 8.58M 2s\n",
      " 33550K .......... .......... .......... .......... .......... 67% 12.5M 2s\n",
      " 33600K .......... .......... .......... .......... .......... 67% 10.1M 2s\n",
      " 33650K .......... .......... .......... .......... .......... 67% 16.4M 2s\n",
      " 33700K .......... .......... .......... .......... .......... 67% 13.5M 2s\n",
      " 33750K .......... .......... .......... .......... .......... 67% 6.97M 2s\n",
      " 33800K .......... .......... .......... .......... .......... 67% 17.1M 2s\n",
      " 33850K .......... .......... .......... .......... .......... 68% 12.3M 2s\n",
      " 33900K .......... .......... .......... .......... .......... 68% 18.7M 2s\n",
      " 33950K .......... .......... .......... .......... .......... 68% 7.20M 2s\n",
      " 34000K .......... .......... .......... .......... .......... 68% 2.89M 2s\n",
      " 34050K .......... .......... .......... .......... .......... 68% 20.4M 2s\n",
      " 34100K .......... .......... .......... .......... .......... 68% 8.50M 2s\n",
      " 34150K .......... .......... .......... .......... .......... 68% 14.4M 2s\n",
      " 34200K .......... .......... .......... .......... .......... 68% 9.03M 2s\n",
      " 34250K .......... .......... .......... .......... .......... 68% 6.77M 2s\n",
      " 34300K .......... .......... .......... .......... .......... 68% 13.8M 2s\n",
      " 34350K .......... .......... .......... .......... .......... 69% 12.1M 2s\n",
      " 34400K .......... .......... .......... .......... .......... 69% 7.28M 2s\n",
      " 34450K .......... .......... .......... .......... .......... 69% 14.7M 2s\n",
      " 34500K .......... .......... .......... .......... .......... 69% 5.14M 2s\n",
      " 34550K .......... .......... .......... .......... .......... 69% 11.4M 2s\n",
      " 34600K .......... .......... .......... .......... .......... 69% 15.6M 2s\n",
      " 34650K .......... .......... .......... .......... .......... 69% 9.68M 2s\n",
      " 34700K .......... .......... .......... .......... .......... 69% 8.95M 2s\n",
      " 34750K .......... .......... .......... .......... .......... 69% 6.17M 2s\n",
      " 34800K .......... .......... .......... .......... .......... 69% 5.63M 2s\n",
      " 34850K .......... .......... .......... .......... .......... 70% 12.4M 2s\n",
      " 34900K .......... .......... .......... .......... .......... 70% 8.34M 2s\n",
      " 34950K .......... .......... .......... .......... .......... 70% 10.5M 2s\n",
      " 35000K .......... .......... .......... .......... .......... 70% 12.5M 2s\n",
      " 35050K .......... .......... .......... .......... .......... 70% 9.34M 2s\n",
      " 35100K .......... .......... .......... .......... .......... 70% 15.3M 2s\n",
      " 35150K .......... .......... .......... .......... .......... 70% 9.12M 2s\n",
      " 35200K .......... .......... .......... .......... .......... 70% 9.06M 2s\n",
      " 35250K .......... .......... .......... .......... .......... 70% 10.5M 2s\n",
      " 35300K .......... .......... .......... .......... .......... 70% 5.34M 2s\n",
      " 35350K .......... .......... .......... .......... .......... 71% 15.5M 2s\n",
      " 35400K .......... .......... .......... .......... .......... 71% 8.10M 2s\n",
      " 35450K .......... .......... .......... .......... .......... 71% 8.24M 2s\n",
      " 35500K .......... .......... .......... .......... .......... 71% 12.1M 2s\n",
      " 35550K .......... .......... .......... .......... .......... 71% 14.5M 2s\n",
      " 35600K .......... .......... .......... .......... .......... 71% 5.19M 1s\n",
      " 35650K .......... .......... .......... .......... .......... 71% 12.7M 1s\n",
      " 35700K .......... .......... .......... .......... .......... 71% 15.4M 1s\n",
      " 35750K .......... .......... .......... .......... .......... 71% 14.5M 1s\n",
      " 35800K .......... .......... .......... .......... .......... 72% 8.69M 1s\n",
      " 35850K .......... .......... .......... .......... .......... 72% 14.1M 1s\n",
      " 35900K .......... .......... .......... .......... .......... 72% 7.29M 1s\n",
      " 35950K .......... .......... .......... .......... .......... 72% 6.39M 1s\n",
      " 36000K .......... .......... .......... .......... .......... 72% 17.0M 1s\n",
      " 36050K .......... .......... .......... .......... .......... 72% 5.90M 1s\n",
      " 36100K .......... .......... .......... .......... .......... 72% 16.5M 1s\n",
      " 36150K .......... .......... .......... .......... .......... 72% 16.4M 1s\n",
      " 36200K .......... .......... .......... .......... .......... 72% 16.2M 1s\n",
      " 36250K .......... .......... .......... .......... .......... 72% 9.29M 1s\n",
      " 36300K .......... .......... .......... .......... .......... 73% 6.42M 1s\n",
      " 36350K .......... .......... .......... .......... .......... 73% 5.34M 1s\n",
      " 36400K .......... .......... .......... .......... .......... 73% 14.2M 1s\n",
      " 36450K .......... .......... .......... .......... .......... 73% 4.06M 1s\n",
      " 36500K .......... .......... .......... .......... .......... 73% 15.0M 1s\n",
      " 36550K .......... .......... .......... .......... .......... 73% 29.2M 1s\n",
      " 36600K .......... .......... .......... .......... .......... 73% 7.79M 1s\n",
      " 36650K .......... .......... .......... .......... .......... 73% 13.9M 1s\n",
      " 36700K .......... .......... .......... .......... .......... 73% 13.7M 1s\n",
      " 36750K .......... .......... .......... .......... .......... 73% 10.7M 1s\n",
      " 36800K .......... .......... .......... .......... .......... 74% 3.51M 1s\n",
      " 36850K .......... .......... .......... .......... .......... 74% 16.6M 1s\n",
      " 36900K .......... .......... .......... .......... .......... 74% 15.2M 1s\n",
      " 36950K .......... .......... .......... .......... .......... 74% 13.9M 1s\n",
      " 37000K .......... .......... .......... .......... .......... 74% 15.2M 1s\n",
      " 37050K .......... .......... .......... .......... .......... 74% 3.56M 1s\n",
      " 37100K .......... .......... .......... .......... .......... 74% 22.5M 1s\n",
      " 37150K .......... .......... .......... .......... .......... 74% 16.1M 1s\n",
      " 37200K .......... .......... .......... .......... .......... 74% 8.11M 1s\n",
      " 37250K .......... .......... .......... .......... .......... 74% 8.35M 1s\n",
      " 37300K .......... .......... .......... .......... .......... 75% 20.6M 1s\n",
      " 37350K .......... .......... .......... .......... .......... 75% 7.62M 1s\n",
      " 37400K .......... .......... .......... .......... .......... 75% 17.3M 1s\n",
      " 37450K .......... .......... .......... .......... .......... 75% 8.65M 1s\n",
      " 37500K .......... .......... .......... .......... .......... 75% 5.75M 1s\n",
      " 37550K .......... .......... .......... .......... .......... 75% 6.93M 1s\n",
      " 37600K .......... .......... .......... .......... .......... 75% 13.7M 1s\n",
      " 37650K .......... .......... .......... .......... .......... 75% 15.9M 1s\n",
      " 37700K .......... .......... .......... .......... .......... 75% 13.0M 1s\n",
      " 37750K .......... .......... .......... .......... .......... 75% 8.40M 1s\n",
      " 37800K .......... .......... .......... .......... .......... 76% 14.4M 1s\n",
      " 37850K .......... .......... .......... .......... .......... 76% 1.56M 1s\n",
      " 37900K .......... .......... .......... .......... .......... 76% 34.3M 1s\n",
      " 37950K .......... .......... .......... .......... .......... 76% 11.2M 1s\n",
      " 38000K .......... .......... .......... .......... .......... 76% 6.51M 1s\n",
      " 38050K .......... .......... .......... .......... .......... 76% 2.96M 1s\n",
      " 38100K .......... .......... .......... .......... .......... 76% 7.40M 1s\n",
      " 38150K .......... .......... .......... .......... .......... 76% 7.40M 1s\n",
      " 38200K .......... .......... .......... .......... .......... 76% 8.14M 1s\n",
      " 38250K .......... .......... .......... .......... .......... 76% 33.7M 1s\n",
      " 38300K .......... .......... .......... .......... .......... 77% 2.29M 1s\n",
      " 38350K .......... .......... .......... .......... .......... 77% 27.6M 1s\n",
      " 38400K .......... .......... .......... .......... .......... 77% 7.91M 1s\n",
      " 38450K .......... .......... .......... .......... .......... 77% 2.64M 1s\n",
      " 38500K .......... .......... .......... .......... .......... 77% 10.6M 1s\n",
      " 38550K .......... .......... .......... .......... .......... 77% 15.3M 1s\n",
      " 38600K .......... .......... .......... .......... .......... 77% 15.4M 1s\n",
      " 38650K .......... .......... .......... .......... .......... 77% 8.94M 1s\n",
      " 38700K .......... .......... .......... .......... .......... 77% 12.4M 1s\n",
      " 38750K .......... .......... .......... .......... .......... 77% 9.68M 1s\n",
      " 38800K .......... .......... .......... .......... .......... 78% 4.39M 1s\n",
      " 38850K .......... .......... .......... .......... .......... 78% 16.7M 1s\n",
      " 38900K .......... .......... .......... .......... .......... 78% 14.4M 1s\n",
      " 38950K .......... .......... .......... .......... .......... 78% 2.86M 1s\n",
      " 39000K .......... .......... .......... .......... .......... 78% 8.48M 1s\n",
      " 39050K .......... .......... .......... .......... .......... 78% 1.60M 1s\n",
      " 39100K .......... .......... .......... .......... .......... 78% 11.0M 1s\n",
      " 39150K .......... .......... .......... .......... .......... 78%  300M 1s\n",
      " 39200K .......... .......... .......... .......... .......... 78%  552M 1s\n",
      " 39250K .......... .......... .......... .......... .......... 78%  650M 1s\n",
      " 39300K .......... .......... .......... .......... .......... 79%  109M 1s\n",
      " 39350K .......... .......... .......... .......... .......... 79%  284M 1s\n",
      " 39400K .......... .......... .......... .......... .......... 79% 12.8M 1s\n",
      " 39450K .......... .......... .......... .......... .......... 79% 16.3M 1s\n",
      " 39500K .......... .......... .......... .......... .......... 79% 7.04M 1s\n",
      " 39550K .......... .......... .......... .......... .......... 79% 20.2M 1s\n",
      " 39600K .......... .......... .......... .......... .......... 79% 2.87M 1s\n",
      " 39650K .......... .......... .......... .......... .......... 79% 8.10M 1s\n",
      " 39700K .......... .......... .......... .......... .......... 79% 7.78M 1s\n",
      " 39750K .......... .......... .......... .......... .......... 79% 13.4M 1s\n",
      " 39800K .......... .......... .......... .......... .......... 80% 10.4M 1s\n",
      " 39850K .......... .......... .......... .......... .......... 80% 15.9M 1s\n",
      " 39900K .......... .......... .......... .......... .......... 80% 14.8M 1s\n",
      " 39950K .......... .......... .......... .......... .......... 80% 10.2M 1s\n",
      " 40000K .......... .......... .......... .......... .......... 80% 5.74M 1s\n",
      " 40050K .......... .......... .......... .......... .......... 80% 18.2M 1s\n",
      " 40100K .......... .......... .......... .......... .......... 80% 5.33M 1s\n",
      " 40150K .......... .......... .......... .......... .......... 80% 16.4M 1s\n",
      " 40200K .......... .......... .......... .......... .......... 80% 12.7M 1s\n",
      " 40250K .......... .......... .......... .......... .......... 80% 15.0M 1s\n",
      " 40300K .......... .......... .......... .......... .......... 81% 12.6M 1s\n",
      " 40350K .......... .......... .......... .......... .......... 81% 8.84M 1s\n",
      " 40400K .......... .......... .......... .......... .......... 81% 7.49M 1s\n",
      " 40450K .......... .......... .......... .......... .......... 81% 7.95M 1s\n",
      " 40500K .......... .......... .......... .......... .......... 81% 28.4M 1s\n",
      " 40550K .......... .......... .......... .......... .......... 81% 11.9M 1s\n",
      " 40600K .......... .......... .......... .......... .......... 81% 2.10M 1s\n",
      " 40650K .......... .......... .......... .......... .......... 81% 16.2M 1s\n",
      " 40700K .......... .......... .......... .......... .......... 81% 15.8M 1s\n",
      " 40750K .......... .......... .......... .......... .......... 81% 7.26M 1s\n",
      " 40800K .......... .......... .......... .......... .......... 82% 2.91M 1s\n",
      " 40850K .......... .......... .......... .......... .......... 82% 29.2M 1s\n",
      " 40900K .......... .......... .......... .......... .......... 82% 6.04M 1s\n",
      " 40950K .......... .......... .......... .......... .......... 82% 15.6M 1s\n",
      " 41000K .......... .......... .......... .......... .......... 82% 13.9M 1s\n",
      " 41050K .......... .......... .......... .......... .......... 82% 10.2M 1s\n",
      " 41100K .......... .......... .......... .......... .......... 82% 15.5M 1s\n",
      " 41150K .......... .......... .......... .......... .......... 82% 15.8M 1s\n",
      " 41200K .......... .......... .......... .......... .......... 82% 9.52M 1s\n",
      " 41250K .......... .......... .......... .......... .......... 82% 6.14M 1s\n",
      " 41300K .......... .......... .......... .......... .......... 83% 9.17M 1s\n",
      " 41350K .......... .......... .......... .......... .......... 83% 10.3M 1s\n",
      " 41400K .......... .......... .......... .......... .......... 83% 12.9M 1s\n",
      " 41450K .......... .......... .......... .......... .......... 83% 3.11M 1s\n",
      " 41500K .......... .......... .......... .......... .......... 83% 30.7M 1s\n",
      " 41550K .......... .......... .......... .......... .......... 83% 13.6M 1s\n",
      " 41600K .......... .......... .......... .......... .......... 83% 6.29M 1s\n",
      " 41650K .......... .......... .......... .......... .......... 83% 13.4M 1s\n",
      " 41700K .......... .......... .......... .......... .......... 83% 10.4M 1s\n",
      " 41750K .......... .......... .......... .......... .......... 83% 11.9M 1s\n",
      " 41800K .......... .......... .......... .......... .......... 84% 13.9M 1s\n",
      " 41850K .......... .......... .......... .......... .......... 84% 4.56M 1s\n",
      " 41900K .......... .......... .......... .......... .......... 84% 6.11M 1s\n",
      " 41950K .......... .......... .......... .......... .......... 84% 13.2M 1s\n",
      " 42000K .......... .......... .......... .......... .......... 84% 15.6M 1s\n",
      " 42050K .......... .......... .......... .......... .......... 84% 6.91M 1s\n",
      " 42100K .......... .......... .......... .......... .......... 84% 14.6M 1s\n",
      " 42150K .......... .......... .......... .......... .......... 84% 16.3M 1s\n",
      " 42200K .......... .......... .......... .......... .......... 84% 3.94M 1s\n",
      " 42250K .......... .......... .......... .......... .......... 84% 10.9M 1s\n",
      " 42300K .......... .......... .......... .......... .......... 85% 7.38M 1s\n",
      " 42350K .......... .......... .......... .......... .......... 85% 12.8M 1s\n",
      " 42400K .......... .......... .......... .......... .......... 85% 6.49M 1s\n",
      " 42450K .......... .......... .......... .......... .......... 85% 19.9M 1s\n",
      " 42500K .......... .......... .......... .......... .......... 85% 5.02M 1s\n",
      " 42550K .......... .......... .......... .......... .......... 85% 16.9M 1s\n",
      " 42600K .......... .......... .......... .......... .......... 85% 6.04M 1s\n",
      " 42650K .......... .......... .......... .......... .......... 85% 15.8M 1s\n",
      " 42700K .......... .......... .......... .......... .......... 85% 7.06M 1s\n",
      " 42750K .......... .......... .......... .......... .......... 85% 8.82M 1s\n",
      " 42800K .......... .......... .......... .......... .......... 86% 5.92M 1s\n",
      " 42850K .......... .......... .......... .......... .......... 86% 11.7M 1s\n",
      " 42900K .......... .......... .......... .......... .......... 86% 9.49M 1s\n",
      " 42950K .......... .......... .......... .......... .......... 86% 13.1M 1s\n",
      " 43000K .......... .......... .......... .......... .......... 86% 15.3M 1s\n",
      " 43050K .......... .......... .......... .......... .......... 86% 14.5M 1s\n",
      " 43100K .......... .......... .......... .......... .......... 86% 14.6M 1s\n",
      " 43150K .......... .......... .......... .......... .......... 86% 9.93M 1s\n",
      " 43200K .......... .......... .......... .......... .......... 86% 9.51M 1s\n",
      " 43250K .......... .......... .......... .......... .......... 86% 15.7M 1s\n",
      " 43300K .......... .......... .......... .......... .......... 87% 2.44M 1s\n",
      " 43350K .......... .......... .......... .......... .......... 87% 15.5M 1s\n",
      " 43400K .......... .......... .......... .......... .......... 87% 14.9M 1s\n",
      " 43450K .......... .......... .......... .......... .......... 87% 15.3M 1s\n",
      " 43500K .......... .......... .......... .......... .......... 87% 8.30M 1s\n",
      " 43550K .......... .......... .......... .......... .......... 87% 10.1M 1s\n",
      " 43600K .......... .......... .......... .......... .......... 87% 13.4M 1s\n",
      " 43650K .......... .......... .......... .......... .......... 87% 5.99M 1s\n",
      " 43700K .......... .......... .......... .......... .......... 87% 5.60M 1s\n",
      " 43750K .......... .......... .......... .......... .......... 87% 11.6M 1s\n",
      " 43800K .......... .......... .......... .......... .......... 88% 13.7M 1s\n",
      " 43850K .......... .......... .......... .......... .......... 88% 15.0M 1s\n",
      " 43900K .......... .......... .......... .......... .......... 88% 10.4M 1s\n",
      " 43950K .......... .......... .......... .......... .......... 88% 16.5M 1s\n",
      " 44000K .......... .......... .......... .......... .......... 88% 1.12M 1s\n",
      " 44050K .......... .......... .......... .......... .......... 88% 14.2M 1s\n",
      " 44100K .......... .......... .......... .......... .......... 88% 5.47M 1s\n",
      " 44150K .......... .......... .......... .......... .......... 88% 8.11M 1s\n",
      " 44200K .......... .......... .......... .......... .......... 88% 7.81M 1s\n",
      " 44250K .......... .......... .......... .......... .......... 88% 32.0M 1s\n",
      " 44300K .......... .......... .......... .......... .......... 89% 9.07M 1s\n",
      " 44350K .......... .......... .......... .......... .......... 89% 5.35M 1s\n",
      " 44400K .......... .......... .......... .......... .......... 89% 7.75M 1s\n",
      " 44450K .......... .......... .......... .......... .......... 89% 14.4M 1s\n",
      " 44500K .......... .......... .......... .......... .......... 89% 10.5M 1s\n",
      " 44550K .......... .......... .......... .......... .......... 89% 9.58M 1s\n",
      " 44600K .......... .......... .......... .......... .......... 89% 31.5M 1s\n",
      " 44650K .......... .......... .......... .......... .......... 89% 13.7M 1s\n",
      " 44700K .......... .......... .......... .......... .......... 89% 13.9M 1s\n",
      " 44750K .......... .......... .......... .......... .......... 89% 5.27M 1s\n",
      " 44800K .......... .......... .......... .......... .......... 90% 10.2M 1s\n",
      " 44850K .......... .......... .......... .......... .......... 90% 7.33M 1s\n",
      " 44900K .......... .......... .......... .......... .......... 90% 10.6M 1s\n",
      " 44950K .......... .......... .......... .......... .......... 90% 11.9M 1s\n",
      " 45000K .......... .......... .......... .......... .......... 90% 13.8M 1s\n",
      " 45050K .......... .......... .......... .......... .......... 90% 14.7M 1s\n",
      " 45100K .......... .......... .......... .......... .......... 90% 9.63M 1s\n",
      " 45150K .......... .......... .......... .......... .......... 90% 31.0M 0s\n",
      " 45200K .......... .......... .......... .......... .......... 90% 10.6M 0s\n",
      " 45250K .......... .......... .......... .......... .......... 90% 6.39M 0s\n",
      " 45300K .......... .......... .......... .......... .......... 91% 33.0M 0s\n",
      " 45350K .......... .......... .......... .......... .......... 91% 13.8M 0s\n",
      " 45400K .......... .......... .......... .......... .......... 91% 4.72M 0s\n",
      " 45450K .......... .......... .......... .......... .......... 91% 18.0M 0s\n",
      " 45500K .......... .......... .......... .......... .......... 91% 6.44M 0s\n",
      " 45550K .......... .......... .......... .......... .......... 91% 30.5M 0s\n",
      " 45600K .......... .......... .......... .......... .......... 91% 9.99M 0s\n",
      " 45650K .......... .......... .......... .......... .......... 91% 16.6M 0s\n",
      " 45700K .......... .......... .......... .......... .......... 91% 7.52M 0s\n",
      " 45750K .......... .......... .......... .......... .......... 91% 15.5M 0s\n",
      " 45800K .......... .......... .......... .......... .......... 92% 8.76M 0s\n",
      " 45850K .......... .......... .......... .......... .......... 92% 4.43M 0s\n",
      " 45900K .......... .......... .......... .......... .......... 92% 14.1M 0s\n",
      " 45950K .......... .......... .......... .......... .......... 92% 6.85M 0s\n",
      " 46000K .......... .......... .......... .......... .......... 92% 6.83M 0s\n",
      " 46050K .......... .......... .......... .......... .......... 92% 8.91M 0s\n",
      " 46100K .......... .......... .......... .......... .......... 92% 6.78M 0s\n",
      " 46150K .......... .......... .......... .......... .......... 92% 27.9M 0s\n",
      " 46200K .......... .......... .......... .......... .......... 92% 6.84M 0s\n",
      " 46250K .......... .......... .......... .......... .......... 92% 16.5M 0s\n",
      " 46300K .......... .......... .......... .......... .......... 93% 5.33M 0s\n",
      " 46350K .......... .......... .......... .......... .......... 93% 15.7M 0s\n",
      " 46400K .......... .......... .......... .......... .......... 93% 3.39M 0s\n",
      " 46450K .......... .......... .......... .......... .......... 93% 18.0M 0s\n",
      " 46500K .......... .......... .......... .......... .......... 93% 4.21M 0s\n",
      " 46550K .......... .......... .......... .......... .......... 93% 31.4M 0s\n",
      " 46600K .......... .......... .......... .......... .......... 93% 16.1M 0s\n",
      " 46650K .......... .......... .......... .......... .......... 93% 12.6M 0s\n",
      " 46700K .......... .......... .......... .......... .......... 93% 14.4M 0s\n",
      " 46750K .......... .......... .......... .......... .......... 93% 6.56M 0s\n",
      " 46800K .......... .......... .......... .......... .......... 94% 5.69M 0s\n",
      " 46850K .......... .......... .......... .......... .......... 94% 30.5M 0s\n",
      " 46900K .......... .......... .......... .......... .......... 94% 6.92M 0s\n",
      " 46950K .......... .......... .......... .......... .......... 94% 10.4M 0s\n",
      " 47000K .......... .......... .......... .......... .......... 94% 13.2M 0s\n",
      " 47050K .......... .......... .......... .......... .......... 94% 7.19M 0s\n",
      " 47100K .......... .......... .......... .......... .......... 94% 11.0M 0s\n",
      " 47150K .......... .......... .......... .......... .......... 94% 9.15M 0s\n",
      " 47200K .......... .......... .......... .......... .......... 94% 11.6M 0s\n",
      " 47250K .......... .......... .......... .......... .......... 94% 7.58M 0s\n",
      " 47300K .......... .......... .......... .......... .......... 95% 5.72M 0s\n",
      " 47350K .......... .......... .......... .......... .......... 95% 5.75M 0s\n",
      " 47400K .......... .......... .......... .......... .......... 95% 15.3M 0s\n",
      " 47450K .......... .......... .......... .......... .......... 95% 9.15M 0s\n",
      " 47500K .......... .......... .......... .......... .......... 95% 10.6M 0s\n",
      " 47550K .......... .......... .......... .......... .......... 95% 8.58M 0s\n",
      " 47600K .......... .......... .......... .......... .......... 95% 11.3M 0s\n",
      " 47650K .......... .......... .......... .......... .......... 95% 10.4M 0s\n",
      " 47700K .......... .......... .......... .......... .......... 95% 11.3M 0s\n",
      " 47750K .......... .......... .......... .......... .......... 96% 5.80M 0s\n",
      " 47800K .......... .......... .......... .......... .......... 96% 8.19M 0s\n",
      " 47850K .......... .......... .......... .......... .......... 96% 17.4M 0s\n",
      " 47900K .......... .......... .......... .......... .......... 96% 15.8M 0s\n",
      " 47950K .......... .......... .......... .......... .......... 96% 2.61M 0s\n",
      " 48000K .......... .......... .......... .......... .......... 96% 10.7M 0s\n",
      " 48050K .......... .......... .......... .......... .......... 96% 13.7M 0s\n",
      " 48100K .......... .......... .......... .......... .......... 96% 9.74M 0s\n",
      " 48150K .......... .......... .......... .......... .......... 96% 3.99M 0s\n",
      " 48200K .......... .......... .......... .......... .......... 96% 16.4M 0s\n",
      " 48250K .......... .......... .......... .......... .......... 97% 28.8M 0s\n",
      " 48300K .......... .......... .......... .......... .......... 97% 11.1M 0s\n",
      " 48350K .......... .......... .......... .......... .......... 97% 12.9M 0s\n",
      " 48400K .......... .......... .......... .......... .......... 97% 4.04M 0s\n",
      " 48450K .......... .......... .......... .......... .......... 97% 9.72M 0s\n",
      " 48500K .......... .......... .......... .......... .......... 97% 7.95M 0s\n",
      " 48550K .......... .......... .......... .......... .......... 97% 11.9M 0s\n",
      " 48600K .......... .......... .......... .......... .......... 97% 6.54M 0s\n",
      " 48650K .......... .......... .......... .......... .......... 97% 6.42M 0s\n",
      " 48700K .......... .......... .......... .......... .......... 97% 14.8M 0s\n",
      " 48750K .......... .......... .......... .......... .......... 98% 15.5M 0s\n",
      " 48800K .......... .......... .......... .......... .......... 98% 8.07M 0s\n",
      " 48850K .......... .......... .......... .......... .......... 98% 14.7M 0s\n",
      " 48900K .......... .......... .......... .......... .......... 98% 12.9M 0s\n",
      " 48950K .......... .......... .......... .......... .......... 98% 15.1M 0s\n",
      " 49000K .......... .......... .......... .......... .......... 98% 5.76M 0s\n",
      " 49050K .......... .......... .......... .......... .......... 98% 15.1M 0s\n",
      " 49100K .......... .......... .......... .......... .......... 98% 1.84M 0s\n",
      " 49150K .......... .......... .......... .......... .......... 98% 18.6M 0s\n",
      " 49200K .......... .......... .......... .......... .......... 98% 9.62M 0s\n",
      " 49250K .......... .......... .......... .......... .......... 99% 7.91M 0s\n",
      " 49300K .......... .......... .......... .......... .......... 99% 10.7M 0s\n",
      " 49350K .......... .......... .......... .......... .......... 99% 12.6M 0s\n",
      " 49400K .......... .......... .......... .......... .......... 99% 11.7M 0s\n",
      " 49450K .......... .......... .......... .......... .......... 99% 6.52M 0s\n",
      " 49500K .......... .......... .......... .......... .......... 99% 7.97M 0s\n",
      " 49550K .......... .......... .......... .......... .......... 99% 15.0M 0s\n",
      " 49600K .......... .......... .......... .......... .......... 99% 5.53M 0s\n",
      " 49650K .......... .......... .......... .......... .......... 99% 15.1M 0s\n",
      " 49700K .......... .......... .......... .......... .......... 99% 15.1M 0s\n",
      " 49750K .......... .......... .......... .........            100% 14.1M=5.4s\n",
      "\n",
      "2023-11-21 16:27:49 (8.98 MB/s) - './checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth' saved [50984463/50984463]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download weights\n",
    "!mkdir -p ./checkpoints/fpn_resnet_18\n",
    "!wget https://github.com/maudzung/SFA3D/raw/master/checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth -P ./checkpoints/fpn_resnet_18/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5f6145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset have been downloaded\n",
      "using ResNet architecture with feature pyramid\n",
      "\n",
      "\n",
      "-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=\n",
      "\n",
      "\n",
      "Loaded weights from ./checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIYA\\AppData\\Local\\Temp/ipykernel_11736/3923018560.py:43: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return pts_2d.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create video writer at ./results\\fpn_resnet_18\\2011_09_26_drive_0014_sync_both_2_sides.avi\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11736/3520060489.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mmetadatas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfront_bevmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_bevmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdemo_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_bevmap_front_vs_back\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mfront_detections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfront_bevmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_detect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfront_bevmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_front\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mback_detections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_bevmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_detect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_bevmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_front\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# Draw prediction in the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11736/3954868594.py\u001b[0m in \u001b[0;36mdo_detect\u001b[1;34m(configs, model, bevmap, is_front)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0minput_bev_maps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbevmap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_synchronized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_bev_maps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hm_cen'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hm_cen'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cen_offset'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cen_offset'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11736/2767790592.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mout_layer1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0mout_layer2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_layer1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mout_layer3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_layer2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11736/2767790592.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mresidual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mresidual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "configs = parse_demo_configs()\n",
    "\n",
    "# Try to download the dataset for demonstration\n",
    "server_url = 'https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data'\n",
    "download_url = '{}/{}/{}.zip'.format(server_url, configs.foldername[:-5], configs.foldername)\n",
    "download_and_unzip(configs.dataset_dir, download_url)\n",
    "\n",
    "model = create_model(configs)\n",
    "print('\\n\\n' + '-*=' * 30 + '\\n\\n')\n",
    "assert os.path.isfile(configs.pretrained_path), \"No file at {}\".format(configs.pretrained_path)\n",
    "model.load_state_dict(torch.load(configs.pretrained_path, map_location='cpu'))\n",
    "print('Loaded weights from {}\\n'.format(configs.pretrained_path))\n",
    "\n",
    "configs.device = torch.device('cpu')\n",
    "model = model.to(device=configs.device)\n",
    "model.eval()\n",
    "\n",
    "out_cap = None\n",
    "demo_dataset = Demo_KittiDataset(configs)\n",
    "with torch.no_grad():\n",
    "    for sample_idx in range(len(demo_dataset)):\n",
    "        metadatas, front_bevmap, back_bevmap, img_rgb = demo_dataset.load_bevmap_front_vs_back(sample_idx)\n",
    "        front_detections, front_bevmap, fps = do_detect(configs, model, front_bevmap, is_front=True)\n",
    "        back_detections, back_bevmap, _ = do_detect(configs, model, back_bevmap, is_front=False)\n",
    "\n",
    "        # Draw prediction in the image\n",
    "        front_bevmap = (front_bevmap.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "        front_bevmap = cv2.resize(front_bevmap, (BEV_WIDTH, BEV_HEIGHT))\n",
    "        front_bevmap = draw_predictions(front_bevmap, front_detections, configs.num_classes)\n",
    "        # Rotate the front_bevmap\n",
    "        front_bevmap = cv2.rotate(front_bevmap, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        # Draw prediction in the image\n",
    "        back_bevmap = (back_bevmap.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "        back_bevmap = cv2.resize(back_bevmap, (BEV_WIDTH, BEV_HEIGHT))\n",
    "        back_bevmap = draw_predictions(back_bevmap, back_detections, configs.num_classes)\n",
    "        # Rotate the back_bevmap\n",
    "        back_bevmap = cv2.rotate(back_bevmap, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "        # merge front and back bevmap\n",
    "        full_bev = np.concatenate((back_bevmap, front_bevmap), axis=1)\n",
    "\n",
    "        img_path = metadatas['img_path'][0]\n",
    "        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "        calib = Calibration(configs.calib_path)\n",
    "        kitti_dets = convert_det_to_real_values(front_detections)\n",
    "        if len(kitti_dets) > 0:\n",
    "            kitti_dets[:, 1:] = lidar_to_camera_box(kitti_dets[:, 1:], calib.V2C, calib.R0, calib.P2)\n",
    "            img_bgr = show_rgb_image_with_boxes(img_bgr, kitti_dets, calib)\n",
    "        img_bgr = cv2.resize(img_bgr, (BEV_WIDTH * 2, 375))\n",
    "\n",
    "        out_img = np.concatenate((img_bgr, full_bev), axis=0)\n",
    "        write_credit(out_img, (50, 410), text_author='Cre: Diya Tharappan ', org_fps=(900, 410), fps=fps)\n",
    "\n",
    "        if out_cap is None:\n",
    "            out_cap_h, out_cap_w = out_img.shape[:2]\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "            out_path = os.path.join(configs.results_dir, '{}_both_2_sides.avi'.format(configs.foldername))\n",
    "            print('Create video writer at {}'.format(out_path))\n",
    "            out_cap = cv2.VideoWriter(out_path, fourcc, 5, (out_cap_w, out_cap_h))\n",
    "\n",
    "        out_cap.write(out_img)\n",
    "\n",
    "if out_cap:\n",
    "    out_cap.release()\n",
    "\n",
    "print(\"Video Created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b484ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
